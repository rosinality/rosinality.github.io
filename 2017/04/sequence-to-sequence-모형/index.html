<!doctype html><html lang=ko-kr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.73.0"><meta name=theme content="Tranquilpeak 0.3.1-BETA"><title>Sequence to Sequence 모형</title><meta name=author content="Kim Seonghyeon"><meta name=keywords content=",machine learning,deep learning,social science"><link rel=icon href=/favicon.png><meta name=description content="기본적인 뉴럴 네트워크는 함수 $f(x)$를 근사하는 것이라고 보면 된다. 입력을 원하는 출력으로 매핑하는 것이다. 예컨대 입력이 이미지라면 입력 이미지가 개인"><meta property="og:description" content="기본적인 뉴럴 네트워크는 함수 $f(x)$를 근사하는 것이라고 보면 된다. 입력을 원하는 출력으로 매핑하는 것이다. 예컨대 입력이 이미지라면 입력 이미지가 개인"><meta property="og:type" content="blog"><meta property="og:title" content="Sequence to Sequence 모형"><meta property="og:url" content="/2017/04/sequence-to-sequence-%EB%AA%A8%ED%98%95/"><meta property="og:site_name" content="Nondifferentiable Log"><meta name=twitter:card content="summary"><meta name=twitter:title content="Nondifferentiable Log"><meta name=twitter:description content="기본적인 뉴럴 네트워크는 함수 $f(x)$를 근사하는 것이라고 보면 된다. 입력을 원하는 출력으로 매핑하는 것이다. 예컨대 입력이 이미지라면 입력 이미지가 개인"><meta name=twitter:creator content="@rosinality"><meta property="og:image" content="http://res.cloudinary.com/rosinality/image/upload/v1492734160/seq2seq/basic_seq2seq.png"><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css><link rel=stylesheet href=/css/style-u6mk0ojoywresbx8iepslrmmhl4stuhrsxuwhkpwrkrx7mryjcaimasnk4pi.min.css></head><body><div id=blog><header id=header data-behavior=5><i id=btn-open-sidebar class="fa fa-lg fa-bars"></i><div class=header-title><a class=header-title-link href=/>Nondifferentiable Log</a></div></header><nav id=sidebar data-behavior=5><div class=sidebar-container><div class=sidebar-profile><a href=/#about><img class=sidebar-profile-picture src="//www.gravatar.com/avatar/63eec5e671fc734bde45cd43cc156abc?s=110" alt></a><h4 class=sidebar-profile-name>Kim Seonghyeon</h4><h5 class=sidebar-profile-bio>Machine learning enthusiast</h5></div><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=/categories><i class="sidebar-button-icon fa fa-lg fa-bookmark"></i><span class=sidebar-button-desc>Categories</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/tags><i class="sidebar-button-icon fa fa-lg fa-tags"></i><span class=sidebar-button-desc>Tags</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/archives><i class="sidebar-button-icon fa fa-lg fa-archive"></i><span class=sidebar-button-desc>Archives</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/#about><i class="sidebar-button-icon fa fa-lg fa-question"></i><span class=sidebar-button-desc>About</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/><i class="sidebar-button-icon fa fa-lg fa-home"></i><span class=sidebar-button-desc>Home</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://github.com/rosinality target=_blank><i class="sidebar-button-icon fa fa-lg fa-github"></i><span class=sidebar-button-desc>GitHub</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=/index.xml><i class="sidebar-button-icon fa fa-lg fa-rss"></i><span class=sidebar-button-desc>RSS</span></a></li></ul></div></nav><div id=main data-behavior=5 class=hasCoverMetaIn><article class=post itemscope itemtype=http://schema.org/BlogPosting><div class="post-header main-content-wrap text-left"><h1 class=post-title itemprop=headline>Sequence to Sequence 모형</h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2017-04-20T21:16:13+09:00>April 20, 2017</time>
<span></span><a class=category-link href=/categories/sorta-informative>sorta informative</a></div></div><div class="post-content markdown" itemprop=articleBody><div class=main-content-wrap><p>기본적인 뉴럴 네트워크는 함수 $f(x)$를 근사하는 것이라고 보면 된다. 입력을 원하는 출력으로 매핑하는 것이다. 예컨대 입력이 이미지라면 입력 이미지가 개인지 새인지 하는 것을 출력하는 함수를 뉴럴 네트워크로 근사하는 것이다. 그런데 생각해보면 함수에 입력하는 변수의 크기는 정해져 있다. 즉 $f(x)$ 함수는 $x$에 대한 함수이지 $x$와 $y$에 대한 함수로 확장할 수는 없는 것이다. 이게 왜 문제가 될까?</p><p>문장을 번역한다고 할 때 입력이 되는 문장의 길이는 그때그때 다를 것이다. 단어가 열 개일 수도 있고 스무 개일 수도 있다. 따라서 영어 문장을 입력으로 받아 한국어 문장을 출력하는 함수는 가변 길이 입력에 대해 적용할 수 있어야 한다. 어떻게 해야 할까?</p><p>Recurrent Neural Network는 이를 Recursion과 상태(state)를 도입하는 방법으로 해결했다. RNN은 다음과 같은 함수이다:</p><p><span class=math>\[
h_t = f(x_t, h_{t - 1})
\]</span></p><p>여기서 $h_t$는 $t$ 시점의 상태이고 $x_t$는 $t$ 시점의 입력이다. 즉 $t$ 시점의 상태는 이전 시점 $t-1$의 상태와 현재 입력에 의해 결정되는 것이다. 즉 단어 1, 단어 2, 단어 3에 대해서 RNN은 다음과 같이 작동한다:</p><p><span class=math>\[
h_1 = f(\text{단어 1}, h_0) \\
h_2 = f(\text{단어 2}, h_1) \\
h_3 = f(\text{단어 3}, h_2) \\
(h_0 = \mathbf{0})
\]</span></p><p>즉 마지막 상태 $h_3$는 모든 입력 단어 1, 단어 2, 단어 3을 RNN이 "보고 난" 이후 결정되는 것이다. 따라서 $h_3$는 입력에 모두에 대한 정보를 (상태의 크기가 충분하다고 하면) 갖게 된다.</p><p>자, 이제 이런 함수로 어떻게 문장을 번역할 수 있을까?</p><p>위와 같은 RNN에 영어 문장을 입력했다고 해보자. 그렇다면 영어 문장을 입력으로 받은 RNN의 최종 상태 $h_t$는 영어 문장에 대한 충분한 정보를 갖고 있을 것이다. 이런 RNN을 입력을 특정한 상태 벡터로 인코딩한다고 해서 인코더라고 부른다. 이제 인코더가 인코딩한 상태 $h_t$를 인코딩된 벡터를 복원하는 디코더에 입력한다. 디코더 RNN이 인코더가 인코딩한 영어 문장을 한국어 문장으로 디코딩하는 것이다. 디코딩은 언어 모델이라는 방식에 기반한다. 잠깐 언어 모델이 무엇인지 설명해보자면 다음과 같다.</p><p>문장을 단어의 시퀀스로 보면 단어들에 기반해서 문장에 확률을 부여할 수 있다. 예를 들어 뉴럴넷은 위대하다라는 문장이 있다고 하자. 그렇다면,</p><p><span class=math>\[
P(\text{뉴럴넷}, \text{은}, \text{위대}, \text{하다})
\]</span></p><p>위와 같은 확률을 생각할 수 있다. 재미있는 것은 위의 확률을 다음과 같이 분해할 수 있다는 것이다.</p><p><span class=math>\[
P(\text{뉴럴넷})P(\text{은}|\text{뉴럴넷})P(\text{위대}|\text{뉴럴넷}, \text{은})P(\text{하다}|\text{뉴럴넷}, \text{은}, \text{위대})
\]</span></p><p>이 구조를 잘 보면 이전 단어들에 대한 다음 단어의 조건부 확률을 구하는 방식으로 전체 문장의 확률을 계산할 수 있다는 의미라는 것을 알 수 있다. 이를 디코더에 어떻게 적용할 수 있을까? 인코딩된 상태 $h_t$에 대해서 다음 한국어 단어의 확률을 계산하는 RNN을 학습시키면 상태 $h_t$에 대해 가장 확률이 높은 한국어 문장을 생성할 수 있다는 것이다. 이 문장이 곧 입력 영어 문장에 대한 번역 한국어 문장이 된다.</p><p>가변 길이 문장을 제한된 크기의 상태로 인코딩한다는 것이 사실상 불가능하기 때문에 실제로 사용되는 모형에서는 주의(Attention) 같은 메커니즘을 도입한다. 하지만 입력 문장을 어떤 상태로 인코딩해서, 인코딩된 상태를 다시 디코딩하는 방식으로 동작한다는 작동 방식은 기본적으로 동일하다. 인코더-디코더가 이런 식으로 연결된 모델을 Sequence to Sequence 모델이라고 부르며 GNMT는 사실상 이 모델을 충분히 크고 정교하게 만든 것이라고 볼 수 있다.</p><p><figure><img src=http://res.cloudinary.com/rosinality/image/upload/v1492734059/seq2seq/basic_seq2seq.png alt="Basic Seq2Seq"></figure>Sequence to Sequence (출처: <a href=https://www.tensorflow.org>https://www.tensorflow.org</a>)</p><p><a href=https://techcrunch.com/2016/11/22/googles-ai-translation-tool-seems-to-have-invented-its-own-secret-internal-language>Google’s AI translation tool seems to have invented its own secret internal language</a></p><p>그렇다면 위의 글에서 뉴럴넷이 내부 언어를 만들어냈다는 것의 의미는 무엇일까? 구글은 최근 GNMT를 단순히 영어-한국어 같은 두 언어 페어 사이의 번역 대신 하나의 모델로 영어, 일본어, 한국어 등 다양한 언어 사이의 번역이 가능하도록 확장했다. 논문은 [[<a href=https://arxiv.org/abs/1611.04558]]에>https://arxiv.org/abs/1611.04558]]에</a> 있다. 어떻게 했냐면 인코더에 입력을 주면서 어떤 언어로 번역해야 할지를 같이 입력으로 준 것이다. 예를 들면 "&lt;영어로> 뉴럴넷은 위대하다"라고 입력한 것이다. 그랬더니 다양한 언어 사이의 번역이 가능해졌다. 단순하지 않은가? 뉴럴넷 연구자인 Andrej Karpathy도 이 아이디어가 당황스러웠던 모양이다.</p><p><figure><img src=http://res.cloudinary.com/rosinality/image/upload/v1492734059/seq2seq/karpathy.png alt=Karpathy></figure>(출처: <a href=https://twitter.com/karpathy/status/798806811360960512>https://twitter.com/karpathy/status/798806811360960512</a>)</p><p>이런 식으로 뉴럴넷을 학습시켰더니 놀랍게도 일본어를 영어로 번역하는 방법을 학습하고, 영어를 한국어로 번역하는 방법을 학습했더니 일본어를 한국어로 번역하는 방법은 학습하지 않았는데도 번역할 수 있게 된 것이다. 대체 어떻게?</p><p>정확히 어떤 일이 벌어지고 있는지는 알기 어렵다. 하지만 몇가지 분석을 통해 벌어지고 있는 일을 추측해볼 수는 있다. 아마도 뉴럴넷은 구체적인 언어와는 별개로 의미가 유사하다면 유사한 방식으로 문장을 인코딩하는 것일 수 있다. 즉 일본어 문장 A의 의미를 $a$로 인코딩한 다음 $a$를 통해 영어로 번역하고, 영어 문장 A의 의미를 $a$로 인코딩한 다음 한국어로 번역한다면, 일본어 문장 A가 들어오면 스위치를 영어 대신 한국어로 바꾸어도 여전히 의미를 $a$로 인코딩한 다음 한국어로 번역할 수 있는 것이다. 그렇게 뉴럴넷은 아마도 언어에 공통된 내적 언어를 학습한 것일 수 있다.</p><p>그렇지만 반드시 이런 현상만 일어나는 것은 아니고 예컨대 포르투갈어 -> 영어, 영어 -> 스페인어에 대해서 학습된 모델이 포르투갈어 -> 스페인어에 대해선 다른 방식으로 인코딩하는 현상도 관찰되었다. 대체 뉴럴넷이 무슨 일을 하고 있는지 종잡을 수는 없다. 그렇지만 뭔가 희한한 일이 일어나고 있다는 건 분명해 보인다.</p><p>또 다양한 언어에 대해 학습시켰기 때문에 이런 것도 가능하다.</p><p><figure><img src=http://res.cloudinary.com/rosinality/image/upload/v1492734059/seq2seq/translate1.png alt="Mixing Translation 1"></figure></p><p>늘 잘 되는 건 아니라지만 입력 언어를 섞어도 번역을 해낼 수 있다는 것이다. 하다가 생각이 났는지 다음과 같은 장난(?)도 했다.</p><p><figure><img src=http://res.cloudinary.com/rosinality/image/upload/v1492734059/seq2seq/translate2.png alt="Mixing Translation 2"></figure></p><p>&lt;일본어로> 혹은 &lt;한국어로> 대신 0.3&lt;일본어로> + 0.7&lt;한국어로>라고 입력해서 번역 결과를 출력한 것이다. 저자들은 일본어와 한국어를 섞은 중간 언어가 튀어나오길 기대했으나 그렇지는 않아서 아쉽다(?)고 말하고 있다. 그렇지만 뭔가 뉘앙스의 차이는 있는 것 같고 그게 일본어와 한국어를 섞는 과정에서 발생한 것일 수도 있다.</p></div></div><div id=post-footer class="post-footer main-content-wrap"><div class=post-footer-tags><span class="text-color-light text-small"></span><br><a class="tag tag--primary tag--small" href=http://rosinality.github.io//tags/neural-network/>neural network</a>
<a class="tag tag--primary tag--small" href=http://rosinality.github.io//tags/rnn/>rnn</a></div><div class=post-actions-wrap><nav><ul class="post-actions post-action-nav"><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=/2017/04/p-%EA%B0%92/ data-tooltip=p-값><i class="fa fa-angle-left"></i><span class="hide-xs hide-sm text-small icon-ml"></span></a></li><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=/2017/04/%EC%83%81%EC%8B%9D%EA%B3%BC-%EC%82%AC%ED%9A%8C%ED%95%99%EC%A0%81-%EC%84%A4%EB%AA%85/ data-tooltip="상식과 사회학적 설명"><span class="hide-xs hide-sm text-small icon-mr"></span><i class="fa fa-angle-right"></i></a></li></ul></nav><ul class="post-actions post-action-share"><li class="post-action hide-lg hide-md hide-sm"><a class="post-action-btn btn btn--default btn-open-shareoptions" href=#btn-open-shareoptions><i class="fa fa-share-alt"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://plus.google.com/share?url=http%3a%2f%2frosinality.github.io%2f2017%2f04%2fsequence-to-sequence-%25EB%25AA%25A8%25ED%2598%2595%2f"><i class="fa fa-google-plus"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://www.facebook.com/sharer/sharer.php?u=http%3a%2f%2frosinality.github.io%2f2017%2f04%2fsequence-to-sequence-%25EB%25AA%25A8%25ED%2598%2595%2f"><i class="fa fa-facebook-official"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://twitter.com/intent/tweet?text=http%3a%2f%2frosinality.github.io%2f2017%2f04%2fsequence-to-sequence-%25EB%25AA%25A8%25ED%2598%2595%2f"><i class="fa fa-twitter"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#disqus_thread><i class="fa fa-comment-o"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#><i class="fa fa-list"></i></a></li></ul></div><div id=disqus_thread><noscript>Please enable JavaScript to view the <a href=//disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div></div></article><footer id=footer class=main-content-wrap><span class=copyrights>&copy; 2023 Kim Seonghyeon.</span></footer></div><div id=share-options-bar class=share-options-bar data-behavior=5><ul class=share-options><li class=share-option><a class=share-option-btn target=new href="https://plus.google.com/share?url=http%3a%2f%2frosinality.github.io%2f2017%2f04%2fsequence-to-sequence-%25EB%25AA%25A8%25ED%2598%2595%2f"><i class="fa fa-google-plus"></i><span></span></a></li><li class=share-option><a class=share-option-btn target=new href="https://www.facebook.com/sharer/sharer.php?u=http%3a%2f%2frosinality.github.io%2f2017%2f04%2fsequence-to-sequence-%25EB%25AA%25A8%25ED%2598%2595%2f"><i class="fa fa-facebook-official"></i><span></span></a></li><li class=share-option><a class=share-option-btn target=new href="https://twitter.com/intent/tweet?text=http%3a%2f%2frosinality.github.io%2f2017%2f04%2fsequence-to-sequence-%25EB%25AA%25A8%25ED%2598%2595%2f"><i class="fa fa-twitter"></i><span></span></a></li></ul></div><div id=share-options-mask class=share-options-mask></div></div><div id=about><div id=about-card><div id=about-btn-close><i class="fa fa-remove"></i></div><img id=about-card-picture src="//www.gravatar.com/avatar/63eec5e671fc734bde45cd43cc156abc?s=110" alt><h4 id=about-card-name>Kim Seonghyeon</h4><div id=about-card-bio>Machine learning enthusiast</div><div id=about-card-job><i class="fa fa-briefcase"></i><br>Graduate student in HCCLab at Seoul National University</div><div id=about-card-location><i class="fa fa-map-marker"></i><br>Korea, Republic of</div></div></div><div id=algolia-search-modal class=modal-container><div class=modal><div class=modal-header><span class=close-button><i class="fa fa-close"></i></span><a href=https://algolia.com target=_blank class="searchby-algolia text-color-light link-unstyled"><span class="searchby-algolia-text text-color-light text-small">by</span>
<img class=searchby-algolia-logo src=https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg></a>
<i class="search-icon fa fa-search"></i><form id=algolia-search-form><input type=text id=algolia-search-input name=search class="form-control input--large search-input" placeholder></form></div><div class=modal-body><div class="no-result text-color-light text-center"></div><div class=results><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/01/ocr-%ED%9A%8C%EA%B3%A0/><h3 class=media-heading>OCR 회고</h3></a><span class=media-meta><span class="media-date text-small">Jan 1, 2023</span></span><div class="media-content hide-xs font-merryweather">타이틀 커버 이미지 출처: https://www.behance.net/gallery/6146939/OCR-A-Poster/modules/152114859 4년 동안 몰두했던 OCR이라는 주제를 마무리하게 되면서 으레 그래왔듯 회고를 남겨본다. 이랬더라면 어땠을까 같은 소소한 소회보다는</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/post/><h3 class=media-heading>Posts</h3></a><span class=media-meta><span class="media-date text-small">Jan 1, 2023</span></span><div class="media-content hide-xs font-merryweather"></div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-7/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 7</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-6/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 6</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-5/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 5</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-4/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 4</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-3/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 3</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-2/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 2</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-1/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 1</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2021/05/%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%97%90%EC%84%9C-%EC%84%A4%EC%A0%95-%EA%B4%80%EB%A6%AC%ED%95%98%EA%B8%B0/><h3 class=media-heading>머신 러닝 시스템에서 설정 관리하기</h3></a><span class=media-meta><span class="media-date text-small">May 5, 2021</span></span><div class="media-content hide-xs font-merryweather">머신 러닝 코드, 특히 실험적 목적이 강한 코드에서 가장 중요한 문제 중 하나가 설정을 관리하는 것이라고 본다. 머신 러닝 모델에는 수많은 하이퍼파라미터가 존재하고 그</div></div><div style=clear:both></div><hr></div></div></div><div class=modal-footer><p class="results-count text-medium" data-message-zero data-message-one data-message-other>62 posts found</p></div></div></div><div id=cover style=background-image:url(http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/stair.jpg)></div><script>(function(d){var config={kitId:'vld6lxf',scriptTimeout:3000,async:true},h=d.documentElement,t=setTimeout(function(){h.className=h.className.replace(/\bwf-loading\b/g,"")+" wf-inactive";},config.scriptTimeout),tk=d.createElement("script"),f=false,s=d.getElementsByTagName("script")[0],a;h.className+=" wf-loading";tk.src='https://use.typekit.net/'+config.kitId+'.js';tk.async=true;tk.onload=tk.onreadystatechange=function(){a=this.readyState;if(f||a&&a!="complete"&&a!="loaded")return;f=true;clearTimeout(t);try{Typekit.load(config)}catch(e){}};s.parentNode.insertBefore(tk,s)})(document);</script><script src=//cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.js></script><script type=text/javascript src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type=text/x-mathjax-config>
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']],
    processEscapes: true,
    processEnvironments: true,
    preview: "none",
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script><script src=/js/script-wl33z0n6ocaypepiqrazthtivfrliqijej4rq8ek8gvrv1awftmgjuv8k4zc.min.js></script><script>$(document).ready(function(){hljs.configure({classPrefix:'',useBR:false});$('pre.code-highlight').each(function(i,block){var code="";hljs.highlightAuto(block.innerText).value.split(/\r\n|\r|\n/).forEach(function(line){code+="<span class=\"line\">"+line+"</span><br>";});if(code.length>0){block.innerHTML=code;}});$('pre > code').each(function(i,block){$(this).addClass('codeblock');hljs.highlightBlock(block);});});</script><script>var disqus_config=function(){this.page.url='http:\/\/rosinality.github.io\/2017\/04\/sequence-to-sequence-%EB%AA%A8%ED%98%95\/';this.page.identifier='\/2017\/04\/sequence-to-sequence-%EB%AA%A8%ED%98%95\/'};(function(){if(window.location.hostname=="localhost"){return;}
var d=document,s=d.createElement('script');var disqus_shortname='rosinality';s.src='//'+disqus_shortname+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script></body></html>