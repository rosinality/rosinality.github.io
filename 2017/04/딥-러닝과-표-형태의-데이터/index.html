<!doctype html><html lang=ko-kr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.73.0"><meta name=theme content="Tranquilpeak 0.3.1-BETA"><title>딥 러닝과 표 형태의 데이터</title><meta name=author content="Kim Seonghyeon"><meta name=keywords content="deep learning,data analysis,tabular data,machine learning,machine learning,deep learning,social science"><link rel=icon href=/favicon.png><meta name=description content="전통적 통계적 모델링의 대상인 표 형태의 데이터tabular data에 대해서는 딥 러닝이 힘을 못 쓴다(?)는 말을 흔히 한다. 사실 이건 딥 러닝이 이미지나 텍스"><meta property="og:description" content="전통적 통계적 모델링의 대상인 표 형태의 데이터tabular data에 대해서는 딥 러닝이 힘을 못 쓴다(?)는 말을 흔히 한다. 사실 이건 딥 러닝이 이미지나 텍스"><meta property="og:type" content="blog"><meta property="og:title" content="딥 러닝과 표 형태의 데이터"><meta property="og:url" content="/2017/04/%EB%94%A5-%EB%9F%AC%EB%8B%9D%EA%B3%BC-%ED%91%9C-%ED%98%95%ED%83%9C%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0/"><meta property="og:site_name" content="Nondifferentiable Log"><meta name=twitter:card content="summary"><meta name=twitter:title content="Nondifferentiable Log"><meta name=twitter:description content="전통적 통계적 모델링의 대상인 표 형태의 데이터tabular data에 대해서는 딥 러닝이 힘을 못 쓴다(?)는 말을 흔히 한다. 사실 이건 딥 러닝이 이미지나 텍스"><meta name=twitter:creator content="@rosinality"><meta property="og:image" content="//www.gravatar.com/avatar/63eec5e671fc734bde45cd43cc156abc?s=640"><meta property="og:image" content="http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/table.jpg"><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css><link rel=stylesheet href=/css/style-u6mk0ojoywresbx8iepslrmmhl4stuhrsxuwhkpwrkrx7mryjcaimasnk4pi.min.css></head><body><div id=blog><header id=header data-behavior=5><i id=btn-open-sidebar class="fa fa-lg fa-bars"></i><div class=header-title><a class=header-title-link href=/>Nondifferentiable Log</a></div></header><nav id=sidebar data-behavior=5><div class=sidebar-container><div class=sidebar-profile><a href=/#about><img class=sidebar-profile-picture src="//www.gravatar.com/avatar/63eec5e671fc734bde45cd43cc156abc?s=110" alt></a><h4 class=sidebar-profile-name>Kim Seonghyeon</h4><h5 class=sidebar-profile-bio>Machine learning enthusiast</h5></div><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=/categories><i class="sidebar-button-icon fa fa-lg fa-bookmark"></i><span class=sidebar-button-desc>Categories</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/tags><i class="sidebar-button-icon fa fa-lg fa-tags"></i><span class=sidebar-button-desc>Tags</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/archives><i class="sidebar-button-icon fa fa-lg fa-archive"></i><span class=sidebar-button-desc>Archives</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/#about><i class="sidebar-button-icon fa fa-lg fa-question"></i><span class=sidebar-button-desc>About</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/><i class="sidebar-button-icon fa fa-lg fa-home"></i><span class=sidebar-button-desc>Home</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://github.com/rosinality target=_blank><i class="sidebar-button-icon fa fa-lg fa-github"></i><span class=sidebar-button-desc>GitHub</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=/index.xml><i class="sidebar-button-icon fa fa-lg fa-rss"></i><span class=sidebar-button-desc>RSS</span></a></li></ul></div></nav><div class="post-header-cover
text-left
post-header-cover--partial" style=background-image:url(http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/table.jpg) data-behavior=5></div><div id=main data-behavior=5 class="hasCover
hasCoverMetaIn"><article class=post itemscope itemtype=http://schema.org/BlogPosting><div class="post-header main-content-wrap text-left"><h1 class=post-title itemprop=headline>딥 러닝과 표 형태의 데이터</h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2017-04-21T16:11:42+09:00>April 21, 2017</time>
<span></span><a class=category-link href=/categories/thoughts>thoughts</a></div></div><div class="post-content markdown" itemprop=articleBody><div class=main-content-wrap><p>전통적 통계적 모델링의 대상인 표 형태의 데이터tabular data에 대해서는 딥 러닝이 힘을 못 쓴다(?)는 말을 흔히 한다. 사실 이건 딥 러닝이 이미지나 텍스트 처리에서 워낙 무지막지한 성능을 보여주기 때문에 그에 비해서 덜 인상적이라는 의미가 크고, 비정형이 아닌 정형의, 표 형태의 데이터에 대해서 당연히 그럭저럭 괜찮은 성능을 보여주는 경우가 많다. 다만 앙상블 트리 같은 모형들이 그런 데이터에 대해서는 더 나은 성능을 보여주는 경우가 많다. 아니 보면 거의 대부분인 듯 싶다.</p><p>왜 그런가? 여기에 대해 이론적 분석을 한 연구가 있는지는 모르겠다. 어쩌면 비교적 저차원의 함수 추정에는 앙상블 트리 모형 같은 모형이 더 적합한 것일지도 모른다. 그러나 이미지나 텍스트 같은 고차원의 괴상한 데이터에는 그런 괴상함을 상대할 수 있는 가정들을 반영할 수 있고 레이어의 중첩을 통해 지수적인 표현력 증가를 얻을 수 있는 뉴럴넷 혹은 딥 러닝이 적합한, 혹은 유일하게 가능한 방법인 것일 수도 있다.</p><p>위와 같은 사실을 다르게 말하면 딥 러닝이 보여주는 강력한 예측 능력이 기존의 통계적 접근에 위협이 된다면, 당연히 기존의 통계적 모델링이 일반적으로 다뤄왔던 데이터에 대해 딥 러닝 수준의 예측 능력을 보여주는 다른 머신 러닝 알고리즘 또한 위협적이라고 해야 할 것이다. 그런데 그런 머신 러닝 알고리즘은 딥 러닝이 2000년대 중반 이후 본격적으로 주목을 받기 이전부터 주목을 받아왔는데, 그런 알고리즘들이 지금까지 통계적 모델링에 큰 위협이 되지 않았다면 딥 러닝도 통계적 모델링에 큰 위협이 되지 않을 것이라고 봐도 좋을 것이다.</p></div></div><div id=post-footer class="post-footer main-content-wrap"><div class=post-footer-tags><span class="text-color-light text-small"></span><br><a class="tag tag--primary tag--small" href=http://rosinality.github.io//tags/deep-learning/>deep learning</a>
<a class="tag tag--primary tag--small" href=http://rosinality.github.io//tags/data-analysis/>data analysis</a>
<a class="tag tag--primary tag--small" href=http://rosinality.github.io//tags/tabular-data/>tabular data</a>
<a class="tag tag--primary tag--small" href=http://rosinality.github.io//tags/machine-learning/>machine learning</a></div><div class=post-actions-wrap><nav><ul class="post-actions post-action-nav"><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=/2017/04/%EB%B9%84%ED%8B%80%EC%A6%88%EA%B0%80-%EC%84%B1%EA%B3%B5%ED%95%9C-%EC%9D%B4%EC%9C%A0/ data-tooltip="비틀즈가 성공한 이유"><i class="fa fa-angle-left"></i><span class="hide-xs hide-sm text-small icon-ml"></span></a></li><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=/2017/04/%EA%B2%BD%ED%97%98%EC%A0%81-%EC%9C%84%ED%97%98-%EC%B5%9C%EC%86%8C%ED%99%94/ data-tooltip="경험적 위험 최소화"><span class="hide-xs hide-sm text-small icon-mr"></span><i class="fa fa-angle-right"></i></a></li></ul></nav><ul class="post-actions post-action-share"><li class="post-action hide-lg hide-md hide-sm"><a class="post-action-btn btn btn--default btn-open-shareoptions" href=#btn-open-shareoptions><i class="fa fa-share-alt"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://plus.google.com/share?url=http%3a%2f%2frosinality.github.io%2f2017%2f04%2f%25EB%2594%25A5-%25EB%259F%25AC%25EB%258B%259D%25EA%25B3%25BC-%25ED%2591%259C-%25ED%2598%2595%25ED%2583%259C%25EC%259D%2598-%25EB%258D%25B0%25EC%259D%25B4%25ED%2584%25B0%2f"><i class="fa fa-google-plus"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://www.facebook.com/sharer/sharer.php?u=http%3a%2f%2frosinality.github.io%2f2017%2f04%2f%25EB%2594%25A5-%25EB%259F%25AC%25EB%258B%259D%25EA%25B3%25BC-%25ED%2591%259C-%25ED%2598%2595%25ED%2583%259C%25EC%259D%2598-%25EB%258D%25B0%25EC%259D%25B4%25ED%2584%25B0%2f"><i class="fa fa-facebook-official"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://twitter.com/intent/tweet?text=http%3a%2f%2frosinality.github.io%2f2017%2f04%2f%25EB%2594%25A5-%25EB%259F%25AC%25EB%258B%259D%25EA%25B3%25BC-%25ED%2591%259C-%25ED%2598%2595%25ED%2583%259C%25EC%259D%2598-%25EB%258D%25B0%25EC%259D%25B4%25ED%2584%25B0%2f"><i class="fa fa-twitter"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#disqus_thread><i class="fa fa-comment-o"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#><i class="fa fa-list"></i></a></li></ul></div><div id=disqus_thread><noscript>Please enable JavaScript to view the <a href=//disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div></div></article><footer id=footer class=main-content-wrap><span class=copyrights>&copy; 2024 Kim Seonghyeon.</span></footer></div><div id=share-options-bar class=share-options-bar data-behavior=5><ul class=share-options><li class=share-option><a class=share-option-btn target=new href="https://plus.google.com/share?url=http%3a%2f%2frosinality.github.io%2f2017%2f04%2f%25EB%2594%25A5-%25EB%259F%25AC%25EB%258B%259D%25EA%25B3%25BC-%25ED%2591%259C-%25ED%2598%2595%25ED%2583%259C%25EC%259D%2598-%25EB%258D%25B0%25EC%259D%25B4%25ED%2584%25B0%2f"><i class="fa fa-google-plus"></i><span></span></a></li><li class=share-option><a class=share-option-btn target=new href="https://www.facebook.com/sharer/sharer.php?u=http%3a%2f%2frosinality.github.io%2f2017%2f04%2f%25EB%2594%25A5-%25EB%259F%25AC%25EB%258B%259D%25EA%25B3%25BC-%25ED%2591%259C-%25ED%2598%2595%25ED%2583%259C%25EC%259D%2598-%25EB%258D%25B0%25EC%259D%25B4%25ED%2584%25B0%2f"><i class="fa fa-facebook-official"></i><span></span></a></li><li class=share-option><a class=share-option-btn target=new href="https://twitter.com/intent/tweet?text=http%3a%2f%2frosinality.github.io%2f2017%2f04%2f%25EB%2594%25A5-%25EB%259F%25AC%25EB%258B%259D%25EA%25B3%25BC-%25ED%2591%259C-%25ED%2598%2595%25ED%2583%259C%25EC%259D%2598-%25EB%258D%25B0%25EC%259D%25B4%25ED%2584%25B0%2f"><i class="fa fa-twitter"></i><span></span></a></li></ul></div><div id=share-options-mask class=share-options-mask></div></div><div id=about><div id=about-card><div id=about-btn-close><i class="fa fa-remove"></i></div><img id=about-card-picture src="//www.gravatar.com/avatar/63eec5e671fc734bde45cd43cc156abc?s=110" alt><h4 id=about-card-name>Kim Seonghyeon</h4><div id=about-card-bio>Machine learning enthusiast</div><div id=about-card-job><i class="fa fa-briefcase"></i><br>Graduate student in HCCLab at Seoul National University</div><div id=about-card-location><i class="fa fa-map-marker"></i><br>Korea, Republic of</div></div></div><div id=algolia-search-modal class=modal-container><div class=modal><div class=modal-header><span class=close-button><i class="fa fa-close"></i></span><a href=https://algolia.com target=_blank class="searchby-algolia text-color-light link-unstyled"><span class="searchby-algolia-text text-color-light text-small">by</span>
<img class=searchby-algolia-logo src=https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg></a>
<i class="search-icon fa fa-search"></i><form id=algolia-search-form><input type=text id=algolia-search-input name=search class="form-control input--large search-input" placeholder></form></div><div class=modal-body><div class="no-result text-color-light text-center"></div><div class=results><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/post/><h3 class=media-heading>Posts</h3></a><span class=media-meta><span class="media-date text-small">Jun 6, 2024</span></span><div class="media-content hide-xs font-merryweather"></div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2024/06/preliminary-explorations-on-ul2-and-second-order-optimizers/><h3 class=media-heading>Preliminary Explorations on UL2 and Second-order Optimizers</h3></a><span class=media-meta><span class="media-date text-small">Jun 6, 2024</span></span><div class="media-content hide-xs font-merryweather">In the field of large language models, the most important recipes to cook the model is not opened to publics. Model architecture itself is quite well-known because many state-of-the-art models are now open weights, and in many cases we find it is a boringly simple vanilla transformers. But for datasets and training objectives it is not well known, and many LLM builders deliberately obfuscates the details of these two. And,</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/11/%EC%98%A4%ED%8E%9C%ED%95%98%EC%9D%B4%EB%A8%B8/><h3 class=media-heading>오펜하이머</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2023</span></span><div class="media-content hide-xs font-merryweather">영화의 가장 중요한 질문. 청문회에서 오펜하이머가 본 환영. 왜 지금 후회하고 반대할 일들을 그 당시에는 예측하지 못했는가? 아니 사실 알고 있지 않았는가? 그런데 알</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/11/%EA%B7%B8%EB%8C%80%EB%93%A4%EC%9D%80-%EC%96%B4%EB%96%BB%EA%B2%8C-%EC%82%B4-%EA%B2%83%EC%9D%B8%EA%B0%80/><h3 class=media-heading>그대들은 어떻게 살 것인가</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2023</span></span><div class="media-content hide-xs font-merryweather">이것은 상징이라고 이렇게까지 말하는 영화는 그리 많지 않을 듯 싶다. 상징이라는 것은 분명한데 이것이 무엇의 상징인지, 그리고 그 상징들이 모여서 어떤 한 가지를 말하</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/11/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8-%EB%AA%A8%EB%8D%B8-%EC%84%A0%ED%83%9D%EC%9D%98-%EA%B8%B0%EC%9B%90%EC%97%90-%EB%8C%80%ED%95%98%EC%97%AC/><h3 class=media-heading>트랜스포머 모델 선택의 기원에 대하여</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2023</span></span><div class="media-content hide-xs font-merryweather">트랜스포머는 이제 너무나 유명한 모델이고 아마 딥 러닝 모델 중에서 트랜스포머보다 많은 설명이 작성된 모델 또한 없을 것 같다. 그런 상황에서 트랜스포머의 디자인에 대</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/07/constitutional-ai/><h3 class=media-heading>Constitutional AI</h3></a><span class=media-meta><span class="media-date text-small">Jul 7, 2023</span></span><div class="media-content hide-xs font-merryweather">Helpful & Harmless Agent AI 모델의 정렬(Alignment)이라고 이야기할 때 흔히 나오는 Helpfulness와 Harmlessness는 어떤 의미인가? 이는 정의</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/02/%EC%9D%B4%EB%AF%B8%EC%A7%80%EC%99%80-%ED%85%8D%EC%8A%A4%ED%8A%B8-%EC%83%9D%EC%84%B1-%EB%AA%A8%EB%8D%B8%EC%97%90-%EB%8C%80%ED%95%B4/><h3 class=media-heading>이미지와 텍스트 생성 모델에 대해</h3></a><span class=media-meta><span class="media-date text-small">Feb 2, 2023</span></span><div class="media-content hide-xs font-merryweather">이미지 생성 하면 Style GAN이었던 시절에도 일러스트 생성 등은 오타쿠적 인기가 있는 주제였다. 문제의 Danbooru 데이터셋 같은 경우에도 그 시점에 이미 만들어진 데이터셋이었</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/02/%EC%96%B8%EC%96%B4%EC%9D%98-%EC%86%90%EC%8B%A4-%EC%95%95%EC%B6%95%EC%97%90-%EB%8C%80%ED%95%98%EC%97%AC/><h3 class=media-heading>언어의 손실 압축에 대하여</h3></a><span class=media-meta><span class="media-date text-small">Feb 2, 2023</span></span><div class="media-content hide-xs font-merryweather">https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web LM을 다음 단어를 예측할 뿐이라거나 학습 데이터를 기억할 뿐이라는 식으로 묘사하는 것은 폄하를 위한 언어이지 LM의 실체나 실제 한계에 대해서 논하기에 적절한 방</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/01/ocr-%ED%9A%8C%EA%B3%A0/><h3 class=media-heading>OCR 회고</h3></a><span class=media-meta><span class="media-date text-small">Jan 1, 2023</span></span><div class="media-content hide-xs font-merryweather">타이틀 커버 이미지 출처: https://www.behance.net/gallery/6146939/OCR-A-Poster/modules/152114859 4년 동안 몰두했던 OCR이라는 주제를 마무리하게 되면서 으레 그래왔듯 회고를 남겨본다. 이랬더라면 어땠을까 같은 소소한 소회보다는</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-7/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 7</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div></div></div><div class=modal-footer><p class="results-count text-medium" data-message-zero data-message-one data-message-other>70 posts found</p></div></div></div><div id=cover style=background-image:url(http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/stair.jpg)></div><script>(function(d){var config={kitId:'vld6lxf',scriptTimeout:3000,async:true},h=d.documentElement,t=setTimeout(function(){h.className=h.className.replace(/\bwf-loading\b/g,"")+" wf-inactive";},config.scriptTimeout),tk=d.createElement("script"),f=false,s=d.getElementsByTagName("script")[0],a;h.className+=" wf-loading";tk.src='https://use.typekit.net/'+config.kitId+'.js';tk.async=true;tk.onload=tk.onreadystatechange=function(){a=this.readyState;if(f||a&&a!="complete"&&a!="loaded")return;f=true;clearTimeout(t);try{Typekit.load(config)}catch(e){}};s.parentNode.insertBefore(tk,s)})(document);</script><script src=//cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.js></script><script src=/js/script-wl33z0n6ocaypepiqrazthtivfrliqijej4rq8ek8gvrv1awftmgjuv8k4zc.min.js></script><script>$(document).ready(function(){hljs.configure({classPrefix:'',useBR:false});$('pre.code-highlight').each(function(i,block){var code="";hljs.highlightAuto(block.innerText).value.split(/\r\n|\r|\n/).forEach(function(line){code+="<span class=\"line\">"+line+"</span><br>";});if(code.length>0){block.innerHTML=code;}});$('pre > code').each(function(i,block){$(this).addClass('codeblock');hljs.highlightBlock(block);});});</script><script>var disqus_config=function(){this.page.url='http:\/\/rosinality.github.io\/2017\/04\/%EB%94%A5-%EB%9F%AC%EB%8B%9D%EA%B3%BC-%ED%91%9C-%ED%98%95%ED%83%9C%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0\/';this.page.identifier='\/2017\/04\/%EB%94%A5-%EB%9F%AC%EB%8B%9D%EA%B3%BC-%ED%91%9C-%ED%98%95%ED%83%9C%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0\/'};(function(){if(window.location.hostname=="localhost"){return;}
var d=document,s=d.createElement('script');var disqus_shortname='rosinality';s.src='//'+disqus_shortname+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script></body></html>