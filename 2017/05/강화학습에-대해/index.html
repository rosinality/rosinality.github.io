<!doctype html><html lang=ko-kr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.73.0"><meta name=theme content="Tranquilpeak 0.3.1-BETA"><title>강화학습에 대해</title><meta name=author content="Kim Seonghyeon"><meta name=keywords content="reinforcement learning,behaviorism,mental model,cognitive psychology,machine learning,deep learning,social science"><link rel=icon href=/favicon.png><meta name=description content="지금의 강화학습은 행동주의 심리학의 조작적 조건 형성과 많이 닮아있다. 사실 강화Reinforcement라는 단어를 쓰는 것 자체가 행동주의적 심리학의 언어"><meta property="og:description" content="지금의 강화학습은 행동주의 심리학의 조작적 조건 형성과 많이 닮아있다. 사실 강화Reinforcement라는 단어를 쓰는 것 자체가 행동주의적 심리학의 언어"><meta property="og:type" content="blog"><meta property="og:title" content="강화학습에 대해"><meta property="og:url" content="/2017/05/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%EC%97%90-%EB%8C%80%ED%95%B4/"><meta property="og:site_name" content="Nondifferentiable Log"><meta name=twitter:card content="summary"><meta name=twitter:title content="Nondifferentiable Log"><meta name=twitter:description content="지금의 강화학습은 행동주의 심리학의 조작적 조건 형성과 많이 닮아있다. 사실 강화Reinforcement라는 단어를 쓰는 것 자체가 행동주의적 심리학의 언어"><meta name=twitter:creator content="@rosinality"><meta property="og:image" content="//www.gravatar.com/avatar/63eec5e671fc734bde45cd43cc156abc?s=640"><meta property="og:image" content="http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/rat"><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css><link rel=stylesheet href=/css/style-u6mk0ojoywresbx8iepslrmmhl4stuhrsxuwhkpwrkrx7mryjcaimasnk4pi.min.css></head><body><div id=blog><header id=header data-behavior=5><i id=btn-open-sidebar class="fa fa-lg fa-bars"></i><div class=header-title><a class=header-title-link href=/>Nondifferentiable Log</a></div></header><nav id=sidebar data-behavior=5><div class=sidebar-container><div class=sidebar-profile><a href=/#about><img class=sidebar-profile-picture src="//www.gravatar.com/avatar/63eec5e671fc734bde45cd43cc156abc?s=110" alt></a><h4 class=sidebar-profile-name>Kim Seonghyeon</h4><h5 class=sidebar-profile-bio>Machine learning enthusiast</h5></div><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=/categories><i class="sidebar-button-icon fa fa-lg fa-bookmark"></i><span class=sidebar-button-desc>Categories</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/tags><i class="sidebar-button-icon fa fa-lg fa-tags"></i><span class=sidebar-button-desc>Tags</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/archives><i class="sidebar-button-icon fa fa-lg fa-archive"></i><span class=sidebar-button-desc>Archives</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/#about><i class="sidebar-button-icon fa fa-lg fa-question"></i><span class=sidebar-button-desc>About</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/><i class="sidebar-button-icon fa fa-lg fa-home"></i><span class=sidebar-button-desc>Home</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://github.com/rosinality target=_blank><i class="sidebar-button-icon fa fa-lg fa-github"></i><span class=sidebar-button-desc>GitHub</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=/index.xml><i class="sidebar-button-icon fa fa-lg fa-rss"></i><span class=sidebar-button-desc>RSS</span></a></li></ul></div></nav><div class="post-header-cover
text-left
post-header-cover--partial" style=background-image:url(http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/rat) data-behavior=5></div><div id=main data-behavior=5 class="hasCover
hasCoverMetaIn"><article class=post itemscope itemtype=http://schema.org/BlogPosting><div class="post-header main-content-wrap text-left"><h1 class=post-title itemprop=headline>강화학습에 대해</h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2017-05-21T00:01:52+09:00>May 21, 2017</time>
<span></span><a class=category-link href=/categories/thoughts>thoughts</a></div></div><div class="post-content markdown" itemprop=articleBody><div class=main-content-wrap><p>지금의 강화학습은 행동주의 심리학의 조작적 조건 형성과 많이 닮아있다. 사실 강화Reinforcement라는 단어를 쓰는 것 자체가 행동주의적 심리학의 언어와 맞닿아 있는 것이라고 볼 수도 있다.</p><p>조작적 조건형성이라는 것 자체는 복잡한 개념은 아니고 강화와 처벌로 동물의 행동의 빈도를 높이거나 낮추는 것이다. 그러니까 레버를 누르면 먹이가 나오는 상자에 쥐를 넣어서 레버를 누르는 행동을 하게 한다거나 하는 것이 그 대표적인 사례다. 워낙 강력한 개념이다보니 많은 곳에서 아주 자연스럽게 쓰이고 있는 원리이기도 하다. 하기를 원하는 행동은 보상을 줘서 더 자주 하게 하고, 하기를 원하지 않는 행동은 처벌을 줘서 하지 않게 만든다는 것이니까 말이다.</p><p>조작적 조건형성이 얼마나 강력한가 하면. 유명한 사례이긴 하지만 조작적 조건형성의 대부 스키너는 비둘기가 탁구를 칠 수 있도록 학습을 시키기도 했다.</p><p><a href="https://www.youtube.com/watch?v=vGazyH6fQQ4">https://www.youtube.com/watch?v=vGazyH6fQQ4</a></p><p>그런데 이런 복잡한 행동을 하게 하는데는 난점이 한 가지 있다. 어떤 행동을 하면 보상을 줘야 하는데 동물이 보통 그런 행동을 할 일이 없다는 것이다. 레버가 뭔지도 모르고 레버를 누르면 무슨 일이 생기는지를 이해할 수도 없는 쥐가 어떻게 레버를 누르게 한다는 말인가? 정말 오랜 시간을 두고 보면 우연히 레버를 누르는 경우가 발생할 수 있다. 보상을 주기 위해서는 하염없이 그걸 기다려야 하는 것이다. 거기다 한 번으로 학습하기는 어려우니 다시 그런 상황이 우연히 발생하기를 기다려야 한다. 이래서는 너무 오래 걸린다.</p><p>다르게 말하면, 행위자가 환경의 메커니즘에 대해 전혀 이해하지 못하고 있는 상황에서는 그저 여러 방식으로 탐색해보는 수밖에 없다는 것이다. 그리고 이게 강화학습에서 흔히 하는 일이기도 하다. 여러 행동들을 해보면서 (거의 우연하게) 괜찮은 행동을 할 수 있기를 기대하기.</p><p>그래서 조작적 조건형성에서는 행동 조성Shaping이라는 방법을 흔히 쓴다. 쥐가 레버를 누르게 하는 것이 목표라면 그 목표까지 가는 과정을 단계별로 분해해서 단계적으로 강화해나가는 것이다. 우선 쥐가 레버 근처로 가면 보상을 주고, 그 다음에는 쥐가 레버 근처에 머무르면 보상을 주고, 레버를 건드리면 보상을 주고, 마침내 레버를 누르면 보상을 주는 방식으로 목표의 중간 단계 행동의 확률을 높여서 학습에 걸리는 시간을 단축하는 것이다.</p><p>그렇지만 이런 단계적 접근이 강화학습의 입장에서 우아한 접근이라고 보기는 힘들 것이다. 무엇보다 고차원적인 행동을 할 수 있는 것이 목표라면(예: 스타2를 플레이하기) 그 목표의 중간 단계들을 적절하게 분해하는 것 자체도 어려운 일이라고 할 수 있다. 내게 주어진 정보를 가지고 상대의 행동을 파악해서 그에 맞게 대응하는 전술을 사용한다라는 추론과 판단, 의사결정이 복합된 목표의 중간 단계를 분석한다고 생각해보자.</p><p>그러나 행위자에게 환경에 대한 인지적 이해가 있다면 굳이 단계적으로 행동을 형성해야할 필요는 없다. 환경에 대한 인지적 모형을 가지고 있다면 벽 뒤에 있는 문의 손잡이를 돌려 연다고 하는 식의 과제를 수행한다고 할 때도 한참 탐색할 필요가 없다. 공간적으로 가능한 행위들을 앉은 상태에서도 추론해 계획할 수 있고 기존의 문을 열었던 방식을 전이Transfer시켜 문을 간단히 열 수 있다.</p><p>그렇다면 강화학습에 필요한 몇 가지 도구들을 생각해볼 수 있다. Yann LeCun이 강조하는 것과 같은 세상에 대한 멘탈 모델, 그러니까 세계의 다음 상태에 대한 예측을 수행하는 모델(LeCun은 unsupervised model이 이런 역할을 할 수 있다고 보는 것 같다)과 그러한 모델을 새로운 과제에 전이시키는 Transfer learning, 그리고 세상에 대한 모델을 맨땅에서부터 만들 필요가 없도록 단서를 주는 Imitation learning. 신석기시대가 시작된 이후로도 인류가 바퀴를 발명하기까지는 수천 년의 시간이 필요했다. 이러한 도구 없이 알고리즘이 매번 바퀴를 바닥에서부터 재발명해야 한다면 복잡한 문제를 해결하기는 어려울 것이다. 혹은 웬만해선 그 복잡한 문제를 해결할 수 있을 정도로 상태 공간을 탐색하기에는 시간이 부족할 것이다.</p></div></div><div id=post-footer class="post-footer main-content-wrap"><div class=post-footer-tags><span class="text-color-light text-small"></span><br><a class="tag tag--primary tag--small" href=http://rosinality.github.io//tags/reinforcement-learning/>reinforcement learning</a>
<a class="tag tag--primary tag--small" href=http://rosinality.github.io//tags/behaviorism/>behaviorism</a>
<a class="tag tag--primary tag--small" href=http://rosinality.github.io//tags/mental-model/>mental model</a>
<a class="tag tag--primary tag--small" href=http://rosinality.github.io//tags/cognitive-psychology/>cognitive psychology</a></div><div class=post-actions-wrap><nav><ul class="post-actions post-action-nav"><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=/2017/06/%EC%98%A5%EC%9E%90/ data-tooltip=옥자><i class="fa fa-angle-left"></i><span class="hide-xs hide-sm text-small icon-ml"></span></a></li><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=/2017/05/%EC%9E%90%EC%9C%A0%EC%A3%BC%EC%9D%98%EC%A0%81-%EC%A0%95%EC%B9%98%EC%9D%98-%EC%9D%B4%EC%83%81/ data-tooltip="자유주의적 정치의 이상"><span class="hide-xs hide-sm text-small icon-mr"></span><i class="fa fa-angle-right"></i></a></li></ul></nav><ul class="post-actions post-action-share"><li class="post-action hide-lg hide-md hide-sm"><a class="post-action-btn btn btn--default btn-open-shareoptions" href=#btn-open-shareoptions><i class="fa fa-share-alt"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://plus.google.com/share?url=http%3a%2f%2frosinality.github.io%2f2017%2f05%2f%25EA%25B0%2595%25ED%2599%2594%25ED%2595%2599%25EC%258A%25B5%25EC%2597%2590-%25EB%258C%2580%25ED%2595%25B4%2f"><i class="fa fa-google-plus"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://www.facebook.com/sharer/sharer.php?u=http%3a%2f%2frosinality.github.io%2f2017%2f05%2f%25EA%25B0%2595%25ED%2599%2594%25ED%2595%2599%25EC%258A%25B5%25EC%2597%2590-%25EB%258C%2580%25ED%2595%25B4%2f"><i class="fa fa-facebook-official"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://twitter.com/intent/tweet?text=http%3a%2f%2frosinality.github.io%2f2017%2f05%2f%25EA%25B0%2595%25ED%2599%2594%25ED%2595%2599%25EC%258A%25B5%25EC%2597%2590-%25EB%258C%2580%25ED%2595%25B4%2f"><i class="fa fa-twitter"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#disqus_thread><i class="fa fa-comment-o"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#><i class="fa fa-list"></i></a></li></ul></div><div id=disqus_thread><noscript>Please enable JavaScript to view the <a href=//disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div></div></article><footer id=footer class=main-content-wrap><span class=copyrights>&copy; 2023 Kim Seonghyeon.</span></footer></div><div id=share-options-bar class=share-options-bar data-behavior=5><ul class=share-options><li class=share-option><a class=share-option-btn target=new href="https://plus.google.com/share?url=http%3a%2f%2frosinality.github.io%2f2017%2f05%2f%25EA%25B0%2595%25ED%2599%2594%25ED%2595%2599%25EC%258A%25B5%25EC%2597%2590-%25EB%258C%2580%25ED%2595%25B4%2f"><i class="fa fa-google-plus"></i><span></span></a></li><li class=share-option><a class=share-option-btn target=new href="https://www.facebook.com/sharer/sharer.php?u=http%3a%2f%2frosinality.github.io%2f2017%2f05%2f%25EA%25B0%2595%25ED%2599%2594%25ED%2595%2599%25EC%258A%25B5%25EC%2597%2590-%25EB%258C%2580%25ED%2595%25B4%2f"><i class="fa fa-facebook-official"></i><span></span></a></li><li class=share-option><a class=share-option-btn target=new href="https://twitter.com/intent/tweet?text=http%3a%2f%2frosinality.github.io%2f2017%2f05%2f%25EA%25B0%2595%25ED%2599%2594%25ED%2595%2599%25EC%258A%25B5%25EC%2597%2590-%25EB%258C%2580%25ED%2595%25B4%2f"><i class="fa fa-twitter"></i><span></span></a></li></ul></div><div id=share-options-mask class=share-options-mask></div></div><div id=about><div id=about-card><div id=about-btn-close><i class="fa fa-remove"></i></div><img id=about-card-picture src="//www.gravatar.com/avatar/63eec5e671fc734bde45cd43cc156abc?s=110" alt><h4 id=about-card-name>Kim Seonghyeon</h4><div id=about-card-bio>Machine learning enthusiast</div><div id=about-card-job><i class="fa fa-briefcase"></i><br>Graduate student in HCCLab at Seoul National University</div><div id=about-card-location><i class="fa fa-map-marker"></i><br>Korea, Republic of</div></div></div><div id=algolia-search-modal class=modal-container><div class=modal><div class=modal-header><span class=close-button><i class="fa fa-close"></i></span><a href=https://algolia.com target=_blank class="searchby-algolia text-color-light link-unstyled"><span class="searchby-algolia-text text-color-light text-small">by</span>
<img class=searchby-algolia-logo src=https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg></a>
<i class="search-icon fa fa-search"></i><form id=algolia-search-form><input type=text id=algolia-search-input name=search class="form-control input--large search-input" placeholder></form></div><div class=modal-body><div class="no-result text-color-light text-center"></div><div class=results><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/post/><h3 class=media-heading>Posts</h3></a><span class=media-meta><span class="media-date text-small">Feb 2, 2023</span></span><div class="media-content hide-xs font-merryweather"></div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/02/%EC%9D%B4%EB%AF%B8%EC%A7%80%EC%99%80-%ED%85%8D%EC%8A%A4%ED%8A%B8-%EC%83%9D%EC%84%B1-%EB%AA%A8%EB%8D%B8%EC%97%90-%EB%8C%80%ED%95%B4/><h3 class=media-heading>이미지와 텍스트 생성 모델에 대해</h3></a><span class=media-meta><span class="media-date text-small">Feb 2, 2023</span></span><div class="media-content hide-xs font-merryweather">이미지 생성 하면 Style GAN이었던 시절에도 일러스트 생성 등은 오타쿠적 인기가 있는 주제였다. 문제의 Danbooru 데이터셋 같은 경우에도 그 시점에 이미 만들어진 데이터셋이었</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/02/%EC%96%B8%EC%96%B4%EC%9D%98-%EC%86%90%EC%8B%A4-%EC%95%95%EC%B6%95%EC%97%90-%EB%8C%80%ED%95%98%EC%97%AC/><h3 class=media-heading>언어의 손실 압축에 대하여</h3></a><span class=media-meta><span class="media-date text-small">Feb 2, 2023</span></span><div class="media-content hide-xs font-merryweather">https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web LM을 다음 단어를 예측할 뿐이라거나 학습 데이터를 기억할 뿐이라는 식으로 묘사하는 것은 폄하를 위한 언어이지 LM의 실체나 실제 한계에 대해서 논하기에 적절한 방</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/01/ocr-%ED%9A%8C%EA%B3%A0/><h3 class=media-heading>OCR 회고</h3></a><span class=media-meta><span class="media-date text-small">Jan 1, 2023</span></span><div class="media-content hide-xs font-merryweather">타이틀 커버 이미지 출처: https://www.behance.net/gallery/6146939/OCR-A-Poster/modules/152114859 4년 동안 몰두했던 OCR이라는 주제를 마무리하게 되면서 으레 그래왔듯 회고를 남겨본다. 이랬더라면 어땠을까 같은 소소한 소회보다는</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-7/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 7</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-6/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 6</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-5/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 5</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-4/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 4</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-3/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 3</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-2/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 2</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div></div></div><div class=modal-footer><p class="results-count text-medium" data-message-zero data-message-one data-message-other>65 posts found</p></div></div></div><div id=cover style=background-image:url(http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/stair.jpg)></div><script>(function(d){var config={kitId:'vld6lxf',scriptTimeout:3000,async:true},h=d.documentElement,t=setTimeout(function(){h.className=h.className.replace(/\bwf-loading\b/g,"")+" wf-inactive";},config.scriptTimeout),tk=d.createElement("script"),f=false,s=d.getElementsByTagName("script")[0],a;h.className+=" wf-loading";tk.src='https://use.typekit.net/'+config.kitId+'.js';tk.async=true;tk.onload=tk.onreadystatechange=function(){a=this.readyState;if(f||a&&a!="complete"&&a!="loaded")return;f=true;clearTimeout(t);try{Typekit.load(config)}catch(e){}};s.parentNode.insertBefore(tk,s)})(document);</script><script src=//cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.js></script><script src=/js/script-wl33z0n6ocaypepiqrazthtivfrliqijej4rq8ek8gvrv1awftmgjuv8k4zc.min.js></script><script>$(document).ready(function(){hljs.configure({classPrefix:'',useBR:false});$('pre.code-highlight').each(function(i,block){var code="";hljs.highlightAuto(block.innerText).value.split(/\r\n|\r|\n/).forEach(function(line){code+="<span class=\"line\">"+line+"</span><br>";});if(code.length>0){block.innerHTML=code;}});$('pre > code').each(function(i,block){$(this).addClass('codeblock');hljs.highlightBlock(block);});});</script><script>var disqus_config=function(){this.page.url='http:\/\/rosinality.github.io\/2017\/05\/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%EC%97%90-%EB%8C%80%ED%95%B4\/';this.page.identifier='\/2017\/05\/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%EC%97%90-%EB%8C%80%ED%95%B4\/'};(function(){if(window.location.hostname=="localhost"){return;}
var d=document,s=d.createElement('script');var disqus_shortname='rosinality';s.src='//'+disqus_shortname+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script></body></html>