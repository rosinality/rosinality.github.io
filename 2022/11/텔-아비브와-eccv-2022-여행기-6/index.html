<!doctype html><html lang=ko-kr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.73.0"><meta name=theme content="Tranquilpeak 0.3.1-BETA"><title>텔 아비브와 ECCV 2022 여행기 6</title><meta name=author content="Kim Seonghyeon"><meta name=keywords content="tel aviv,eccv 2022,machine learning,machine learning,deep learning,social science"><link rel=icon href=/favicon.png><meta name=description content="텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브"><meta property="og:description" content="텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브"><meta property="og:type" content="blog"><meta property="og:title" content="텔 아비브와 ECCV 2022 여행기 6"><meta property="og:url" content="/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-6/"><meta property="og:site_name" content="Nondifferentiable Log"><meta name=twitter:card content="summary"><meta name=twitter:title content="Nondifferentiable Log"><meta name=twitter:description content="텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브"><meta name=twitter:creator content="@rosinality"><meta property="og:image" content="//www.gravatar.com/avatar/63eec5e671fc734bde45cd43cc156abc?s=640"><meta property="og:image" content="https://res.cloudinary.com/rosinality/image/upload/v1667440604/tel-aviv/20221027_171443.jpg"><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css><link rel=stylesheet href=/css/style-u6mk0ojoywresbx8iepslrmmhl4stuhrsxuwhkpwrkrx7mryjcaimasnk4pi.min.css></head><body><div id=blog><header id=header data-behavior=5><i id=btn-open-sidebar class="fa fa-lg fa-bars"></i><div class=header-title><a class=header-title-link href=/>Nondifferentiable Log</a></div></header><nav id=sidebar data-behavior=5><div class=sidebar-container><div class=sidebar-profile><a href=/#about><img class=sidebar-profile-picture src="//www.gravatar.com/avatar/63eec5e671fc734bde45cd43cc156abc?s=110" alt></a><h4 class=sidebar-profile-name>Kim Seonghyeon</h4><h5 class=sidebar-profile-bio>Machine learning enthusiast</h5></div><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=/categories><i class="sidebar-button-icon fa fa-lg fa-bookmark"></i><span class=sidebar-button-desc>Categories</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/tags><i class="sidebar-button-icon fa fa-lg fa-tags"></i><span class=sidebar-button-desc>Tags</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/archives><i class="sidebar-button-icon fa fa-lg fa-archive"></i><span class=sidebar-button-desc>Archives</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/#about><i class="sidebar-button-icon fa fa-lg fa-question"></i><span class=sidebar-button-desc>About</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/><i class="sidebar-button-icon fa fa-lg fa-home"></i><span class=sidebar-button-desc>Home</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://github.com/rosinality target=_blank><i class="sidebar-button-icon fa fa-lg fa-github"></i><span class=sidebar-button-desc>GitHub</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=/index.xml><i class="sidebar-button-icon fa fa-lg fa-rss"></i><span class=sidebar-button-desc>RSS</span></a></li></ul></div></nav><div class="post-header-cover
text-left
post-header-cover--partial" style=background-image:url(https://res.cloudinary.com/rosinality/image/upload/v1667440604/tel-aviv/20221027_171443.jpg) data-behavior=5></div><div id=main data-behavior=5 class="hasCover
hasCoverMetaIn"><article class=post itemscope itemtype=http://schema.org/BlogPosting><div class="post-header main-content-wrap text-left"><h1 class=post-title itemprop=headline>텔 아비브와 ECCV 2022 여행기 6</h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2022-11-07T16:16:12+09:00>November 7, 2022</time>
<span></span><a class=category-link href=/categories/travel>travel</a></div></div><div class="post-content markdown" itemprop=articleBody><div class=main-content-wrap><ol><li><a href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-1/>텔 아비브와 ECCV 2022 여행기 1</a></li><li><a href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-2/>텔 아비브와 ECCV 2022 여행기 2</a></li><li><a href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-3/>텔 아비브와 ECCV 2022 여행기 3</a></li><li><a href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-4/>텔 아비브와 ECCV 2022 여행기 4</a></li><li><a href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-5/>텔 아비브와 ECCV 2022 여행기 5</a></li><li>텔 아비브와 ECCV 2022 여행기 6</li><li><a href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-7/>텔 아비브와 ECCV 2022 여행기 7</a></li></ol><p>학회 마지막 날.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_075231.jpg alt="또 조식"></p><p>또 샥슈카를 열심히 챙김.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_102327.jpg alt="학회 버스"></p><p>좀 이상한 타이밍에 타서 학회장 가는 버스에 혼자 탑승.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_103417.jpg alt="Neural Strands: Learning Hair Geometry and Appearance from Multi-View Images"></p><p><a href=https://arxiv.org/abs/2207.14067>Neural Strands: Learning Hair Geometry and Appearance from Multi-View Images</a>. Neural Strands가 여기 나온 연구였음. 남겨둔 메모가 있으니 가져와보면:</p><blockquote><p>multi view 이미지들에서 머리카락의 기하학적 구조를 추출해서 렌더링하는 프레임워크. 기하학적 구조를 추출하기 때문에 편집이 용이하다고 주장하고 있네요. 이전에 언리얼 엔진 데모 같은 것에서 머리카락 렌더링을 티저로 사용하곤 했었는데 그런 게 좀 생각나네요.</p></blockquote><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_103625.jpg alt="Improved Masked Image Generation with Token-Critic"></p><p><a href=https://arxiv.org/abs/2209.04439>Improved Masked Image Generation with Token-Critic</a>. 마침 요즘 관심 있는 주제에 대한 연구 포스터. 포스터를 붙이고 있길래 살짝 거들었음. 이런 masked image generation이 pixel level diffusion에 대해 가지는 장점이 무엇이라고 생각하냐고 물으니 빠른 샘플링 속도를 장점으로 제시. 퀄리티 측면에서 동등하다고 보지만 vq-vae 사용으로 인해 texture에 대한 재현이 약할 수 있지만 global structure에 대해서는 괜찮은 것 같다고 제안. (혹은 더 나을 수 있는 가능성도.)</p><p>critic 학습에 얼마나 걸렸는지 물으니 큰 모델이라 4~5일 정도 걸렸다고 함. GPU/TPU를 얼마나 쓴 조건인지는 제대로 못 들었지만.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_103859.jpg alt="GARF: Gaussian Activated Radiance Fields for High Fidelity Reconstruction and Pose Estimation"></p><p><a href=https://arxiv.org/abs/2204.05735>GARF: Gaussian Activated Radiance Fields for High Fidelity Reconstruction and Pose Estimation</a></p><p>nerf에서 pose estimation을 동시에 수행/학습하는 방법에 대한 연구. 직관이나 분석에 대해서도 설명해줬는데 아주 흥미로웠음. 좌표에 대한 그냥 relu mlp를 돌리면 low rank(혹은 low frequency) 매핑이라 성능이 불충분하고 (코멘트가 정확히 기억나지는 않는다.) positional encoding을 사용하면 이 문제는 해소되지만 그래디언트의 패턴이 썩 좋지 않음. sinusoidal (<a href=https://arxiv.org/abs/2006.09661>SIREN</a>) activation을 사용하면 해소되지만 sinusoidal function은 거의 모든 지점에서 그래디언트가 0 이상이기 때문에 initialization에 민감하게 반응. GARF는 gaussian activation을 사용해서 이 문제들을 모두 해소. <a href=https://arxiv.org/abs/2104.06405>BARF</a>의 경우에는 이런 문제들 때문에 커리큘럼 같은 것이 필요했는데 그런 것이 필요하지 않다고. positional encoding을 없애고 gaussian activation으로 바꾼 다음 학습하면 그냥 된다고 함.</p><p>굳이 colmap을 쓸 필요 없이 앞으로는 그냥 이걸 쓰면 된다고 하는 정도로 이야기함. 굉장히 흥미로워서 좀 더 분석한 다음 nerf 구현에 밀어넣어보고 싶음.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_104015.jpg alt="A Broad Study of Pre-training for Domain Generalization and Adaptation"></p><p><a href=https://arxiv.org/abs/2203.11819>A Broad Study of Pre-training for Domain Generalization and Adaptation</a>. 여러 프리트레이닝 방법, 데이터셋, 아키텍처의 domain generalization 성능에 대한 연구. domain generalization/adaptation 데이터셋들과 imagenet-a 같은 robustness 데이터셋에서 나타나는 패턴이 다른가 하는 질문을 하니 개념적으로 비슷한 부분들이 있지만 데이터셋의 규모 같은 차이로 인해 패턴이 일치하지 않는 경우가 있다는 이야기를 들었다.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_104314.jpg alt="SLIP: Self-supervision meets Language-Image Pre-training"></p><p><a href=https://arxiv.org/abs/2112.12750>SLIP: Self-supervision meets Language-Image Pre-training</a>. clip pretraining + self-supervised (contrastive) pretraining for image backbone. 성능 향상이 눈에 띄는 정도였음. 한 가지 흥미로웠던 부분은 beit 같은 masked image modeling보다 simclr 같은 contrastive training이 (이미지 self supervision에만 적용하는 경우에는 beit가 나음에도) clip pretraining과 결합했을 때 더 나았다는 것. 왜 그런지 물어보니 미스테리하지만 (이 부분은 잘 기억나지 않음) image self supervision이 추가적으로 보강해주는 부분에서 차이가 있는 것이 아닌가 하는 이야기. openai clip은 더 대규모의 이미지-텍스트 페어에 대해서 학습했는데 그 규모에서도 향상이 있을지 물어보니 그 규모까지 외삽하는 것은 어렵지만 논문 내에서 다룬 데이터셋들에서도 데이터셋이 커져도 성능 향상은 있었다는 것을 고려할 때 gain이 있을 수 있지 않을까 하고 제안.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_105259.jpg alt="Simple Open-Vocabulary Object Detection with Vision Transformers"></p><p><a href=https://arxiv.org/abs/2205.06230>Simple Open-Vocabulary Object Detection with Vision Transformers</a>. OWL-ViT. GLIP하고 비교하면 어떤지 물어보니 OWL-ViT는 심플함을 추구해서 GLIP에 있는 image-text feature fusion 같은 요소들을 제외했다고. 그러니 GLIP이 성능의 포텐셜은 더 높을 수도 있지 않겠느냐고 이야기함. 그런데 실험 테이블에서는 GLIP보다 OWL-ViT가 더 나은데? 라고 묻자 글쎄 그건 왜 그런지 우리도 잘 모르겠네 이런 이야기를 나눔. 😂</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_110905.jpg alt="Detecting Twenty-thousand Classes using Image-level Supervision"></p><p><a href=https://arxiv.org/abs/2201.02605>Detecting Twenty-thousand Classes using Image-level Supervision</a>. 어쩌다 카메라가 제대로 흔들렸네.</p><blockquote><p>이미지 단위 레이블 정보를 object detection에 활용하기. (weak supervision) 특별한 절차 없이 가장 큰 proposal 박스에 이미지 레이블을 부여해서 학습시키네요.</p></blockquote><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_110948.jpg alt="A Simple Single-Scale Vision Transformer for Object Localization and Instance Segmentation"></p><p><a href=https://arxiv.org/abs/2112.09747>A Simple Single-Scale Vision Transformer for Object Localization and Instance Segmentation</a></p><blockquote><p>vit에서 multiscale 구조는 딱히 필요하지 않고 single scale로 레이어를 쭉 쌓아도 좋다는 결과. 다만 연산이 비효율적이니 window attention을 활용하는데 이 window 크기를 점진적으로 키우는 구조는 고려해봤네요. 다 좋은데 이 window attention이 overlapping window 기반이라&mldr;이걸 구현하는 게 문제긴 하네요. single scale swin 같은 구조가 가능할까 싶기도 한데요.</p></blockquote><p>detection head는 cascade mask r-cnn 기반. (벤치마크를 깨겠다는 의지가 충만해보이는 선택이라고 할 수 있음.) detection head도 심플하게 만드는 방향을 충분히 생각해볼 수 있겠다.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_105426.jpg alt="ViewFormer: NeRF-free Neural Rendering from Few Images Using Transformers"></p><p><a href=https://arxiv.org/abs/2203.10157>ViewFormer: NeRF-free Neural Rendering from Few Images Using Transformers</a></p><p>nerf rendering 파이프라인 없이 트랜스포머에 position 정보를 입력한 다음 이미지를 바로 생성. 이미지는 잘 나오지면 역시 3d consistency를 보장하기 어렵다는 것이 주된 문제일 듯.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_122123.jpg alt="학회 점심 1"></p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_124052.jpg alt="학회 점심 2"></p><p>그 와중에 학회 점심은 또 챙겨먹음.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_143756.jpg alt="디젠고프 센터"></p><p>오후 시간에 디젠고프 센터(Dizengoff Center)에 들렀음. 텔 아비브 최대 쇼핑몰이라는 듯. 복잡하고 이것저것 많았는데 흥미로운 것이 서브컬쳐나 오타쿠스러운 상품을 취급하는 가게들이 꽤 많았음. 사진은 없지만 진격의 거인이나 귀멸의 칼날 같은 서구권에서 인기 있기로 유명한(?) 것도 그렇지만 특히 눈에 띈 것이 원신. 원신 굿즈가 정말 많았음. 이스라엘에서 원신을 한다는 게 잘 상상이 안 되는데&mldr;여튼.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_155054.jpg alt="올드 야파"></p><p>그 다음은 텔 아비브의 구 시가지 올드 야파로.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_155521.jpg alt=시계탑></p><p>올드 야파의 시계탑. 여기 있는 시장은 카멜 마켓보다 더 좁고 구불구불했다.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_162330.jpg alt="크나페와 터키식 차"></p><p>일행 중 한 분이 극구 추천해서 맛본 크나페(쿠나파? Knafeh)와 터키식 차. 아이스크림을 얹은 바리에이션인데 정말 맛있었음.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_164628.jpg alt="야파 올라가는 길 1"></p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_165139.jpg alt="야파 올라가는 길 2"></p><p>거리를 지나 올라가는 길.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_165146.jpg alt="야파 올라가는 길 모스크"></p><p>중간에 만난 모스크.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_165148.jpg alt="야파 올라가는 길 바다"></p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_170417.jpg alt="베드로 환시 기념 성당"></p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_170216.jpg alt="베드로 환시 기념 성당 내부"></p><p>올라가는 길에 베드로 환시 기념 성당을 만나 내부에 들어가볼 수 있었다. 마침 미사가 끝난 바로 직후 타이밍이라(17시) 수사로 보이는 분이 관대하게 들여보내주셨음. 환시 기념이라는 아우라 때문인지 느껴지는 감흥이 있었다. 예루살렘에 가본 분도 있었는데 여기 와보고 나서 그 분들이 좀 부럽다 하는 생각을 처음 했음.</p><p>환시 기념 성당이라는 것이 대체 무슨 의미냐는 이야기가 나왔는데 일행 중 한 분이 코셔 안 지켜도 된다고 한 사건이라고 단 번에 요약해내셔서 좀 재미있었음.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_170619.jpg alt="올드 야파 골목길 1"></p><p>올드 야파의 골목길. 이렇게 성벽처럼 높은 벽들 사이로 길이 나 있고 그 벽에 집들이 들어가 있는 구조였음.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_170648.jpg alt="올드 야파 골목길 2"></p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_171111.jpg alt="무두장이 시몬의 집"></p><p>골목길을 지나가다 만난 무두장이 시몬의 집.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_171443.jpg alt="올드 야파 골목길 3"></p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_172127.jpg alt="올드 야파 내려가는 길"></p><p>내려가는 길에서 만난 바다.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_172157.jpg alt="올드 야파의 바다 1"></p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_172722.jpg alt="올드 야파의 바다 2"></p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_210529.jpg alt=커틀릿></p><p>텔 아비브에서의 마지막 저녁. 루마니아 레스토랑이라는 곳에 들어감. 커틀릿.</p><p><img src=https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221027_204615.jpg alt="골드스타 맥주"></p><p>또드스타 맥주.</p><p>이 날은 이것으로 마무리.</p></div></div><div id=post-footer class="post-footer main-content-wrap"><div class=post-footer-tags><span class="text-color-light text-small"></span><br><a class="tag tag--primary tag--small" href=http://rosinality.github.io//tags/tel-aviv/>tel aviv</a>
<a class="tag tag--primary tag--small" href=http://rosinality.github.io//tags/eccv-2022/>eccv 2022</a>
<a class="tag tag--primary tag--small" href=http://rosinality.github.io//tags/machine-learning/>machine learning</a></div><div class=post-actions-wrap><nav><ul class="post-actions post-action-nav"><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-7/ data-tooltip="텔 아비브와 ECCV 2022 여행기 7"><i class="fa fa-angle-left"></i><span class="hide-xs hide-sm text-small icon-ml"></span></a></li><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-5/ data-tooltip="텔 아비브와 ECCV 2022 여행기 5"><span class="hide-xs hide-sm text-small icon-mr"></span><i class="fa fa-angle-right"></i></a></li></ul></nav><ul class="post-actions post-action-share"><li class="post-action hide-lg hide-md hide-sm"><a class="post-action-btn btn btn--default btn-open-shareoptions" href=#btn-open-shareoptions><i class="fa fa-share-alt"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://plus.google.com/share?url=http%3a%2f%2frosinality.github.io%2f2022%2f11%2f%25ED%2585%2594-%25EC%2595%2584%25EB%25B9%2584%25EB%25B8%258C%25EC%2599%2580-eccv-2022-%25EC%2597%25AC%25ED%2596%2589%25EA%25B8%25B0-6%2f"><i class="fa fa-google-plus"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://www.facebook.com/sharer/sharer.php?u=http%3a%2f%2frosinality.github.io%2f2022%2f11%2f%25ED%2585%2594-%25EC%2595%2584%25EB%25B9%2584%25EB%25B8%258C%25EC%2599%2580-eccv-2022-%25EC%2597%25AC%25ED%2596%2589%25EA%25B8%25B0-6%2f"><i class="fa fa-facebook-official"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://twitter.com/intent/tweet?text=http%3a%2f%2frosinality.github.io%2f2022%2f11%2f%25ED%2585%2594-%25EC%2595%2584%25EB%25B9%2584%25EB%25B8%258C%25EC%2599%2580-eccv-2022-%25EC%2597%25AC%25ED%2596%2589%25EA%25B8%25B0-6%2f"><i class="fa fa-twitter"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#disqus_thread><i class="fa fa-comment-o"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#><i class="fa fa-list"></i></a></li></ul></div><div id=disqus_thread><noscript>Please enable JavaScript to view the <a href=//disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div></div></article><footer id=footer class=main-content-wrap><span class=copyrights>&copy; 2025 Kim Seonghyeon.</span></footer></div><div id=share-options-bar class=share-options-bar data-behavior=5><ul class=share-options><li class=share-option><a class=share-option-btn target=new href="https://plus.google.com/share?url=http%3a%2f%2frosinality.github.io%2f2022%2f11%2f%25ED%2585%2594-%25EC%2595%2584%25EB%25B9%2584%25EB%25B8%258C%25EC%2599%2580-eccv-2022-%25EC%2597%25AC%25ED%2596%2589%25EA%25B8%25B0-6%2f"><i class="fa fa-google-plus"></i><span></span></a></li><li class=share-option><a class=share-option-btn target=new href="https://www.facebook.com/sharer/sharer.php?u=http%3a%2f%2frosinality.github.io%2f2022%2f11%2f%25ED%2585%2594-%25EC%2595%2584%25EB%25B9%2584%25EB%25B8%258C%25EC%2599%2580-eccv-2022-%25EC%2597%25AC%25ED%2596%2589%25EA%25B8%25B0-6%2f"><i class="fa fa-facebook-official"></i><span></span></a></li><li class=share-option><a class=share-option-btn target=new href="https://twitter.com/intent/tweet?text=http%3a%2f%2frosinality.github.io%2f2022%2f11%2f%25ED%2585%2594-%25EC%2595%2584%25EB%25B9%2584%25EB%25B8%258C%25EC%2599%2580-eccv-2022-%25EC%2597%25AC%25ED%2596%2589%25EA%25B8%25B0-6%2f"><i class="fa fa-twitter"></i><span></span></a></li></ul></div><div id=share-options-mask class=share-options-mask></div></div><div id=about><div id=about-card><div id=about-btn-close><i class="fa fa-remove"></i></div><img id=about-card-picture src="//www.gravatar.com/avatar/63eec5e671fc734bde45cd43cc156abc?s=110" alt><h4 id=about-card-name>Kim Seonghyeon</h4><div id=about-card-bio>Machine learning enthusiast</div><div id=about-card-job><i class="fa fa-briefcase"></i><br>Graduate student in HCCLab at Seoul National University</div><div id=about-card-location><i class="fa fa-map-marker"></i><br>Korea, Republic of</div></div></div><div id=algolia-search-modal class=modal-container><div class=modal><div class=modal-header><span class=close-button><i class="fa fa-close"></i></span><a href=https://algolia.com target=_blank class="searchby-algolia text-color-light link-unstyled"><span class="searchby-algolia-text text-color-light text-small">by</span>
<img class=searchby-algolia-logo src=https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg></a>
<i class="search-icon fa fa-search"></i><form id=algolia-search-form><input type=text id=algolia-search-input name=search class="form-control input--large search-input" placeholder></form></div><div class=modal-body><div class="no-result text-color-light text-center"></div><div class=results><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/post/><h3 class=media-heading>Posts</h3></a><span class=media-meta><span class="media-date text-small">May 5, 2025</span></span><div class="media-content hide-xs font-merryweather"></div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2025/05/%ED%81%B4%EB%A0%88%EB%A5%B4-%EC%98%B5%EC%8A%A4%ED%80%B4%EB%A5%B4-33-%EC%9B%90%EC%A0%95%EB%8C%80/><h3 class=media-heading>클레르 옵스퀴르: 33 원정대</h3></a><span class=media-meta><span class="media-date text-small">May 5, 2025</span></span><div class="media-content hide-xs font-merryweather">오랜만에 좋은 게임을 했다. 새삼스럽지만 게임은 굉장히 강력한 스토리텔링의 수단이라는 생각을 한다. 게임 플레이와 섞이기 때문에 서사의 밀도가 높지는 않겠지만 2</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2024/09/scaling-law-architecture-for-stability-and-layer-stacking/><h3 class=media-heading>Scaling Law, Architecture for Stability and Layer Stacking</h3></a><span class=media-meta><span class="media-date text-small">Sep 9, 2024</span></span><div class="media-content hide-xs font-merryweather">Scaling Law Scaling law is one of the most important findings in LLMs (and neural networks in general) 1. You can make almost all important decisions about training of models with scaling law. For example you can choose model size, number of training steps 2, hyperparameters such as learning rate and batch size 3, learning rate schedules 4, mixture of training datasets 5, etc. So if you are serious about</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2024/06/preliminary-explorations-on-ul2-and-second-order-optimizers/><h3 class=media-heading>Preliminary Explorations on UL2 and Second-order Optimizers</h3></a><span class=media-meta><span class="media-date text-small">Jun 6, 2024</span></span><div class="media-content hide-xs font-merryweather">In the field of large language models, the most important recipes to cook the model is not opened to publics. Model architecture itself is quite well-known because many state-of-the-art models are now open weights, and in many cases we find it is a boringly simple vanilla transformers. But for datasets and training objectives it is not well known, and many LLM builders deliberately obfuscates the details of these two. And,</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/07/constitutional-ai/><h3 class=media-heading>Constitutional AI</h3></a><span class=media-meta><span class="media-date text-small">Jul 7, 2023</span></span><div class="media-content hide-xs font-merryweather">Helpful & Harmless Agent AI 모델의 정렬(Alignment)이라고 이야기할 때 흔히 나오는 Helpfulness와 Harmlessness는 어떤 의미인가? 이는 정의</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/02/%EC%9D%B4%EB%AF%B8%EC%A7%80%EC%99%80-%ED%85%8D%EC%8A%A4%ED%8A%B8-%EC%83%9D%EC%84%B1-%EB%AA%A8%EB%8D%B8%EC%97%90-%EB%8C%80%ED%95%B4/><h3 class=media-heading>이미지와 텍스트 생성 모델에 대해</h3></a><span class=media-meta><span class="media-date text-small">Feb 2, 2023</span></span><div class="media-content hide-xs font-merryweather">이미지 생성 하면 Style GAN이었던 시절에도 일러스트 생성 등은 오타쿠적 인기가 있는 주제였다. 문제의 Danbooru 데이터셋 같은 경우에도 그 시점에 이미 만들어진 데이터셋이었</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/02/%EC%96%B8%EC%96%B4%EC%9D%98-%EC%86%90%EC%8B%A4-%EC%95%95%EC%B6%95%EC%97%90-%EB%8C%80%ED%95%98%EC%97%AC/><h3 class=media-heading>언어의 손실 압축에 대하여</h3></a><span class=media-meta><span class="media-date text-small">Feb 2, 2023</span></span><div class="media-content hide-xs font-merryweather">https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web LM을 다음 단어를 예측할 뿐이라거나 학습 데이터를 기억할 뿐이라는 식으로 묘사하는 것은 폄하를 위한 언어이지 LM의 실체나 실제 한계에 대해서 논하기에 적절한 방</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/01/ocr-%ED%9A%8C%EA%B3%A0/><h3 class=media-heading>OCR 회고</h3></a><span class=media-meta><span class="media-date text-small">Jan 1, 2023</span></span><div class="media-content hide-xs font-merryweather">타이틀 커버 이미지 출처: https://www.behance.net/gallery/6146939/OCR-A-Poster/modules/152114859 4년 동안 몰두했던 OCR이라는 주제를 마무리하게 되면서 으레 그래왔듯 회고를 남겨본다. 이랬더라면 어땠을까 같은 소소한 소회보다는</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-7/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 7</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-6/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 6</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div></div></div><div class=modal-footer><p class="results-count text-medium" data-message-zero data-message-one data-message-other>69 posts found</p></div></div></div><div id=cover style=background-image:url(http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/stair.jpg)></div><script>(function(d){var config={kitId:'vld6lxf',scriptTimeout:3000,async:true},h=d.documentElement,t=setTimeout(function(){h.className=h.className.replace(/\bwf-loading\b/g,"")+" wf-inactive";},config.scriptTimeout),tk=d.createElement("script"),f=false,s=d.getElementsByTagName("script")[0],a;h.className+=" wf-loading";tk.src='https://use.typekit.net/'+config.kitId+'.js';tk.async=true;tk.onload=tk.onreadystatechange=function(){a=this.readyState;if(f||a&&a!="complete"&&a!="loaded")return;f=true;clearTimeout(t);try{Typekit.load(config)}catch(e){}};s.parentNode.insertBefore(tk,s)})(document);</script><script src=//cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.js></script><script src=/js/script-wl33z0n6ocaypepiqrazthtivfrliqijej4rq8ek8gvrv1awftmgjuv8k4zc.min.js></script><script>$(document).ready(function(){hljs.configure({classPrefix:'',useBR:false});$('pre.code-highlight').each(function(i,block){var code="";hljs.highlightAuto(block.innerText).value.split(/\r\n|\r|\n/).forEach(function(line){code+="<span class=\"line\">"+line+"</span><br>";});if(code.length>0){block.innerHTML=code;}});$('pre > code').each(function(i,block){$(this).addClass('codeblock');hljs.highlightBlock(block);});});</script><script>var disqus_config=function(){this.page.url='http:\/\/rosinality.github.io\/2022\/11\/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-6\/';this.page.identifier='\/2022\/11\/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-6\/'};(function(){if(window.location.hostname=="localhost"){return;}
var d=document,s=d.createElement('script');var disqus_shortname='rosinality';s.src='//'+disqus_shortname+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script></body></html>