<!doctype html><html lang=ko-kr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.73.0"><meta name=theme content="Tranquilpeak 0.3.1-BETA"><title>OCR 회고</title><meta name=author content="Kim Seonghyeon"><meta name=keywords content="ocr,memoir,machine learning,machine learning,deep learning,social science"><link rel=icon href=/favicon.png><meta name=description content="타이틀 커버 이미지 출처: https://www.behance.net/gallery/6146939/OCR-A-Poster/modules/152114859 4년 동안 몰두했던 OCR이라는 주제를 마무리하게 되면서 으레 그래왔듯 회고를 남겨본다. 이랬더라면 어땠을까 같은 소소한 소회보다는"><meta property="og:description" content="타이틀 커버 이미지 출처: https://www.behance.net/gallery/6146939/OCR-A-Poster/modules/152114859 4년 동안 몰두했던 OCR이라는 주제를 마무리하게 되면서 으레 그래왔듯 회고를 남겨본다. 이랬더라면 어땠을까 같은 소소한 소회보다는"><meta property="og:type" content="blog"><meta property="og:title" content="OCR 회고"><meta property="og:url" content="/2023/01/ocr-%ED%9A%8C%EA%B3%A0/"><meta property="og:site_name" content="Nondifferentiable Log"><meta name=twitter:card content="summary"><meta name=twitter:title content="Nondifferentiable Log"><meta name=twitter:description content="타이틀 커버 이미지 출처: https://www.behance.net/gallery/6146939/OCR-A-Poster/modules/152114859 4년 동안 몰두했던 OCR이라는 주제를 마무리하게 되면서 으레 그래왔듯 회고를 남겨본다. 이랬더라면 어땠을까 같은 소소한 소회보다는"><meta name=twitter:creator content="@rosinality"><meta property="og:image" content="https://res.cloudinary.com/rosinality/image/upload/v1672667223/ocr-a.jpg"><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css><link rel=stylesheet href=/css/style-u6mk0ojoywresbx8iepslrmmhl4stuhrsxuwhkpwrkrx7mryjcaimasnk4pi.min.css></head><body><div id=blog><header id=header data-behavior=5><i id=btn-open-sidebar class="fa fa-lg fa-bars"></i><div class=header-title><a class=header-title-link href=/>Nondifferentiable Log</a></div></header><nav id=sidebar data-behavior=5><div class=sidebar-container><div class=sidebar-profile><a href=/#about><img class=sidebar-profile-picture src="//www.gravatar.com/avatar/63eec5e671fc734bde45cd43cc156abc?s=110" alt></a><h4 class=sidebar-profile-name>Kim Seonghyeon</h4><h5 class=sidebar-profile-bio>Machine learning enthusiast</h5></div><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=/categories><i class="sidebar-button-icon fa fa-lg fa-bookmark"></i><span class=sidebar-button-desc>Categories</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/tags><i class="sidebar-button-icon fa fa-lg fa-tags"></i><span class=sidebar-button-desc>Tags</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/archives><i class="sidebar-button-icon fa fa-lg fa-archive"></i><span class=sidebar-button-desc>Archives</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/#about><i class="sidebar-button-icon fa fa-lg fa-question"></i><span class=sidebar-button-desc>About</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/><i class="sidebar-button-icon fa fa-lg fa-home"></i><span class=sidebar-button-desc>Home</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://github.com/rosinality target=_blank><i class="sidebar-button-icon fa fa-lg fa-github"></i><span class=sidebar-button-desc>GitHub</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=/index.xml><i class="sidebar-button-icon fa fa-lg fa-rss"></i><span class=sidebar-button-desc>RSS</span></a></li></ul></div></nav><div class="post-header-cover
text-left
post-header-cover--partial" style=background-image:url(https://res.cloudinary.com/rosinality/image/upload/v1672667223/ocr-a.jpg) data-behavior=5></div><div id=main data-behavior=5 class="hasCover
hasCoverMetaIn"><article class=post itemscope itemtype=http://schema.org/BlogPosting><div class="post-header main-content-wrap text-left"><h1 class=post-title itemprop=headline>OCR 회고</h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2023-01-02T22:49:14+09:00>January 2, 2023</time>
<span></span><a class=category-link href=/categories/memoir>memoir</a></div></div><div class="post-content markdown" itemprop=articleBody><div class=main-content-wrap><p>타이틀 커버 이미지 출처: <a href=https://www.behance.net/gallery/6146939/OCR-A-Poster/modules/152114859>https://www.behance.net/gallery/6146939/OCR-A-Poster/modules/152114859</a></p><p>4년 동안 몰두했던 OCR이라는 주제를 마무리하게 되면서 으레 그래왔듯 회고를 남겨본다. 이랬더라면 어땠을까 같은 소소한 소회보다는 비교적 서비스에 가까운 작업을 진행하면서 생각했던, 혹은 부딪쳤던 문제들에 대해 남겨놓고 언젠가 다시 돌아와서 이 문제들에 대해 다른, 되도록이면 더 나은 생각을 할 수 있게 되기를 바라는 쪽에 가깝겠다.</p><h1 id=ai-겨울>AI 겨울</h1><p>AI의 겨울이 다시 찾아올까? OCR에 대한 회고의 첫 마디에서 등장하기에는 지나치게 큰 주제인데, 나는 이 문제에서 시작하는 것이 OCR에서 경험했던 문제들을 좀 더 추상적인 관점에서 볼 수 있는 생각의 틀을 제공할 수 있으리라는 생각을 한다. 그런데 도대체 AI 겨울이란 무엇인가? AI가 AI에서 약속했던 것들을 제공하지 못했던 것에서 발생했던 문제들이라고 한다면 그 AI의 약속이란 대체 무엇이었던 것일까? 아마 과거의 AI 겨울에서 중요했던 문제는, 예를 들어 ASR 같은 우리가 중요하게 생각하는 과제에 대해 고성능 솔루션을 제공할 수 있으리라 기대했지만 그러지 못했다 같은 측면이 크지 않았을까 싶다.</p><p>그렇다면 지금도 그런 문제가 발생할 가능성이 있을까? 자율주행 같은 문제에서 데이터를 끝없이 투입해서 코너 케이스를 커버하지 못하는 문제 등에서는 그런 한계가 보이는 것 같기도 하지만, ASR이나 OCR 같은 문제에서는 모델과 데이터의 발달로 성능이 꽤 괜찮은 수준까지 발전하고 있고 앞으로도 그럴 수 있을 가능성이 높아 보이기도 한다. 그러니 결국 케바케이지만 성능의 한계 자체가 문제가 될 가능성은 낮아지고 있다고 보인다.</p><p>여기서 우리가 AI에 대해 암묵적으로 걸고 있는 기대와 예상의 다른 측면들을 생각해볼까 한다.</p><h1 id=과제는-풀었다만-이-과제가-우리가-기대한-만큼의-가치를-제공할-수-있는-것이었던가>과제는 풀었다만, 이 과제가 우리가 기대한 만큼의 가치를 제공할 수 있는 것이었던가?</h1><p>OCR 같이 이미 잘 정의되어 있고 으레 여기서 고성능을 달성할 수 있다면 유용하게 쓰일 수 있으리라고 가정되는 과제들도, 정작 그 과제에 대한 그 솔루션이 개발되었을 때 발생하는 가치, 즉 사용자에 대한 효용이 기대보다 크지 않은 것 같은 상황에 맞닥뜨리게 되는 경우가 있다. 여기에는 몇 가지 이유가 있었을 것이다. 첫째로는 이 과제가 사실 더 큰 목표와 과제에 대한 좀 더 낮은 단계의 문제(Sub-problem)였을 가능성이다. 예컨대 챗봇 같은 것을 만드는 것이 목적이라면 화자 의도 인식 같은 것은 챗봇을 구축하는데 필요한 작은 문제이다. 이 문제를 잘 푸는 것이 챗봇에 도움이 될 수도 있지만 그것만으로 챗봇을 구성할 수 있는 것은 아니다. 요즘 같이 End-to-End 솔루션들이 효과적인 시점에는 애초에 그 문제를 푸는 것이 딱히 필요하지 않았던 것일 수도 있다.</p><p>두 번째 가능성은 실제 사용 시나리오에서 이 과제들이 어떻게 작동할지, 어떤 기능들이 추가적으로 필요할지 충분히 생각해보지 않은 경우가 있을 수 있겠다. 어쩌면 이 사용 시나리오 자체를 명확하게 구상하지 못했을 가능성도 있다. 즉 어떤 기능을 사용자에게 제공하겠다는 그림 자체가 허술했을 가능성도 있다. 더욱이 이 구체적인 과제에 대한 솔루션의 성능이 부족한 상황에서는 이 성능을 향상시키는데 급급하게 되고, 또한 애초에 가장 기본적인 단계에서부터 잘 작동하지 않으니 더 큰 그림을 볼만한 여유가 없어지게 만드는 경향도 있다. 애초에 글자 하나 제대로 읽지 못하는데 그걸 사용해서 무언가를 하겠다는 거창한 계획을 세우는 것은 허황하게 보일 가능성이 높다.</p><p>나는 지금 이 문제가 여기저기서 발생하고 있는 것이 아닐까 생각한다. 즉 우리는 풀 문제를 설정하고 그 문제에 대해서 고성능 솔루션을 만드는 고비까지는 넘었지만 정작 그 솔루션을 들고 밖으로 나가보니 생각보다 사용처가 많지 않다는 것을 발견하게 된 것이다. 단적으로 말해 충분한 돈을 내고 쓰고 싶어하는 사례가 많지 않은 것이다.</p><h1 id=모든-문제가-가치-있는-것은-아니었다-그렇다면-대체-가치-있는-과제는-어디에-있는가>모든 문제가 가치 있는 것은 아니었다. 그렇다면 대체 가치 있는 과제는 어디에 있는가?</h1><p>기존에 잘 정의되어 있었던, 으레 가치 있다고 가정했던 과제들이 그 자체만으로는 충분하지 않거나 사실 큰 가치가 없을 수 있다는 생각이 들었다면, 그렇다면 정말 가치 있는 과제가 무엇이 있을지가 문제가 되는 것이 순서이다. 그러나 이 순간 문제는 더 어려운 지점으로 나아간다. 이 시점부터 우리는 이미 정의된 과제가 아니라 과제를 찾아내고 발견하며 스스로 설정해야 하는 상황으로 들어가게 된다. 이런저런 문제들을 풀 수 있는 도구들은 구비되어 있다. 그렇지만 도구들을 구비하고 대충 문제가 주어졌을 때 그 문제를 풀 수 있을지를 가늠할 수 있는 엔지니어링적 감각과 가치 있는 주제들을 선정하는 기획의 영역은 분명 다르다. 그렇지만 기획의 감각만으로 문제를 풀 수도 없다. 무엇이 가능하고 어떤 문제를 풀 수 있는 도구가 주어져 있는지를 파악하지 못하면 급진적인 가능성과 문제들에 대해서는 엄두를 내기 어렵다. 어떤 아이디어가 떠올라도 기술적으로 어렵거나 불가능할 것이라고 판단해서 스스로 포기해버리는 경우가 왕왕 발생한다. (물론 구비한 도구들로 풀 수 있는 문제들 중 딱히 가치 있는 문제가 없는 경우 또한 있을 수 있다.)</p><p>나는 지금 AI 연구 개발이 이 문제들에 맞닥뜨린 경우가 많지 않은가 하는 생각을 한다. 어쩌면 AI 연구 개발이 기존에 잘 정의된 과제들과 그에 대한 도구들에서 시작했던 것이 이런 문제들을 증폭했을 수도 있다. 이제 다시 되짚어 가치 있는 것들을 선정하고 그것을 개발하기 위해 집중해야 할 텐데 그것이 생각보다 만만하지 않다. 거기에 그렇다면 지금까지 개발한 것은 대체 무엇이었는가 하는 질문도 들어오는 시점이 아닌가.</p><h1 id=대충-뭔가-다-자동화할-수-있지-않을까>대충 뭔가 다 자동화할 수 있지 않을까?</h1><p>약간 다른 측면에서, AI에 대한 기대 중 하나는 대충 이런 양상이라고 생각한다. 뭔지 잘 모르겠지만, 대체 무슨 일을 어떻게 자동화할 것인지에 대한 그림은 없지만 AI/ML 기술들이 발전하면 하여간 무언가는 자동화가 될 것이라는 막연한 기대. 그나마 더 구체화된 것이 앞으로 무슨무슨 직군을 대체할 수 있으리라는 식으로 나오는 경우는 있다. 그러나 직군이 수행하는 역할이 무엇이며 어떤 작업들을 해야 하고 그 직군을 둘러싼 사회적 조건들과 특성이 어떠한지에 대한 고려는 딱히 없는 경우가 태반이다. 그래서 여하간 이것저것 대체하고 자동화하리라고 기대했는데 그런 결과는 그리 많이 나오지 않는다. 그리고 그것이 과도한 기대와 현실의 차이가 된다.</p><p>이는 위의 문제와도 연관된 것이라 할 수 있겠다. 이것저것 다 해결할 수 있을 것 같았지만 정작 실제로는 어떤 과제가 가치있을지, 그 과제를 어떻게 풀어나갈 수 있을지 탐색하는 것도 막막하고 시간이 많이 필요한 일이다. 이상과 현실의 타임라인이 어긋나기 시작하니 마찰이 발생하게 된다.</p><h1 id=그래서-지금-여기에서-무엇을-할-것인가>그래서, 지금 여기에서 무엇을 할 것인가?</h1><p>두 가지 가능성이 있으리라고 생각한다.</p><ol><li><p>다시 한 번 정말로 가치 있는 과제를 찾아내고 그 과제를 풀어내는 것에 천착하는 것. 우리가 가진 기술들, 혹은 우리가 쓰는 것을 선호하고 편안하게 느끼는 기술들이 우선이 되는 것이 아니라 정말로 쓸모 있는 제품을 설계하는 것에 집중하는 것이다. 그리고 우리가 그 제품에 사용하기 위한 기술을 만들어나가는 순간 순간에 그 기술 자체가 아니라 우리가 구축하고자 하는 제품의 목표에 부합하도록 노력하는 것.</p></li><li><p>모델의 발전이 창발적인 특성을 나타내는 형태의 모델을 사용해 모델의 발전 자체가 새로운 적용 분야와 가능성, 기능의 발견으로 이어지게 하는 것. 예컨대 대규모 언어 모델과 같은 것이 사례가 되겠다. 즉 모델의 발전(모델 크기, 데이터의 양, 학습 연산력의 규모의 증가)이 이전에 예상하지 못했던 능력의 획득으로 이어지는 사례가 되겠다. 이 새로운 능력들은 우리가 예상하지 못한 적용 사례와 가치를 창출할 가능성이 있다. 물론 그렇다고 모델이 알아서 모든 것을 해내리라고 기대할 수는 없고 방향을 구상하는 것이 필요하겠지만. (Instruct GPT가 Unsupervised Pretraining 뿐만 아니라 구체적으로 설게된 Instruction Finetuning의 결합으로 만들어진 것처럼.)</p></li></ol><p>이 둘 모두 급진적인 재정비 혹은 목표의 재설정을 요구하는 것이라고 생각한다. 그리고 이러한 실천이 요구된다는 것은 모델의 성능을 높이기 위해 튜닝하고 데이터를 수집하는 것과 같은 지금까지 ML 엔지니어로서 수행했던 것, 그리고 요구되었던 것들과는 결이 다른 요청이 등장하게 되는 시점이 되었다는 의미라고 생각한다.</p><h1 id=다시-ocr에-대해-논하자면>다시 OCR에 대해 논하자면</h1><p>추상적인 차원에서 이야기했으니 이제 구체적인 경험과 연결해야할 때가 된 것 같다. 내가 4년 좀 넘게 OCR 팀의 과제를 수행하면서 늘 부딪혔던 문제, 고민했던 문제는 이제 OCR 이후에 무엇이 올 것인가였다. 팀의 초기에는 OCR 파이프라인을 만들고, 소소하게 모델을 개선해서 성능을 향상시키거나, 혹은 데이터의 추가로 모델의 성능을 OCR이라는 과제 자체에 대해서 의미 있느 수준까지 끌어올리는 작업을 하는 것만으로도 충분했다. 그러나 OCR 파이프라인이 궤도에 오른 이후에는 그렇다면 OCR 파이프라인을 구축하는 것 이외에 무엇이 주어질 것인가 하는 문제가 중요해졌다. OCR 파이프라인의 끝없는 개선? 아주 단순하게 말하자면 OCR 파이프라인의 성능을 향상시키는 것은 기계적이고 주기적인 방식의 데이터 추가와 재학습으로도 대응할 수 있다. 우리는 그런 기계적인 작업을 반복하는 대신 다른 무언가가 필요한 것이다. (다르게 말하자면, 주기적인 데이터 추가와 재학습으로 대응할 수 있는 문제에 대해 많은 입력을 투입하고, 종종 그러는 것처럼 반복적이고 소소한 모델 개선 작업에 인력을 사용하는 것은 비효율적이라고 생각한다.)</p><p>그렇지만 사실 이러한 질문, 즉 OCR 다음은 무엇인가라는 질문은 그리 적절하지 않은 것이었던 것 같다. 이런 질문은 즉 OCR을 마무리하고 나면 그 다음 단계가 있어서 그걸 작업하면 되고, 또 그 다음 단계로 나아가면 된다는 식의 인상을 준다. 즉 지금 발견하지는 못했더라도 바로 다음의 인접한 단계가 있어서 그걸 밟아나가면 된다고 생각하는 것이다. 이는 국소적(Local)인 규모의 관점이라고 할 수 있겠다. OCR 모델의 성능을 개선하는 것처럼 점진적인 개선, 기능 추가를 통해 전체 제품을 개선하려는 것이다.</p><p>그러나 위에서 장황하게 논의한 것과 연관해서 생각하자면 순서는 반대가 되어야 한다. 혹은 관점을 전역적(Global)인 것으로 전환해야 한다. 우리가 제공하고자 하며 구축하고자 하는 제품에 대한 구상이나 설계에서 시작해서 필요한 컴포넌트들을 구축하는 식으로 작업할 수 있었다. OCR의 다음 단계가 있는 것이 아니라 채워넣어야할 다음 컴포넌트가 있는 것이다. OCR이라는, 가장 중요한 컴포넌트 혹은 제품의 전체처럼 느껴지는 과제 또한 결국 제품에 필요한 하나의 컴포넌트에 불과한 것이다. OCR의 다음 단계를 생각하면서도 이 제품의 측면에 대해서는 그다지 생각해보지 않았던 것 같다. Document Reconstruction 같이 나름대로 생각해본 것에 대해서도 이것이 정말로 어느 정도의 가치를 창출할 수 있을 것인가에 대해서는 깊게 생각해보지 않았다. 아마 의미 있을 것이라고 추측했던 것이 전부였다고 할 수도 있겠다.</p><p>다음엔 기술이 아니라 제품을 기준으로 생각할 수 있기를, 혹은 그렇게 생각해보도록 시도할 수 있기를. 물론 이것이 기술이 중요하지 않다는 것은 아니다. 새로운 기술이 주어지는 것은 새로운 가능성이 주어진다는 것이고 위에서 말했던 것처럼 기술적으로 가능하다고 생각될 때에야 생각해낼 수 있는 가치가 있는 것이다. 그러나 여전히 새로운 기술과 가능성이 곧 새로운 가치로 이어진다는 의미는 아니라는 것을 기억해야 한다.</p><h1 id=ocr의-바깥에서>OCR의 바깥에서</h1><p>기존의, 우리가 익숙한 과제들의 연장만으로는 충분하지 않은 것 같다는 감각이 강해지고 있지만 이 꺼림칙한 추측을 해소할 새로운 과제, 가치, 관점들은 아직 등장하지 않은 중간적 시점이 도래한 것 같다. 이제 새로운 가능성들이 보이기 시작하고, 그것에 대해서 충분히 의미있게 예측하는 것도 가능하긴 하지만 (늘 하는 이야기인 GPT-4는 GPT-3보다 아마 질적인 차이를 가질 것이고 아마 GPT-5 또한 GPT-4에 대해 그러할 것이라는 것과 같은) 그 가능성들이 모두 그만한 가치로 이어지리라는 보장은 할 수 없는 시점이라고 생각한다. 우리가 우리에게 익숙한 것들이 충분한 가치를 생성할 것이라고 믿었던 것이 반드시 정확하지는 않았던 것처럼.</p><p>그런 의미에서 이젠 불명확한 지점을 향해 예측하고 리스크를 감수하는 것이 요청되고 있는지도 모르겠다. 그러지 않으면 지금 이 시점에 머물러 익숙함을 반복하는 자체가 또한 리스크가 될 지도 모른다.</p><p>망치를 쥐고 있으면 세상 모든 것이 못으로 보인다지만, 지금의 문제는 못 같이 보이는 것조차 발견하기가 쉽지 않다는 것이지 않을까 싶다. 일단 못이건 다른 무엇이건 망치를 휘두를 수 있는 대상이 있다면 휘두르는 것이 맞을 수 있다. 적합한 도구를 쓰는 것에 비할 바는 아니겠지만 망치를 들고 우두커니 서 있는 것보다는 나을 것이다.</p><h1 id=그-외-소소한-생각들>그 외, 소소한 생각들</h1><p>이렇게 나열하니 무언가 대단한 가르침이나 격언인 것 같다. 실은 그저 내 경험을 간결하게 요약해보려는 시도일 뿐이다. 고작해야 $N = 1$일 뿐이다.</p><h3 id=the-bitter-lesson>The Bitter Lesson</h3><p><a href=http://www.incompleteideas.net/IncIdeas/BitterLesson.html>http://www.incompleteideas.net/IncIdeas/BitterLesson.html</a> (한국어 역: <a href=https://newsight.tistory.com/302>https://newsight.tistory.com/302</a>)</p><p>혹시 읽어보지 않은 이들이 있다면 꼭 읽어보라고 권하고 싶다. The Bitter Lesson은 AI/ML을 통틀어 논한 것이지만 딥 러닝에 국한해서도 동일하게 적용되는 것처럼 보인다. 단순하고, 학습과 탐색에 기반하고, 더 큰 모델, 더 많은 데이터, 더 강력한 연산력에 기반한 방법이야말로 더 장기적으로 성공적이며, 더 유지보수하기 쉽다. 하나의 모델에 대해 수많은 튜닝을 하는 방법들이 등장하지만 장기적으로 의미 있는 도구는 그리 많지 않다. 우리가 생각하기에 좋은 방법처럼 느껴지는 것을 결합하거나 튜닝하기 위해 집착하는 것은 별로 좋지 않다. 혹은 의도적으로 그러지 않으려 시도하는 것도 가능할 것 같다.</p><h3 id=언제나-큰-문제부터-찾기>언제나 큰 문제부터 찾기</h3><p>모델이 잘 작동하지 않으면 보통 행여나 작은 디테일들, 소소한 하이퍼파라미터 등의 차이에서 기인한 것이 아닐까 추측하기 쉽다. 어쩌면 사람은 스스로 큰 실수를 저질렀을 것이라기보단 작은 디테일을 커버하지 않았다고 생각하고 싶어하는 것 같다. 모델이 예상대로 학습하지 않거나 작동하지 않는다면 언제나 큰 실수가 있지 않은지를 먼저 생각해야 한다.</p><h3 id=데이터로-해결할-수-있는-것이라면-데이터가-가장-저렴할-수-있다>데이터로 해결할 수 있는 것이라면 데이터가 가장 저렴할 수 있다</h3><p>성능이 문제라면 작은 튜닝과 소소한 개선으로 점진적인 성능 향상을 꾀하기 전에 추가적인 데이터를 사용할 수 있는지를 먼저 고려하자. 기존 모델을 약간씩 개선하는 것보다는 새로운 문제를 푸는 것이 더 가치있을 수 있다.</p><h3 id=단기적인-해결이-아닌-장기적으로-유용한-대안을>단기적인 해결이 아닌 장기적으로 유용한 대안을</h3><p>혹은 최소한 단기적인 해결이 장기적인 해결책에 방해가 되거나 자원의 낭비가 되지 않도록 고려해야 한다.</p><h3 id=어쩌면-학습-기반-모델을-쓰는-것이-더-저렴하다>어쩌면 학습 기반 모델을 쓰는 것이 더 저렴하다</h3><p>위의 생각과 연결되는 것이라고도 할 수 있겠다. 어떤 문제가 주어지고 그 문제를 휴리스틱이나 알고리즘으로 풀 수 있닥소 생각하면 으레 그쪽이 선호되기 마련이다. 혹은 이런 이야기가 격언처럼 돌아다니기도 한다. 예를 들면 휴리스틱을 사용하면 풀 수 있는 문제를 다들 학습 기반 모델로 풀려고 하는 것이 문제다와 같은 식으로. 그러나 이것은 이 문제가 단발성으로 끝날 때에 한정된 것이다. 앞으로 문제의 요구 사항이 늘어난다면, 더 나아가 그 요구사항이 휴리스틱으로 커버하기 어려운 것이라면 휴리스틱보다는 학습 기반 모델이 더 명료하고 더 유지보수하기 쉬울 수 있다. 따라서 앞으로 어떤 예외와 요구사항과 코너 케이스가 발생할 수 있는가에 대해 고려해야 한다.</p><h3 id=전체-도메인에서-쉬운-일부-케이스로-국한하는-것을-조심할-것>전체 도메인에서 쉬운 일부 케이스로 국한하는 것을 조심할 것</h3><p>전체 문제나 도메인을 모두 포괄하는 것은 까다로운 일이고, 그 문제를 조금 축소한다면 난이도가 훨씬 쉬워지는 경우가 많다. 대강 대체 이런 케이스까지 커버할 필요가 있겠어라고 생각하고 문제를 좀 더 쉽게 풀고자 하는 것은 강력한 유혹이다. 그러나 그 코너 케이스가 장기적으로 중요한 문제가 될 수 있다는 것을 고려해야 한다. 오히려 더 광범위하고 더 넓은 문제, 도메인에 적용될 가능성을 생각해보는 것 또한 의미가 있다.</p><h3 id=모델과-사랑에-빠지지-말-것>모델과 사랑에 빠지지 말 것</h3><p>내가 선호하는 방법, 만들어놓은 모델에 집착하지 말 것. 가장 효율적이고 효과적인 방법과 모델을 우선할 것. 각자의 모델들이 경쟁하는 상황을 경계하고 모두의 작업과 개선물들이 반영될 수 있는 형태로 작업할 수 있도록 협업을 설계할 것.</p><h3 id=다른-이들에게-필요한-것을-공개할-것>다른 이들에게 필요한 것을 공개할 것</h3><p>사람들은 왕왕 자신에게 필요한 요청 사항들에 대해서는 공개적으로 발언하면서 다른 이들에게 유용하거나 필요한 정보들에 대해서는 공개하지 않는 경우가 있다. 구체적으로는 업무적 진행 사항들과 의사 결정에 대한 정보가 공유되지 않는 것이다. 업무가 사적이거나 1대 1 의사소통만으로 진행되거나 혹은 개인적인 판단만으로 중요한 결정이 진행될 수도 있다.</p><p>다만 다른 사람들에게 필요한 정보를 먼저 공유하는 것은 상당히 어색한 일이다. 이건 HCI 실험 등에서 사용되는 Think Aloud (<a href=https://en.wikipedia.org/wiki/Think_aloud_protocol>https://en.wikipedia.org/wiki/Think_aloud_protocol</a>) 처럼 생각해볼 수도 있을 것 같다. 즉 작업을 진행하면서 떠오르는 생각, 추측들, 의사결정들을 생각으로 그치는 것이 아니라 직접 발언하는 것이다. 언제나 공식적인 방법과 통로로 소통하고 작업할 것. 나를 전혀 모르는 이들도 협업할 수 있는 대상이 되도록 할 것.</p></div></div><div id=post-footer class="post-footer main-content-wrap"><div class=post-footer-tags><span class="text-color-light text-small"></span><br><a class="tag tag--primary tag--small" href=http://rosinality.github.io//tags/ocr/>ocr</a>
<a class="tag tag--primary tag--small" href=http://rosinality.github.io//tags/memoir/>memoir</a>
<a class="tag tag--primary tag--small" href=http://rosinality.github.io//tags/machine-learning/>machine learning</a></div><div class=post-actions-wrap><nav><ul class="post-actions post-action-nav"><li class=post-action><a class="post-action-btn btn btn--disabled"><i class="fa fa-angle-left"></i><span class="hide-xs hide-sm text-small icon-ml"></span></a></li><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-7/ data-tooltip="텔 아비브와 ECCV 2022 여행기 7"><span class="hide-xs hide-sm text-small icon-mr"></span><i class="fa fa-angle-right"></i></a></li></ul></nav><ul class="post-actions post-action-share"><li class="post-action hide-lg hide-md hide-sm"><a class="post-action-btn btn btn--default btn-open-shareoptions" href=#btn-open-shareoptions><i class="fa fa-share-alt"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://plus.google.com/share?url=http%3a%2f%2frosinality.github.io%2f2023%2f01%2focr-%25ED%259A%258C%25EA%25B3%25A0%2f"><i class="fa fa-google-plus"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://www.facebook.com/sharer/sharer.php?u=http%3a%2f%2frosinality.github.io%2f2023%2f01%2focr-%25ED%259A%258C%25EA%25B3%25A0%2f"><i class="fa fa-facebook-official"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://twitter.com/intent/tweet?text=http%3a%2f%2frosinality.github.io%2f2023%2f01%2focr-%25ED%259A%258C%25EA%25B3%25A0%2f"><i class="fa fa-twitter"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#disqus_thread><i class="fa fa-comment-o"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#><i class="fa fa-list"></i></a></li></ul></div><div id=disqus_thread><noscript>Please enable JavaScript to view the <a href=//disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div></div></article><footer id=footer class=main-content-wrap><span class=copyrights>&copy; 2023 Kim Seonghyeon.</span></footer></div><div id=share-options-bar class=share-options-bar data-behavior=5><ul class=share-options><li class=share-option><a class=share-option-btn target=new href="https://plus.google.com/share?url=http%3a%2f%2frosinality.github.io%2f2023%2f01%2focr-%25ED%259A%258C%25EA%25B3%25A0%2f"><i class="fa fa-google-plus"></i><span></span></a></li><li class=share-option><a class=share-option-btn target=new href="https://www.facebook.com/sharer/sharer.php?u=http%3a%2f%2frosinality.github.io%2f2023%2f01%2focr-%25ED%259A%258C%25EA%25B3%25A0%2f"><i class="fa fa-facebook-official"></i><span></span></a></li><li class=share-option><a class=share-option-btn target=new href="https://twitter.com/intent/tweet?text=http%3a%2f%2frosinality.github.io%2f2023%2f01%2focr-%25ED%259A%258C%25EA%25B3%25A0%2f"><i class="fa fa-twitter"></i><span></span></a></li></ul></div><div id=share-options-mask class=share-options-mask></div></div><div id=about><div id=about-card><div id=about-btn-close><i class="fa fa-remove"></i></div><img id=about-card-picture src="//www.gravatar.com/avatar/63eec5e671fc734bde45cd43cc156abc?s=110" alt><h4 id=about-card-name>Kim Seonghyeon</h4><div id=about-card-bio>Machine learning enthusiast</div><div id=about-card-job><i class="fa fa-briefcase"></i><br>Graduate student in HCCLab at Seoul National University</div><div id=about-card-location><i class="fa fa-map-marker"></i><br>Korea, Republic of</div></div></div><div id=algolia-search-modal class=modal-container><div class=modal><div class=modal-header><span class=close-button><i class="fa fa-close"></i></span><a href=https://algolia.com target=_blank class="searchby-algolia text-color-light link-unstyled"><span class="searchby-algolia-text text-color-light text-small">by</span>
<img class=searchby-algolia-logo src=https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg></a>
<i class="search-icon fa fa-search"></i><form id=algolia-search-form><input type=text id=algolia-search-input name=search class="form-control input--large search-input" placeholder></form></div><div class=modal-body><div class="no-result text-color-light text-center"></div><div class=results><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/01/ocr-%ED%9A%8C%EA%B3%A0/><h3 class=media-heading>OCR 회고</h3></a><span class=media-meta><span class="media-date text-small">Jan 1, 2023</span></span><div class="media-content hide-xs font-merryweather">타이틀 커버 이미지 출처: https://www.behance.net/gallery/6146939/OCR-A-Poster/modules/152114859 4년 동안 몰두했던 OCR이라는 주제를 마무리하게 되면서 으레 그래왔듯 회고를 남겨본다. 이랬더라면 어땠을까 같은 소소한 소회보다는</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/post/><h3 class=media-heading>Posts</h3></a><span class=media-meta><span class="media-date text-small">Jan 1, 2023</span></span><div class="media-content hide-xs font-merryweather"></div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-7/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 7</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-6/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 6</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-5/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 5</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-4/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 4</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-3/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 3</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-2/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 2</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-1/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 1</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2021/05/%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D-%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%97%90%EC%84%9C-%EC%84%A4%EC%A0%95-%EA%B4%80%EB%A6%AC%ED%95%98%EA%B8%B0/><h3 class=media-heading>머신 러닝 시스템에서 설정 관리하기</h3></a><span class=media-meta><span class="media-date text-small">May 5, 2021</span></span><div class="media-content hide-xs font-merryweather">머신 러닝 코드, 특히 실험적 목적이 강한 코드에서 가장 중요한 문제 중 하나가 설정을 관리하는 것이라고 본다. 머신 러닝 모델에는 수많은 하이퍼파라미터가 존재하고 그</div></div><div style=clear:both></div><hr></div></div></div><div class=modal-footer><p class="results-count text-medium" data-message-zero data-message-one data-message-other>62 posts found</p></div></div></div><div id=cover style=background-image:url(http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/stair.jpg)></div><script>(function(d){var config={kitId:'vld6lxf',scriptTimeout:3000,async:true},h=d.documentElement,t=setTimeout(function(){h.className=h.className.replace(/\bwf-loading\b/g,"")+" wf-inactive";},config.scriptTimeout),tk=d.createElement("script"),f=false,s=d.getElementsByTagName("script")[0],a;h.className+=" wf-loading";tk.src='https://use.typekit.net/'+config.kitId+'.js';tk.async=true;tk.onload=tk.onreadystatechange=function(){a=this.readyState;if(f||a&&a!="complete"&&a!="loaded")return;f=true;clearTimeout(t);try{Typekit.load(config)}catch(e){}};s.parentNode.insertBefore(tk,s)})(document);</script><script src=//cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.js></script><script type=text/javascript src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type=text/x-mathjax-config>
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']],
    processEscapes: true,
    processEnvironments: true,
    preview: "none",
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script><script src=/js/script-wl33z0n6ocaypepiqrazthtivfrliqijej4rq8ek8gvrv1awftmgjuv8k4zc.min.js></script><script>$(document).ready(function(){hljs.configure({classPrefix:'',useBR:false});$('pre.code-highlight').each(function(i,block){var code="";hljs.highlightAuto(block.innerText).value.split(/\r\n|\r|\n/).forEach(function(line){code+="<span class=\"line\">"+line+"</span><br>";});if(code.length>0){block.innerHTML=code;}});$('pre > code').each(function(i,block){$(this).addClass('codeblock');hljs.highlightBlock(block);});});</script><script>var disqus_config=function(){this.page.url='http:\/\/rosinality.github.io\/2023\/01\/ocr-%ED%9A%8C%EA%B3%A0\/';this.page.identifier='\/2023\/01\/ocr-%ED%9A%8C%EA%B3%A0\/'};(function(){if(window.location.hostname=="localhost"){return;}
var d=document,s=d.createElement('script');var disqus_shortname='rosinality';s.src='//'+disqus_shortname+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script></body></html>