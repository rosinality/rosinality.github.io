<!doctype html><html lang=ko-kr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.73.0"><meta name=theme content="Tranquilpeak 0.3.1-BETA"><title>sorta informative</title><meta name=author content="Kim Seonghyeon"><meta name=keywords content=",machine learning,deep learning,social science"><link rel=icon href=/favicon.png><link rel=alternate type=application/rss+xml title=RSS href=http://rosinality.github.io/categories/sorta-informative/index.xml><meta name=description content><meta property="og:description" content><meta property="og:type" content="blog"><meta property="og:title" content="sorta informative"><meta property="og:url" content="/categories/sorta-informative/"><meta property="og:site_name" content="Nondifferentiable Log"><meta name=twitter:card content="summary"><meta name=twitter:title content="Nondifferentiable Log"><meta name=twitter:description content><meta name=twitter:creator content="@rosinality"><meta property="og:image" content="//www.gravatar.com/avatar/63eec5e671fc734bde45cd43cc156abc?s=640"><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css><link rel=stylesheet href=/css/style-u6mk0ojoywresbx8iepslrmmhl4stuhrsxuwhkpwrkrx7mryjcaimasnk4pi.min.css></head><body><div id=blog><header id=header data-behavior=5><i id=btn-open-sidebar class="fa fa-lg fa-bars"></i><div class=header-title><a class=header-title-link href=/>Nondifferentiable Log</a></div></header><nav id=sidebar data-behavior=5><div class=sidebar-container><div class=sidebar-profile><a href=/#about><img class=sidebar-profile-picture src="//www.gravatar.com/avatar/63eec5e671fc734bde45cd43cc156abc?s=110" alt></a><h4 class=sidebar-profile-name>Kim Seonghyeon</h4><h5 class=sidebar-profile-bio>Machine learning enthusiast</h5></div><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=/categories><i class="sidebar-button-icon fa fa-lg fa-bookmark"></i><span class=sidebar-button-desc>Categories</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/tags><i class="sidebar-button-icon fa fa-lg fa-tags"></i><span class=sidebar-button-desc>Tags</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/archives><i class="sidebar-button-icon fa fa-lg fa-archive"></i><span class=sidebar-button-desc>Archives</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/#about><i class="sidebar-button-icon fa fa-lg fa-question"></i><span class=sidebar-button-desc>About</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=/><i class="sidebar-button-icon fa fa-lg fa-home"></i><span class=sidebar-button-desc>Home</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://github.com/rosinality target=_blank><i class="sidebar-button-icon fa fa-lg fa-github"></i><span class=sidebar-button-desc>GitHub</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=/index.xml><i class="sidebar-button-icon fa fa-lg fa-rss"></i><span class=sidebar-button-desc>RSS</span></a></li></ul></div></nav><div id=main data-behavior=5 class=hasCoverMetaIn><section class="postShorten-group main-content-wrap"><article class="postShorten postShorten--thumbnailimg-top" itemscope itemtype=http://schema.org/BlogPosting><div class=postShorten-wrap><a href=http://rosinality.github.io/2017/05/%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8%EC%9D%84-%EB%A7%8C%EB%93%A4%EA%B8%B0/><div class=postShorten-thumbnailimg><img alt itemprop=image src=http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/brussels-forest></div></a><div class=postShorten-header><h1 class=postShorten-title itemprop=headline><a class=link-unstyled href=http://rosinality.github.io/2017/05/%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8%EC%9D%84-%EB%A7%8C%EB%93%A4%EA%B8%B0/>머신 러닝 모델을 만들기</a></h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2017-05-08T22:31:57+09:00>May 8, 2017</time>
<span></span><a class=category-link href=/categories/sorta-informative>sorta informative</a></div></div><div class=postShorten-excerpt itemprop=articleBody><p>머신 러닝을 하는데 성능이 잘 안 나온다는 질문이 종종 보여서, 모델 성능 평가의 왕도를 소개해봄. 사실 Deep Learning book의 챕터 11에 나오는 내용. 전처리를 하고 데이터 …<br><a href=http://rosinality.github.io/2017/05/%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8%EC%9D%84-%EB%A7%8C%EB%93%A4%EA%B8%B0/ class="postShorten-excerpt_link link"></a></p></div></div></article><article class="postShorten postShorten--thumbnailimg-top" itemscope itemtype=http://schema.org/BlogPosting><div class=postShorten-wrap><a href=http://rosinality.github.io/2017/05/2017-%EB%8C%80%EC%84%A0-%EC%97%AC%EB%A1%A0%EC%A1%B0%EC%82%AC-%EB%B6%84%EC%84%9D/><div class=postShorten-thumbnailimg><img alt itemprop=image src=http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/poll></div></a><div class=postShorten-header><h1 class=postShorten-title itemprop=headline><a class=link-unstyled href=http://rosinality.github.io/2017/05/2017-%EB%8C%80%EC%84%A0-%EC%97%AC%EB%A1%A0%EC%A1%B0%EC%82%AC-%EB%B6%84%EC%84%9D/>2017 대선 여론조사 분석</a></h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2017-05-01T03:05:27+09:00>May 1, 2017</time>
<span></span><a class=category-link href=/categories/sorta-informative>sorta informative</a></div></div><div class=postShorten-excerpt itemprop=articleBody><p>우선, 2012년에는 우선 2012년 여론조사와 실제 대선 결과를 비교해보면 다음과 같다. 여론조사 결과의 경우 합이 100이 되도록 각 값을 값의 합으로 나눴다. …<br><a href=http://rosinality.github.io/2017/05/2017-%EB%8C%80%EC%84%A0-%EC%97%AC%EB%A1%A0%EC%A1%B0%EC%82%AC-%EB%B6%84%EC%84%9D/ class="postShorten-excerpt_link link"></a></p></div></div></article><article class="postShorten postShorten--thumbnailimg-top" itemscope itemtype=http://schema.org/BlogPosting><div class=postShorten-wrap><a href=http://rosinality.github.io/2017/04/caffe2%EC%97%90-%EB%8C%80%ED%95%B4/><div class=postShorten-thumbnailimg><img alt itemprop=image src=http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/coffee></div></a><div class=postShorten-header><h1 class=postShorten-title itemprop=headline><a class=link-unstyled href=http://rosinality.github.io/2017/04/caffe2%EC%97%90-%EB%8C%80%ED%95%B4/>Caffe2에 대해</a></h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2017-04-25T15:28:52+09:00>April 25, 2017</time>
<span></span><a class=category-link href=/categories/sorta-informative>sorta informative</a></div></div><div class=postShorten-excerpt itemprop=articleBody><p>PyTorch랑 장기적으로 백엔드를 통합한다니까 관심이 생겨서 Caffe2를 좀 들여다봤음. Caffe를 써본 적은 없음. protocol buffer 파일을 만들어서 돌린다는 것 …<br><a href=http://rosinality.github.io/2017/04/caffe2%EC%97%90-%EB%8C%80%ED%95%B4/ class="postShorten-excerpt_link link"></a></p></div></div></article><article class="postShorten postShorten--thumbnailimg-top" itemscope itemtype=http://schema.org/BlogPosting><div class=postShorten-wrap><a href=http://rosinality.github.io/2017/04/%EB%B6%84%EC%84%9D%EC%82%AC%ED%9A%8C%ED%95%99%EA%B3%BC-%EC%9D%B8%EA%B3%BC%EC%A0%81-%EC%84%A4%EB%AA%85/><div class=postShorten-thumbnailimg><img alt itemprop=image src=http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/lamp.jpg></div></a><div class=postShorten-header><h1 class=postShorten-title itemprop=headline><a class=link-unstyled href=http://rosinality.github.io/2017/04/%EB%B6%84%EC%84%9D%EC%82%AC%ED%9A%8C%ED%95%99%EA%B3%BC-%EC%9D%B8%EA%B3%BC%EC%A0%81-%EC%84%A4%EB%AA%85/>분석사회학과 인과적 설명</a></h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2017-04-21T16:23:15+09:00>April 21, 2017</time>
<span></span><a class=category-link href=/categories/sorta-informative>sorta informative</a></div></div><div class=postShorten-excerpt itemprop=articleBody><p>사회학하면 어쩐지 거대한 이론과 담론들로 대표되는 것 같다. 실제로 그게 주요한 사회학의 전통이라고 해도 크게 틀리지는 않을 것이다. 그와는 좀 다른 전통이 있는데 그 …<br><a href=http://rosinality.github.io/2017/04/%EB%B6%84%EC%84%9D%EC%82%AC%ED%9A%8C%ED%95%99%EA%B3%BC-%EC%9D%B8%EA%B3%BC%EC%A0%81-%EC%84%A4%EB%AA%85/ class="postShorten-excerpt_link link"></a></p></div></div></article><article class="postShorten postShorten--thumbnailimg-top" itemscope itemtype=http://schema.org/BlogPosting><div class=postShorten-wrap><a href=http://rosinality.github.io/2017/04/%EB%AA%A8%EB%9E%98%EB%8D%94%EB%AF%B8-%EB%AA%A8%ED%98%95/><div class=postShorten-thumbnailimg><img alt itemprop=image src=http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/desert.jpg></div></a><div class=postShorten-header><h1 class=postShorten-title itemprop=headline><a class=link-unstyled href=http://rosinality.github.io/2017/04/%EB%AA%A8%EB%9E%98%EB%8D%94%EB%AF%B8-%EB%AA%A8%ED%98%95/>모래더미 모형</a></h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2017-04-21T16:22:52+09:00>April 21, 2017</time>
<span></span><a class=category-link href=/categories/sorta-informative>sorta informative</a></div></div><div class=postShorten-excerpt itemprop=articleBody><p>모래더미 모형이라고 마크 뷰캐넌이 자주 써먹는 모형이 있다. 복잡한 모형은 아니다. 평평한 평면 위 어느 한 곳에 모래를 하나 떨어뜨린다고 하자. 똑같은 곳에 모래가 또 …<br><a href=http://rosinality.github.io/2017/04/%EB%AA%A8%EB%9E%98%EB%8D%94%EB%AF%B8-%EB%AA%A8%ED%98%95/ class="postShorten-excerpt_link link"></a></p></div></div></article><article class="postShorten postShorten--thumbnailimg-top" itemscope itemtype=http://schema.org/BlogPosting><div class=postShorten-wrap><a href=http://rosinality.github.io/2017/04/%EB%B0%B0%EC%B9%98-%EC%A0%95%EA%B7%9C%ED%99%94-2/><div class=postShorten-thumbnailimg><img alt itemprop=image src=http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/batches.jpg></div></a><div class=postShorten-header><h1 class=postShorten-title itemprop=headline><a class=link-unstyled href=http://rosinality.github.io/2017/04/%EB%B0%B0%EC%B9%98-%EC%A0%95%EA%B7%9C%ED%99%94-2/>배치 정규화 2</a></h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2017-04-21T16:18:05+09:00>April 21, 2017</time>
<span></span><a class=category-link href=/categories/sorta-informative>sorta-informative</a></div></div><div class=postShorten-excerpt itemprop=articleBody><p>batch normalization의 문제 의식은 뉴럴넷에서 하나의 레이어의 출력은 이전의 레이어의 출력에 의해 영향을 받기에, 깊은 뉴럴넷에서는 이런 &ldquo …<br><a href=http://rosinality.github.io/2017/04/%EB%B0%B0%EC%B9%98-%EC%A0%95%EA%B7%9C%ED%99%94-2/ class="postShorten-excerpt_link link"></a></p></div></div></article><article class="postShorten postShorten--thumbnailimg-top" itemscope itemtype=http://schema.org/BlogPosting><div class=postShorten-wrap><a href=http://rosinality.github.io/2017/04/%EB%B9%84%ED%8B%80%EC%A6%88%EA%B0%80-%EC%84%B1%EA%B3%B5%ED%95%9C-%EC%9D%B4%EC%9C%A0/><div class=postShorten-thumbnailimg><img alt itemprop=image src=http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/abbey-road.jpg></div></a><div class=postShorten-header><h1 class=postShorten-title itemprop=headline><a class=link-unstyled href=http://rosinality.github.io/2017/04/%EB%B9%84%ED%8B%80%EC%A6%88%EA%B0%80-%EC%84%B1%EA%B3%B5%ED%95%9C-%EC%9D%B4%EC%9C%A0/>비틀즈가 성공한 이유</a></h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2017-04-21T16:13:20+09:00>April 21, 2017</time>
<span></span><a class=category-link href=/categories/sorta-informative>sorta informative</a></div></div><div class=postShorten-excerpt itemprop=articleBody><p>Watts가 Turco & Zuckerman이 쓴 비판에 대한 대응으로 쓴 Response to Turco and Zuckerman’s “Versthen for Sociology"라는 글에서 나온 예시 중에 이런 게 있음. 비틀 …<br><a href=http://rosinality.github.io/2017/04/%EB%B9%84%ED%8B%80%EC%A6%88%EA%B0%80-%EC%84%B1%EA%B3%B5%ED%95%9C-%EC%9D%B4%EC%9C%A0/ class="postShorten-excerpt_link link"></a></p></div></div></article><article class="postShorten postShorten--thumbnailimg-top" itemscope itemtype=http://schema.org/BlogPosting><div class=postShorten-wrap><a href=http://rosinality.github.io/2017/04/%EA%B2%BD%ED%97%98%EC%A0%81-%EC%9C%84%ED%97%98-%EC%B5%9C%EC%86%8C%ED%99%94/><div class=postShorten-thumbnailimg><img alt itemprop=image src=http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/exit.jpg></div></a><div class=postShorten-header><h1 class=postShorten-title itemprop=headline><a class=link-unstyled href=http://rosinality.github.io/2017/04/%EA%B2%BD%ED%97%98%EC%A0%81-%EC%9C%84%ED%97%98-%EC%B5%9C%EC%86%8C%ED%99%94/>경험적 위험 최소화</a></h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2017-04-21T16:02:37+09:00>April 21, 2017</time>
<span></span><a class=category-link href=/categories/sorta-informative>sorta informative</a></div></div><div class=postShorten-excerpt itemprop=articleBody><p>Breiman이 Statistical Modeling: The Two Cultures에서 보여줬던 것처럼 통계적 모델링에는 대체로 두 가지 경로가 있다. 하나는 데이터의 생성 과정을 기술하여 데이터를 모 …<br><a href=http://rosinality.github.io/2017/04/%EA%B2%BD%ED%97%98%EC%A0%81-%EC%9C%84%ED%97%98-%EC%B5%9C%EC%86%8C%ED%99%94/ class="postShorten-excerpt_link link"></a></p></div></div></article><article class="postShorten postShorten--thumbnailimg-top" itemscope itemtype=http://schema.org/BlogPosting><div class=postShorten-wrap><a href=http://rosinality.github.io/2017/04/wasserstein-%EA%B1%B0%EB%A6%AC/><div class=postShorten-thumbnailimg><img alt itemprop=image src=https://res.cloudinary.com/rosinality/image/upload/v1492740759/covers/earthmover.jpg></div></a><div class=postShorten-header><h1 class=postShorten-title itemprop=headline><a class=link-unstyled href=http://rosinality.github.io/2017/04/wasserstein-%EA%B1%B0%EB%A6%AC/>Wasserstein 거리</a></h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2017-04-21T11:12:59+09:00>April 21, 2017</time>
<span></span><a class=category-link href=/categories/sorta-informative>sorta informative</a></div></div><div class=postShorten-excerpt itemprop=articleBody><p>지금 시점에서는 나온지 좀 되긴 했지만 여전히 재미있는 Wasserstein GAN에 대해서 정리해본다. 뉴럴넷이라는 측면에서도 재미있지만 나오는 수학도 재미있다. Read-through: Wasserstein GAN과 …<br><a href=http://rosinality.github.io/2017/04/wasserstein-%EA%B1%B0%EB%A6%AC/ class="postShorten-excerpt_link link"></a></p></div></div></article><article class="postShorten postShorten--thumbnailimg-top" itemscope itemtype=http://schema.org/BlogPosting><div class=postShorten-wrap><a href=http://rosinality.github.io/2017/04/%EC%83%81%EC%8B%9D%EA%B3%BC-%EC%82%AC%ED%9A%8C%ED%95%99%EC%A0%81-%EC%84%A4%EB%AA%85-2/><div class=postShorten-thumbnailimg><img alt itemprop=image src=https://res.cloudinary.com/rosinality/image/upload/v1492734051/covers/road2x.jpg></div></a><div class=postShorten-header><h1 class=postShorten-title itemprop=headline><a class=link-unstyled href=http://rosinality.github.io/2017/04/%EC%83%81%EC%8B%9D%EA%B3%BC-%EC%82%AC%ED%9A%8C%ED%95%99%EC%A0%81-%EC%84%A4%EB%AA%85-2/>상식과 사회학적 설명 2</a></h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2017-04-21T11:03:26+09:00>April 21, 2017</time>
<span></span><a class=category-link href=/categories/sorta-informative>sorta informative</a></div></div><div class=postShorten-excerpt itemprop=articleBody><p>와츠의 상식과 사회학적 설명은 개인적으로 정말 좋아하는 논문이라 이전에 잠깐 요약을 했었다. 요약을 더 요약하자면 와츠의 논지는 다음과 같다. 사회학 이론들은 대부 …<br><a href=http://rosinality.github.io/2017/04/%EC%83%81%EC%8B%9D%EA%B3%BC-%EC%82%AC%ED%9A%8C%ED%95%99%EC%A0%81-%EC%84%A4%EB%AA%85-2/ class="postShorten-excerpt_link link"></a></p></div></div></article><div class=pagination-bar><ul class=pagination><li class=pagination-prev><a class="btn btn--default btn--small" href=/categories/sorta-informative/><i class="fa fa-angle-left text-base icon-mr"></i><span></span></a></li><li class=pagination-next><a class="btn btn--default btn--small" href=/categories/sorta-informative/page/3/><span></span><i class="fa fa-angle-right text-base icon-ml"></i></a></li><li class=pagination-number></li></ul></div></section><footer id=footer class=main-content-wrap><span class=copyrights>&copy; 2024 Kim Seonghyeon.</span></footer></div></div><div id=about><div id=about-card><div id=about-btn-close><i class="fa fa-remove"></i></div><img id=about-card-picture src="//www.gravatar.com/avatar/63eec5e671fc734bde45cd43cc156abc?s=110" alt><h4 id=about-card-name>Kim Seonghyeon</h4><div id=about-card-bio>Machine learning enthusiast</div><div id=about-card-job><i class="fa fa-briefcase"></i><br>Graduate student in HCCLab at Seoul National University</div><div id=about-card-location><i class="fa fa-map-marker"></i><br>Korea, Republic of</div></div></div><div id=algolia-search-modal class=modal-container><div class=modal><div class=modal-header><span class=close-button><i class="fa fa-close"></i></span><a href=https://algolia.com target=_blank class="searchby-algolia text-color-light link-unstyled"><span class="searchby-algolia-text text-color-light text-small">by</span>
<img class=searchby-algolia-logo src=https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg></a>
<i class="search-icon fa fa-search"></i><form id=algolia-search-form><input type=text id=algolia-search-input name=search class="form-control input--large search-input" placeholder></form></div><div class=modal-body><div class="no-result text-color-light text-center"></div><div class=results><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/post/><h3 class=media-heading>Posts</h3></a><span class=media-meta><span class="media-date text-small">Sep 9, 2024</span></span><div class="media-content hide-xs font-merryweather"></div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2024/09/scaling-law-architecture-for-stability-and-layer-stacking/><h3 class=media-heading>Scaling Law, Architecture for Stability and Layer Stacking</h3></a><span class=media-meta><span class="media-date text-small">Sep 9, 2024</span></span><div class="media-content hide-xs font-merryweather">Scaling Law Scaling law is one of the most important findings in LLMs (and neural networks in general) 1. You can make almost all important decisions about training of models with scaling law. For example you can choose model size, number of training steps 2, hyperparameters such as learning rate and batch size 3, learning rate schedules 4, mixture of training datasets 5, etc. So if you are serious about</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2024/06/preliminary-explorations-on-ul2-and-second-order-optimizers/><h3 class=media-heading>Preliminary Explorations on UL2 and Second-order Optimizers</h3></a><span class=media-meta><span class="media-date text-small">Jun 6, 2024</span></span><div class="media-content hide-xs font-merryweather">In the field of large language models, the most important recipes to cook the model is not opened to publics. Model architecture itself is quite well-known because many state-of-the-art models are now open weights, and in many cases we find it is a boringly simple vanilla transformers. But for datasets and training objectives it is not well known, and many LLM builders deliberately obfuscates the details of these two. And,</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/07/constitutional-ai/><h3 class=media-heading>Constitutional AI</h3></a><span class=media-meta><span class="media-date text-small">Jul 7, 2023</span></span><div class="media-content hide-xs font-merryweather">Helpful & Harmless Agent AI 모델의 정렬(Alignment)이라고 이야기할 때 흔히 나오는 Helpfulness와 Harmlessness는 어떤 의미인가? 이는 정의</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/02/%EC%9D%B4%EB%AF%B8%EC%A7%80%EC%99%80-%ED%85%8D%EC%8A%A4%ED%8A%B8-%EC%83%9D%EC%84%B1-%EB%AA%A8%EB%8D%B8%EC%97%90-%EB%8C%80%ED%95%B4/><h3 class=media-heading>이미지와 텍스트 생성 모델에 대해</h3></a><span class=media-meta><span class="media-date text-small">Feb 2, 2023</span></span><div class="media-content hide-xs font-merryweather">이미지 생성 하면 Style GAN이었던 시절에도 일러스트 생성 등은 오타쿠적 인기가 있는 주제였다. 문제의 Danbooru 데이터셋 같은 경우에도 그 시점에 이미 만들어진 데이터셋이었</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/02/%EC%96%B8%EC%96%B4%EC%9D%98-%EC%86%90%EC%8B%A4-%EC%95%95%EC%B6%95%EC%97%90-%EB%8C%80%ED%95%98%EC%97%AC/><h3 class=media-heading>언어의 손실 압축에 대하여</h3></a><span class=media-meta><span class="media-date text-small">Feb 2, 2023</span></span><div class="media-content hide-xs font-merryweather">https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web LM을 다음 단어를 예측할 뿐이라거나 학습 데이터를 기억할 뿐이라는 식으로 묘사하는 것은 폄하를 위한 언어이지 LM의 실체나 실제 한계에 대해서 논하기에 적절한 방</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2023/01/ocr-%ED%9A%8C%EA%B3%A0/><h3 class=media-heading>OCR 회고</h3></a><span class=media-meta><span class="media-date text-small">Jan 1, 2023</span></span><div class="media-content hide-xs font-merryweather">타이틀 커버 이미지 출처: https://www.behance.net/gallery/6146939/OCR-A-Poster/modules/152114859 4년 동안 몰두했던 OCR이라는 주제를 마무리하게 되면서 으레 그래왔듯 회고를 남겨본다. 이랬더라면 어땠을까 같은 소소한 소회보다는</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-7/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 7</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-6/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 6</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div><div class=media><div class=media-body><a class=link-unstyled href=http://rosinality.github.io/2022/11/%ED%85%94-%EC%95%84%EB%B9%84%EB%B8%8C%EC%99%80-eccv-2022-%EC%97%AC%ED%96%89%EA%B8%B0-5/><h3 class=media-heading>텔 아비브와 ECCV 2022 여행기 5</h3></a><span class=media-meta><span class="media-date text-small">Nov 11, 2022</span></span><div class="media-content hide-xs font-merryweather">텔 아비브와 ECCV 2022 여행기 1 텔 아비브와 ECCV 2022 여행기 2 텔 아비브와 ECCV 2022 여행기 3 텔 아비브와 ECCV 2022 여행기 4 텔 아비브와 ECCV 2022 여행기 5 텔 아비브와 ECCV 2022 여행기 6 텔 아비브</div></div><div style=clear:both></div><hr></div></div></div><div class=modal-footer><p class="results-count text-medium" data-message-zero data-message-one data-message-other>68 posts found</p></div></div></div><div id=cover style=background-image:url(http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/stair.jpg)></div><script>(function(d){var config={kitId:'vld6lxf',scriptTimeout:3000,async:true},h=d.documentElement,t=setTimeout(function(){h.className=h.className.replace(/\bwf-loading\b/g,"")+" wf-inactive";},config.scriptTimeout),tk=d.createElement("script"),f=false,s=d.getElementsByTagName("script")[0],a;h.className+=" wf-loading";tk.src='https://use.typekit.net/'+config.kitId+'.js';tk.async=true;tk.onload=tk.onreadystatechange=function(){a=this.readyState;if(f||a&&a!="complete"&&a!="loaded")return;f=true;clearTimeout(t);try{Typekit.load(config)}catch(e){}};s.parentNode.insertBefore(tk,s)})(document);</script><script src=//cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.js></script><script src=/js/script-wl33z0n6ocaypepiqrazthtivfrliqijej4rq8ek8gvrv1awftmgjuv8k4zc.min.js></script><script>$(document).ready(function(){hljs.configure({classPrefix:'',useBR:false});$('pre.code-highlight').each(function(i,block){var code="";hljs.highlightAuto(block.innerText).value.split(/\r\n|\r|\n/).forEach(function(line){code+="<span class=\"line\">"+line+"</span><br>";});if(code.length>0){block.innerHTML=code;}});$('pre > code').each(function(i,block){$(this).addClass('codeblock');hljs.highlightBlock(block);});});</script></body></html>