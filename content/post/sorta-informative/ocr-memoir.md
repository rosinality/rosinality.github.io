+++
keywords = ["ocr", "memoir", "machine learning"]
tags = ["ocr", "memoir", "machine learning"]
categories = ["memoir"]
isCJKLanguage = true
hasMath = false
coverImage = "https://res.cloudinary.com/rosinality/image/upload/v1672667223/ocr-a.jpg"
coverSize = "partial"
autoThumbnailImage = true
thumbnailImagePosition = "top"
date = 2023-01-02T22:49:14+09:00
title = "OCR 회고"
+++

타이틀 커버 이미지 출처: https://www.behance.net/gallery/6146939/OCR-A-Poster/modules/152114859

4년 동안 몰두했던 OCR이라는 주제를 마무리하게 되면서 으레 그래왔듯 회고를 남겨본다. 이랬더라면 어땠을까 같은 소소한 소회보다는 비교적 서비스에 가까운 작업을 진행하면서 생각했던, 혹은 부딪쳤던 문제들에 대해 남겨놓고 언젠가 다시 돌아와서 이 문제들에 대해 다른, 되도록이면 더 나은 생각을 할 수 있게 되기를 바라는 쪽에 가깝겠다.

# AI 겨울

AI의 겨울이 다시 찾아올까? OCR에 대한 회고의 첫 마디에서 등장하기에는 지나치게 큰 주제인데, 나는 이 문제에서 시작하는 것이 OCR에서 경험했던 문제들을 좀 더 추상적인 관점에서 볼 수 있는 생각의 틀을 제공할 수 있으리라는 생각을 한다. 그런데 도대체 AI 겨울이란 무엇인가? AI가 AI에서 약속했던 것들을 제공하지 못했던 것에서 발생했던 문제들이라고 한다면 그 AI의 약속이란 대체 무엇이었던 것일까? 아마 과거의 AI 겨울에서 중요했던 문제는, 예를 들어 ASR 같은 우리가 중요하게 생각하는 과제에 대해 고성능 솔루션을 제공할 수 있으리라 기대했지만 그러지 못했다 같은 측면이 크지 않았을까 싶다.

그렇다면 지금도 그런 문제가 발생할 가능성이 있을까? 자율주행 같은 문제에서 데이터를 끝없이 투입해서 코너 케이스를 커버하지 못하는 문제 등에서는 그런 한계가 보이는 것 같기도 하지만, ASR이나 OCR 같은 문제에서는 모델과 데이터의 발달로 성능이 꽤 괜찮은 수준까지 발전하고 있고 앞으로도 그럴 수 있을 가능성이 높아 보이기도 한다. 그러니 결국 케바케이지만 성능의 한계 자체가 문제가 될 가능성은 낮아지고 있다고 보인다.

여기서 우리가 AI에 대해 암묵적으로 걸고 있는 기대와 예상의 다른 측면들을 생각해볼까 한다.

# 과제는 풀었다만, 이 과제가 우리가 기대한 만큼의 가치를 제공할 수 있는 것이었던가?

OCR 같이 이미 잘 정의되어 있고 으레 여기서 고성능을 달성할 수 있다면 유용하게 쓰일 수 있으리라고 가정되는 과제들도, 정작 그 과제에 대한 그 솔루션이 개발되었을 때 발생하는 가치, 즉 사용자에 대한 효용이 기대보다 크지 않은 것 같은 상황에 맞닥뜨리게 되는 경우가 있다. 여기에는 몇 가지 이유가 있었을 것이다. 첫째로는 이 과제가 사실 더 큰 목표와 과제에 대한 좀 더 낮은 단계의 문제(Sub-problem)였을 가능성이다. 예컨대 챗봇 같은 것을 만드는 것이 목적이라면 화자 의도 인식 같은 것은 챗봇을 구축하는데 필요한 작은 문제이다. 이 문제를 잘 푸는 것이 챗봇에 도움이 될 수도 있지만 그것만으로 챗봇을 구성할 수 있는 것은 아니다. 요즘 같이 End-to-End 솔루션들이 효과적인 시점에는 애초에 그 문제를 푸는 것이 딱히 필요하지 않았던 것일 수도 있다.

두 번째 가능성은 실제 사용 시나리오에서 이 과제들이 어떻게 작동할지, 어떤 기능들이 추가적으로 필요할지 충분히 생각해보지 않은 경우가 있을 수 있겠다. 어쩌면 이 사용 시나리오 자체를 명확하게 구상하지 못했을 가능성도 있다. 즉 어떤 기능을 사용자에게 제공하겠다는 그림 자체가 허술했을 가능성도 있다. 더욱이 이 구체적인 과제에 대한 솔루션의 성능이 부족한 상황에서는 이 성능을 향상시키는데 급급하게 되고, 또한 애초에 가장 기본적인 단계에서부터 잘 작동하지 않으니 더 큰 그림을 볼만한 여유가 없어지게 만드는 경향도 있다. 애초에 글자 하나 제대로 읽지 못하는데 그걸 사용해서 무언가를 하겠다는 거창한 계획을 세우는 것은 허황하게 보일 가능성이 높다.

나는 지금 이 문제가 여기저기서 발생하고 있는 것이 아닐까 생각한다. 즉 우리는 풀 문제를 설정하고 그 문제에 대해서 고성능 솔루션을 만드는 고비까지는 넘었지만 정작 그 솔루션을 들고 밖으로 나가보니 생각보다 사용처가 많지 않다는 것을 발견하게 된 것이다. 단적으로 말해 충분한 돈을 내고 쓰고 싶어하는 사례가 많지 않은 것이다.

# 모든 문제가 가치 있는 것은 아니었다. 그렇다면 대체 가치 있는 과제는 어디에 있는가?

기존에 잘 정의되어 있었던, 으레 가치 있다고 가정했던 과제들이 그 자체만으로는 충분하지 않거나 사실 큰 가치가 없을 수 있다는 생각이 들었다면, 그렇다면 정말 가치 있는 과제가 무엇이 있을지가 문제가 되는 것이 순서이다. 그러나 이 순간 문제는 더 어려운 지점으로 나아간다. 이 시점부터 우리는 이미 정의된 과제가 아니라 과제를 찾아내고 발견하며 스스로 설정해야 하는 상황으로 들어가게 된다. 이런저런 문제들을 풀 수 있는 도구들은 구비되어 있다. 그렇지만 도구들을 구비하고 대충 문제가 주어졌을 때 그 문제를 풀 수 있을지를 가늠할 수 있는 엔지니어링적 감각과 가치 있는 주제들을 선정하는 기획의 영역은 분명 다르다. 그렇지만 기획의 감각만으로 문제를 풀 수도 없다. 무엇이 가능하고 어떤 문제를 풀 수 있는 도구가 주어져 있는지를 파악하지 못하면 급진적인 가능성과 문제들에 대해서는 엄두를 내기 어렵다. 어떤 아이디어가 떠올라도 기술적으로 어렵거나 불가능할 것이라고 판단해서 스스로 포기해버리는 경우가 왕왕 발생한다. (물론 구비한 도구들로 풀 수 있는 문제들 중 딱히 가치 있는 문제가 없는 경우 또한 있을 수 있다.)

나는 지금 AI 연구 개발이 이 문제들에 맞닥뜨린 경우가 많지 않은가 하는 생각을 한다. 어쩌면 AI 연구 개발이 기존에 잘 정의된 과제들과 그에 대한 도구들에서 시작했던 것이 이런 문제들을 증폭했을 수도 있다. 이제 다시 되짚어 가치 있는 것들을 선정하고 그것을 개발하기 위해 집중해야 할 텐데 그것이 생각보다 만만하지 않다. 거기에 그렇다면 지금까지 개발한 것은 대체 무엇이었는가 하는 질문도 들어오는 시점이 아닌가.

# 대충 뭔가 다 자동화할 수 있지 않을까?

약간 다른 측면에서, AI에 대한 기대 중 하나는 대충 이런 양상이라고 생각한다. 뭔지 잘 모르겠지만, 대체 무슨 일을 어떻게 자동화할 것인지에 대한 그림은 없지만 AI/ML 기술들이 발전하면 하여간 무언가는 자동화가 될 것이라는 막연한 기대. 그나마 더 구체화된 것이 앞으로 무슨무슨 직군을 대체할 수 있으리라는 식으로 나오는 경우는 있다. 그러나 직군이 수행하는 역할이 무엇이며 어떤 작업들을 해야 하고 그 직군을 둘러싼 사회적 조건들과 특성이 어떠한지에 대한 고려는 딱히 없는 경우가 태반이다. 그래서 여하간 이것저것 대체하고 자동화하리라고 기대했는데 그런 결과는 그리 많이 나오지 않는다. 그리고 그것이 과도한 기대와 현실의 차이가 된다.

이는 위의 문제와도 연관된 것이라 할 수 있겠다. 이것저것 다 해결할 수 있을 것 같았지만 정작 실제로는 어떤 과제가 가치있을지, 그 과제를 어떻게 풀어나갈 수 있을지 탐색하는 것도 막막하고 시간이 많이 필요한 일이다. 이상과 현실의 타임라인이 어긋나기 시작하니 마찰이 발생하게 된다.

# 그래서, 지금 여기에서 무엇을 할 것인가?

두 가지 가능성이 있으리라고 생각한다.

1. 다시 한 번 정말로 가치 있는 과제를 찾아내고 그 과제를 풀어내는 것에 천착하는 것. 우리가 가진 기술들, 혹은 우리가 쓰는 것을 선호하고 편안하게 느끼는 기술들이 우선이 되는 것이 아니라 정말로 쓸모 있는 제품을 설계하는 것에 집중하는 것이다. 그리고 우리가 그 제품에 사용하기 위한 기술을 만들어나가는 순간 순간에 그 기술 자체가 아니라 우리가 구축하고자 하는 제품의 목표에 부합하도록 노력하는 것.

2. 모델의 발전이 창발적인 특성을 나타내는 형태의 모델을 사용해 모델의 발전 자체가 새로운 적용 분야와 가능성, 기능의 발견으로 이어지게 하는 것. 예컨대 대규모 언어 모델과 같은 것이 사례가 되겠다. 즉 모델의 발전(모델 크기, 데이터의 양, 학습 연산력의 규모의 증가)이 이전에 예상하지 못했던 능력의 획득으로 이어지는 사례가 되겠다. 이 새로운 능력들은 우리가 예상하지 못한 적용 사례와 가치를 창출할 가능성이 있다. 물론 그렇다고 모델이 알아서 모든 것을 해내리라고 기대할 수는 없고 방향을 구상하는 것이 필요하겠지만. (Instruct GPT가 Unsupervised Pretraining 뿐만 아니라 구체적으로 설게된 Instruction Finetuning의 결합으로 만들어진 것처럼.)

이 둘 모두 급진적인 재정비 혹은 목표의 재설정을 요구하는 것이라고 생각한다. 그리고 이러한 실천이 요구된다는 것은 모델의 성능을 높이기 위해 튜닝하고 데이터를 수집하는 것과 같은 지금까지 ML 엔지니어로서 수행했던 것, 그리고 요구되었던 것들과는 결이 다른 요청이 등장하게 되는 시점이 되었다는 의미라고 생각한다.

# 다시 OCR에 대해 논하자면

추상적인 차원에서 이야기했으니 이제 구체적인 경험과 연결해야할 때가 된 것 같다. 내가 4년 좀 넘게 OCR 팀의 과제를 수행하면서 늘 부딪혔던 문제, 고민했던 문제는 이제 OCR 이후에 무엇이 올 것인가였다. 팀의 초기에는 OCR 파이프라인을 만들고, 소소하게 모델을 개선해서 성능을 향상시키거나, 혹은 데이터의 추가로 모델의 성능을 OCR이라는 과제 자체에 대해서 의미 있느 수준까지 끌어올리는 작업을 하는 것만으로도 충분했다. 그러나 OCR 파이프라인이 궤도에 오른 이후에는 그렇다면 OCR 파이프라인을 구축하는 것 이외에 무엇이 주어질 것인가 하는 문제가 중요해졌다. OCR 파이프라인의 끝없는 개선? 아주 단순하게 말하자면 OCR 파이프라인의 성능을 향상시키는 것은 기계적이고 주기적인 방식의 데이터 추가와 재학습으로도 대응할 수 있다. 우리는 그런 기계적인 작업을 반복하는 대신 다른 무언가가 필요한 것이다. (다르게 말하자면, 주기적인 데이터 추가와 재학습으로 대응할 수 있는 문제에 대해 많은 입력을 투입하고, 종종 그러는 것처럼 반복적이고 소소한 모델 개선 작업에 인력을 사용하는 것은 비효율적이라고 생각한다.)

그렇지만 사실 이러한 질문, 즉 OCR 다음은 무엇인가라는 질문은 그리 적절하지 않은 것이었던 것 같다. 이런 질문은 즉 OCR을 마무리하고 나면 그 다음 단계가 있어서 그걸 작업하면 되고, 또 그 다음 단계로 나아가면 된다는 식의 인상을 준다. 즉 지금 발견하지는 못했더라도 바로 다음의 인접한 단계가 있어서 그걸 밟아나가면 된다고 생각하는 것이다. 이는 국소적(Local)인 규모의 관점이라고 할 수 있겠다. OCR 모델의 성능을 개선하는 것처럼 점진적인 개선, 기능 추가를 통해 전체 제품을 개선하려는 것이다.

그러나 위에서 장황하게 논의한 것과 연관해서 생각하자면 순서는 반대가 되어야 한다. 혹은 관점을 전역적(Global)인 것으로 전환해야 한다. 우리가 제공하고자 하며 구축하고자 하는 제품에 대한 구상이나 설계에서 시작해서 필요한 컴포넌트들을 구축하는 식으로 작업할 수 있었다. OCR의 다음 단계가 있는 것이 아니라 채워넣어야할 다음 컴포넌트가 있는 것이다. OCR이라는, 가장 중요한 컴포넌트 혹은 제품의 전체처럼 느껴지는 과제 또한 결국 제품에 필요한 하나의 컴포넌트에 불과한 것이다. OCR의 다음 단계를 생각하면서도 이 제품의 측면에 대해서는 그다지 생각해보지 않았던 것 같다. Document Reconstruction 같이 나름대로 생각해본 것에 대해서도 이것이 정말로 어느 정도의 가치를 창출할 수 있을 것인가에 대해서는 깊게 생각해보지 않았다. 아마 의미 있을 것이라고 추측했던 것이 전부였다고 할 수도 있겠다.

