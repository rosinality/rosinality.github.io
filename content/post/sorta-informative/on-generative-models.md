+++
keywords = ["machine learng", "language model", "generative model"]
tags = ["machine learning", "language model", "generative model"]
categories = ["sorta informative"]
isCJKLanguage = true
hasMath = false
coverImage = "https://res.cloudinary.com/rosinality/image/upload/v1676471831/steve-johnson-RzykwoNjoLw-unsplash_dyaqvg.jpg"
coverSize = "partial"
autoThumbnailImage = true
thumbnailImagePosition = "top"
draft = false
date = 2023-02-15T23:30:19+09:00
title = "이미지와 텍스트 생성 모델에 대해"
+++

이미지 생성 하면 Style GAN이었던 시절에도 일러스트 생성 등은 오타쿠적 인기가 있는 주제였다. 문제의 Danbooru 데이터셋 같은 경우에도 그 시점에 이미 만들어진 데이터셋이었다. 가끔 학계 내에 논문으로 등장하기도 했지만 주로 개인적인 연구나 작업물 등의 형태로 돌아다니는 것도 많았다. 애초에 그 사람들의 목적은 학계 내에서의 명성이 아니라 일러스트가 조금 더 잘 나오는 것이었기 때문에.

Waifu Generation의 뒤를 이어 Novel AI가 이런 시장에서 돈을 벌 수 있으리라고 판단했던 것 같고 결과적으로는 체크포인트가 털리면서 그 야심이 좌절된 듯한 그림이 되어버렸지만, 과거 개인적인 작업의 형태로도 명맥이 이어져 왔다는 것을 생각해보면, 베이스가 되는 Stable Diffusion의 체크포인트가 공개된 이상 공개된 형태로 이런 일러스트 생성 모델 등이 개발될 수밖에 없었던 것도 사실일 듯 싶다.

그래도 이전에는 ML을 아는 사람들이 취미 삼아 작업하는 쪽이었다면 결과물이 훨씬 더 안정적으로 나오게 되면서부터 훨씬 더 다양한 폭의 사람들이 참여하는 커뮤니티가 형성되고 있는 듯 싶다. 도구도 이미 상당히 고도화 되어 있어 파인 튜닝하고 모델을 섞는 등 ML 연구자들이 하는 작업들을 이제 수많은 사람들이 아무렇지도 않게 시도하고 있다. 그 과정에서 LoRA (https://arxiv.org/abs/2106.09685) 같은 방법들이 다시 발굴되기도 하고. 결과적으로 이 영역은 arXiv를 통해 학계 내에서 나오는 발전을 추적하는 것만이 아니라 이런 일러스트 생성 커뮤니티 내부의 유행을 알아야 할 필요가 생기는 듯 싶다. 프롬프트 튜닝이나 모델 튜닝 같은 작업에서 사람의 숫자를 당할 수는 없는 법이다. (아직도 문장으로 프롬프트를 쓰고 있는 사람은 없겠지?)

그런 의미에서 사회적으로 이는 상당히 흥미로운 현상이라고 생각한다. ML 모델이 이렇게 넓은 저변에 대해 이렇게 고도화된 방식으로, 또한 분산된 방식으로 활용되는 것은 전례가 없지 않은가? 그것이 그 커뮤니티 내에서만 작동하는 것이 아니라 이미 커뮤니티 밖으로 흘러넘쳐 다른 일반적인 커뮤니티에서도 돌아다니고 있으며 일러스트 시장에도 영향을 미치고 있다는 점에서. 다만 이걸로 사업을 하려고 생각했던 이들 입장에서는 좀 골치가 아프긴 할 듯 싶다. 다음에 한참 더 개선된, 새로운 모델을 만든다면 공개하지 않는 쪽을 선택하려 할지도 모르겠다. 물론, 각자 이미 좋은 결과물들을 만들어내고 있었던 사람들에게 돈을 낼 용의를 불러일으키자면 그 특성이 한참 더 좋아야겠지만.

이 정 반대편에 있는 생성 모델이 대규모 언어 모델이라 할 수 있을 것이다. 그래도 최근에는 공개된 모델들이 있긴 하지만 공개된 모델들을 받아와도 추론을 하는 정도에도 상당한 규모의 연산 자원이 필요하다. (Stable Diffusion 튜닝 같은 경우 쓸만한 GPU가 있다면 개인 데스크탑에서 해결하고 아니면 Colab로도 잘 쓰고 있는 것 같다.) 그걸 좀 쓸만하게 RLHF 같은 튜닝을 하자면 다시 그보다 훨씬 더 막대한 규모의 자원이 필요하고, 새로운, 더 개선된 언어 모델을 만들자면 다시 엄청난 연산 자원과 데이터가 필요하다. 아무나 손댈 수도 없고 실질적으로 지금 시점에서 유의미한 결과물을 낼 수 있는 것은 OpenAI와 구글에 국한된 것으로 보인다. 이는 보통 ML 업계에서도 보기 드문 수준의 집중화로 보인다.

더 안 좋은 것은 과연 지금 시점에서 이 두 회사를 따라잡으려 시도한다고 하더라도 그것이 어느 정도 가능할 것인지, 그리고 실제로 어느 정도 따라잡을 수 있다고 하더라도 이 회사들에 대해 어느 정도 경쟁력을 갖출 수 있을지에 대해서 회의적인 이들이 충분히 많다는 것. 간단히 ChatGPT를 겨우 따라잡더라도, 더 대규모의 더 개선된 언어 모델을 기반으로 한 새로운 모델이 등장한다면? 거기에 이미 서비스에 투입되면서, 그리고 계속해서 튜닝 작업을 진행하면서 축적하고 있는 데이터들은 어떻게 상대할 수 있을까? 낙관할 수 있는 근거가 그렇게 많지는 않은 듯 싶다.

알파고와 강화 학습에 이어 생성 모델이 AI/ML 분야의 2차 Hype를 불러일으키고 있는 모양새이지만, 알파고 시절의 관대한(?) Hype에 비해 현재 생성 모델이 조성하고 있는 Hype는 그리 여유롭지 않은 듯 하다. 사실은 이전에 비해 오히려 더 살벌해진 것 같은 느낌도 있다. 한쪽에서는 개인들과 커뮤니티가 무료로 모델을 사용하고 있는 상황이고 다른 쪽에서는 그 어느떄보다도 중앙 집중된 방식의 모델이 굴러가고 있다. 그 사이의 틈바구니에서 어느 정도의 가능성과 시장이 가능할지는 의심스럽다. 물론 바위가 굴러오더라도 작은 몸 하나 숨길 만한 틈새는 찾을 수 있는 법이지만, 그러자면 알파고 Hype가 가시고 과연 AI/ML이 어느 정도 가치를 창출할 수 있는가라는 회의가 찾아온 시점에서 발견했던 문제들일 다시 태클해야할 것이다.