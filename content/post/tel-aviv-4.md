+++
keywords = ["tel aviv", "eccv 2022", "machine learning"]
tags = ["tel aviv", "eccv 2022", "machine learning"]
categories = ["travel"]
isCJKLanguage = true
hasMath = true
coverImage = "https://res.cloudinary.com/rosinality/image/upload/v1667440604/tel-aviv/20221025_172656.jpg"
coverSize = "partial"
autoThumbnailImage = true
thumbnailImagePosition = "top"
date = 2022-11-07T12:31:27+09:00
title = "í…” ì•„ë¹„ë¸Œì™€ ECCV 2022 ì—¬í–‰ê¸° 4"
+++

1. [í…” ì•„ë¹„ë¸Œì™€ ECCV 2022 ì—¬í–‰ê¸° 1]( {{< ref "post/tel-aviv-1.md" >}})
2. [í…” ì•„ë¹„ë¸Œì™€ ECCV 2022 ì—¬í–‰ê¸° 2]( {{< ref "post/tel-aviv-2.md" >}})
3. [í…” ì•„ë¹„ë¸Œì™€ ECCV 2022 ì—¬í–‰ê¸° 3]( {{< ref "post/tel-aviv-3.md" >}})
4. í…” ì•„ë¹„ë¸Œì™€ ECCV 2022 ì—¬í–‰ê¸° 4
5. [í…” ì•„ë¹„ë¸Œì™€ ECCV 2022 ì—¬í–‰ê¸° 5]( {{< ref "post/tel-aviv-5.md" >}})
6. [í…” ì•„ë¹„ë¸Œì™€ ECCV 2022 ì—¬í–‰ê¸° 6]( {{< ref "post/tel-aviv-6.md" >}})
7. [í…” ì•„ë¹„ë¸Œì™€ ECCV 2022 ì—¬í–‰ê¸° 7]( {{< ref "post/tel-aviv-7.md" >}})

<!--start-summary-->

![í…” ì•„ë¹„ë¸Œ ì—‘ìŠ¤í¬](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_091131.jpg)

ë³¸ê²©ì ì¸ í•™íšŒì˜ ì‹œì‘. í•™íšŒëŠ” í…” ì•„ë¹„ë¸Œ ì—‘ìŠ¤í¬ì—ì„œ ì§„í–‰ëë‹¤.

![í…” ì•„ë¹„ë¸Œ ì—‘ìŠ¤í¬ ì• ê³µì›](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_091148.jpg)

ì—‘ìŠ¤í¬ ê±´ë¬¼ ì•ì—ëŠ” ì´ë ‡ê²Œ ë„ë¶€ëŸ¬ì ¸(?) ìˆì„ ìˆ˜ ìˆëŠ” ê³µê°„ì´ ìˆì—ˆëŠ”ë° í…” ì•„ë¹„ë¹„ì˜ í–‡ë³•ì€ ì‚¬ì‹¤ íŒŒë¼ì†” í•˜ë‚˜ ì •ë„ë¡œëŠ” ë²„í‹°ê¸° ì–´ë ¤ìš´ ê°ì´ ì¢€ ìˆì—ˆë‹¤. ê°ë„ê°€ ë”± ë§ìœ¼ë©´ ëª¨ë¥¼ê¹Œ.

![ì—‘ìŠ¤í¬ ë‚´](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_091455.jpg)

![Long-Tail Detection with Effective Class-Margins](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_093802.jpg)

ì²« ë°œí‘œëŠ” [Long-Tail Detection with Effective Class-Margins](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136680684.pdf). ì´ìª½ì€ í¬ìŠ¤í„°ì—ì„œ ì•½ê°„ ì§ˆì˜ë¥¼ ë‚˜ëˆ´ìœ¼ë¯€ë¡œ ê·¸ìª½ì—ì„œ ì†Œê°œí•˜ê¸°ë¡œ.

![Improving Robustness by Enhancing Weak Subnets](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_100301.jpg)

ì‚¬ì§„ì´ ì—†ì–´ì„œ ì¢€ ê±´ë„ˆë›°ê³  ë‹¤ìŒì€ [Improving Robustness by Enhancing Weak Subnets](https://arxiv.org/abs/2201.12765). ì˜ˆë¥¼ ë“¤ì–´ Lottery Ticketì´ ìˆë‹¤ë©´ Lottery Ticket ì™¸ì˜ ë‚˜ë¨¸ì§€ Weightë“¤ì˜ ì—­í• ì€ ë¬´ì—‡ì¸ê°€? ì´ Weightë“¤ì´ êµ¬ì„±í•˜ëŠ” Sub Networkë“¤ì˜ ì„±ëŠ¥ì„ í™•ë³´í•˜ëŠ” ê²ƒì´ Robustnessì— ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤ëŠ” ì•„ì´ë””ì–´. ë‹¨ ì´ Weak Subnetì„ ì°¾ëŠ” ê²ƒì´ ê·¸ë ‡ê²Œ ì‰¬ìš´ ì‘ì—…ì€ ì•„ë‹Œ ë“¯ í•˜ê³  ì—¬ê¸°ì„œëŠ” RL/Policy Gradientë¥¼ ì‚¬ìš©í–ˆë‹¤.

![Monocular 3D Object Detection with Depth from Motion](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_102323.jpg)

ë‹¤ìŒì€ [Monocular 3D Object Detection with Depth from Motion](https://arxiv.org/abs/2207.12988). ì´ìª½ì€ ì œëª© ê·¸ëŒ€ë¡œ Monocular 3D Object Detectionì„ ë‹¤ë£¨ëŠ”ë° Monocular Detectionì—ì„œ ì„±ëŠ¥ì„ ì œì•½í•˜ëŠ” ê°€ì¥ í° ìš”ì¸ì€ Depth ì •ë³´ì˜ ë¶ˆì¶©ë¶„í•¨ì´ë¼ëŠ” ì•„ì´ë””ì–´ì˜€ë‹¤. ì¹´ë©”ë¼ì˜ ì›€ì§ì„ì„ í†µí•´ì„œ ìˆ˜ì§‘ëœ ì´ë¯¸ì§€ë“¤ì„ í†µí•´ ì´ Depth ì •ë³´ë¥¼ ì¶”ì •í•˜ëŠ” ê²ƒìœ¼ë¡œ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤ëŠ” ì—°êµ¬.

![Rafael](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_103904.jpg)

í¬ìŠ¤í„° ë°œí‘œì¥ìœ¼ë¡œ. ì´ìŠ¤ë¼ì—˜ ì•„ë‹ˆë„ê¹Œë´ Rafaelì´ë¼ëŠ” êµ°ìˆ˜ê¸°ì—… ë¶€ìŠ¤ë„ í•˜ë‚˜ ìˆì—ˆë‹¤. ì›¬ ë¯¸ì‚¬ì¼ ëŸ°ì²˜ê°€ í•˜ë‚˜ ìˆì—ˆëŠ”ë° í•œ ë²ˆì”© ë©”ì–´ë³´ëŠ” ì‚¬ëŒë“¤ì´ ìˆì—ˆìŒ. ëŒ€ì¶© ë¯¸ì‚¬ì¼ ëŸ°ì²˜ë¡œ ë¹„í–‰ í‘œì ì„ ì¡°ì¤€í•˜ëŠ” ì‹œë®¬ë ˆì´ì…˜ ê°™ì€ ê²ƒì´ì—ˆë˜ ë“¯.

![Springer](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_103932.jpg)

Springerì—ì„œ ì—¬ëŠ” í•™íšŒë‹µê²Œ Springer ì±…ë„ íŒ”ê³  ìˆì—ˆë‹¤.

![Weights & Biases](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_104034.jpg)

Weights & Biases ë¶€ìŠ¤. ë„¤ì´ë²„ í´ë¡œë°”ì—ì„œ ì™”ë‹¤ê³  í•˜ë‹ˆ ì•Œì•„ë³´ë”ë¼. ì•„ì£¼ ì˜ ì“°ê³  ìˆë‹¤ê³  í•œ ë§ˆë”” í–ˆë‹¤. ë­”ê°€ ê°œì„ ì„ ì›í•˜ëŠ” ê²ƒì´ ìˆëƒëŠ” ì§ˆë¬¸ë„ ìˆì—ˆëŠ”ë° ë‚´ê°€ ì“°ëŠ” ë ˆë²¨ì—ì„œëŠ” ë”±íˆ ê°œì„ ì˜ í•„ìš”ê°€ ëŠê»´ì§€ëŠ” ê²ƒì€ ì—†ì–´ì„œ ê³ ë¯¼ì„ ì¢€ í–ˆë‹¤. (ê²°êµ­ ë§ì€ ì•ˆ í•¨.)

![GM](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_104423.jpg)

ììœ¨ì£¼í–‰ ê´€ë ¨í•´ì„œ ë‚˜ì˜¨ ë¶€ìŠ¤ë„ ì¢€ ìˆì—ˆë‹¤. GMì´ë‚˜ Mobileye ë“±.

![GM](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_104423.jpg)

CVì— ë‚¨ì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€? í•™íšŒì¥ì—ì„œ í•œêµ­ ì‚¬ëŒë“¤ê³¼ ë§Œë‚˜ë©´ì„œ CVì— ë‚¨ì€ ì£¼ì œëŠ” 1. Multimodal, 2. Generation (Diffusion), 3. 3D (Implicit Representation) ì´ë¼ê³  ìš”ì•½í•˜ëŠ” íŒ¨ì•…ì§ˆ(?)ì„ ë¶€ë ¸ë‹¤. ê·¸ëŸ°ë° ìƒê°í•´ë³´ë©´ ì—¬ê¸°ì—ì„œ Videoì— ëŒ€í•œ ì–¸ê¸‰ì„ ê¹œë°•í•œ ë“¯. íŠ¹íˆ í•™íšŒì¥ì—ì„œ ëˆˆì— ì¢…ì¢… ëˆ ê²ƒì´ ì—­ì‚¬ì™€ ì „í†µì˜ íŠ¸ë˜í‚¹ ë¬¸ì œ.

![Backbone is All Your Need](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_104604.jpg)

[Backbone is All Your Need: A Simplified Architecture for Visual Object Tracking](https://arxiv.org/abs/2203.05328). ì„œì¹˜ ì´ë¯¸ì§€ì™€ ì˜ˆì œ ì´ë¯¸ì§€, ê·¸ë¦¬ê³  ì˜ˆì œ ì´ë¯¸ì§€ì˜ ì¤‘ì•™ ë¶€ë¶„ í¬ë¡­ì„ íŠ¸ëœìŠ¤í¬ë¨¸ì— ì§‘ì–´ë„£ê³  ê²°ê³¼ë¥¼ ë‚´ë†“ë„ë¡ ë§Œë“¤ë©´ ëœë‹¤ëŠ” ì•„ì´ë””ì–´.

![Three things everyone should know about Vision Transformers](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_104942.jpg)

[Three things everyone should know about Vision Transformers](https://arxiv.org/abs/2203.09795)

1ì €ì Hugo Touvronì„ ì—¬ê¸°ì„œ ì²˜ìŒ ë³´ê²Œ ëë‹¤. ì›Œë‚™ ì¸ê¸°ê°€ ìˆì–´ì„œ ì§ˆë¬¸ì´ ì–´ë ¤ì› ë˜ì§€ë¼ ë‚´ìš©ì€ ì´ì „ì— ê¸°ë¡í•´ë‘” ë…¸íŠ¸ë¡œ ëŒ€ì²´.

1. y = x + mhsa(x), z = y + ffn(y) ê°™ì€ ë°©ì‹ìœ¼ë¡œ ê³„ì† ìŒ“ëŠ” ëŒ€ì‹  y = x + mhsa(x) + mhsa(x), z = y + ffn(y) + ffn(y) ê°™ì€ ì‹ìœ¼ë¡œ ëª¨ë“ˆë“¤ì„ ë³‘ë ¬ë¡œ (ì•½ê°„ multi branchìŠ¤ëŸ½ê²Œ) ê²°í•©í•  ìˆ˜ ìˆë‹¤. ê³„ì‚°ë„ ë³‘ë ¬ë¡œ ì˜ í•˜ë©´ ë” ë¹¨ë¼ì§ˆì§€ë„? ì…ë‹ˆë‹¤. gpt-jì—ì„œ y = x + mhsa(x) + ffn(x) ê°™ì€ ì ‘ê·¼ì„ ì‚¬ìš©í•œë‹¤ë˜ë° ë¹„ìŠ·í•œ ê²ƒ ê°™ê¸°ë„ í•˜ë„¤ìš”.
2. íŒŒì¸íŠœë‹ í•  ë•Œ (íŠ¹íˆ ì…ë ¥ í¬ê¸°ê°€ ë‹¬ë¼ì§ˆ ë•Œ) mhsaë§Œ íŠœë‹í•´ë„ ì¶©ë¶„í•˜ë‹¤.
3. stride 16 patchify ë ˆì´ì–´ë¥¼ ë” ì‘ì€ strideë¥¼ ê°€ì§€ëŠ” patchify ë ˆì´ì–´ë“¤ë¡œ ìª¼ê°œëŠ” ê²ƒë„ ê´œì°®ë‹¤(resnet-d ìŠ¤ëŸ½ê²Œ) ì…ë‹ˆë‹¤.

![Long-Tail Detection with Effective Class-Margins](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_105947.jpg)

ì˜¤ë„ ë°œí‘œì˜€ë˜ [Long-Tail Detection with Effective Class-Margins](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136680684.pdf). í•™ìŠµ ëª©í‘œì™€ í…ŒìŠ¤íŠ¸ mAP ë©”íŠ¸ë¦­ ì‚¬ì´ì—ëŠ” ê°­ì´ ìˆìœ¼ë¯€ë¡œ mAPì˜ ë°”ìš´ë“œì— í•´ë‹¹í•˜ëŠ” ì—ëŸ¬ë¡œ í•™ìŠµí•œë‹¤ëŠ” ì•„ì´ë””ì–´ì´ë‹¤. ê²°ê³¼ì ìœ¼ë¡œëŠ” Long-Tail ê²€ì¶œ ë¬¸ì œì— ì´ì „ì— ì ìš©ë˜ì–´ì™”ë˜ ë°©ì‹, ì˜ˆë¥¼ ë“¤ì–´ Seesaw Loss ([https://arxiv.org/abs/2008.10032](https://arxiv.org/abs/2008.10032)) ê°™ì€ ê²ƒì²˜ëŸ¼ lossë¥¼ reweightingí•˜ëŠ” ê²ƒê³¼ ë¹„ìŠ·í•œ ê²°ê³¼ê°€ ëœë‹¤. ê·¸ë ‡ì§€ë§Œ ì¥ì ì´ë¼ë©´ ì´ lossì— ëŒ€í•´ ì¶”ê°€ì ì¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°€ ìš”êµ¬ë˜ì§€ ì•Šê³  loss ê·¸ëŒ€ë¡œ ìµœì ì´ë¼ëŠ” ë¶€ë¶„. ì €ìì˜ ì„¤ëª…ìœ¼ë¡œëŠ” ì´ì „ì˜ ì ‘ê·¼ë“¤ë„ ëŒ€ì²´ ì™œ ë˜ëŠ” ê²ƒì¸ì§€ ì¢€ ì´í•´ê°€ ë˜ì§€ ì•ŠëŠ” ë¶€ë¶„ì´ ìˆëŠ”ë° (ì˜ˆë¥¼ ë“¤ì–´ loss reweightingë§Œìœ¼ë¡œ long-tail ë¬¸ì œê°€ í’€ë¦°ë‹¤ê³ ? ë¼ëŠ” ê·¼ë³¸ì ì¸ ì§ˆë¬¸), ê·¸ë ‡ë‹¤ë©´ ê·¸ ì´í•´ê°€ ë˜ì§€ ì•ŠëŠ” ì ‘ê·¼ì„ ì™„ê²°í•  ìˆ˜ ìˆëŠ” ì ‘ê·¼ì„ ê³ ì•ˆí•˜ê² ë‹¤ëŠ” ë°©í–¥ì´ì—ˆë‹¤ëŠ” ê²ƒ ê°™ë‹¤.

![Multimodal Object Detection via Probabilistic Ensembling](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_110812.jpg)

ì˜¤ë„ ë°œí‘œì˜€ë˜ [Multimodal Object Detection via Probabilistic Ensembling](https://arxiv.org/abs/2104.02904). ì˜ˆë¥¼ ë“¤ì–´ RGB ì´ë¯¸ì§€ì™€ Thermal ì´ë¯¸ì§€ ê°™ì€ Multimodal ì„¸íŒ…ì—ì„œ ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ê°ê° ë‚˜ì˜¨ ê²€ì¶œê¸°ì˜ ê²€ì¶œ ê²°ê³¼ë¥¼ ì–´ë–»ê²Œ ì¡°í•©í•  ê²ƒì¸ê°€ í•˜ëŠ” ë¬¸ì œ. ê¸°ë³¸ì ì¸ ì ‘ê·¼ì€ $p(y|x_1)$ê³¼ $p(y|x_2)$ê°€ ìˆì„ ë•Œ $p(y|x_1,x_2)$ë¥¼ ì¶”ì •í•˜ëŠ” ë¬¸ì œë¡œ ë³´ëŠ” ê²ƒ. ëŠ˜ ê·¸ë ‡ë“¯ì´ ë² ì´ì¦ˆ ë£°ì„ ë™ì›í•´ì„œ íƒœí´í•˜ëŠ” ì ‘ê·¼ì´ì—ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ Multimodal ë¿ë§Œ ì•„ë‹ˆë¼ ì¼ë°˜ì ì¸ ë””í…ì…˜ ì•™ìƒë¸”ì„ ìœ„í•´ì„œë„ ì“¸ ìˆ˜ ìˆëŠ”ê°€? ì§ˆë¬¸í–ˆì—ˆëŠ”ë° ê·¸ë ‡ë‹¤ê³  í•œ ê²ƒ ê°™ê¸´ í•˜ë‹¤. (ì˜¤ë„ ìƒí™©ì—ì„œ í–ˆë˜ ì§ˆë¬¸ì´ë¼ ì‘ë‹µì´ ì•„ì£¼ ì •í™•í•œ ê²ƒì´ì—ˆëŠ”ì§€ ì¢€ ì• ë§¤í•˜ë‹¤. ê·¸ë ‡ì§€ë§Œ ì•ˆ ë  ì´ìœ ëŠ” ì—†ì§€ ì•Šì„ì§€.)

![Panoptic Scene Graph Generation](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_110936.jpg)

ECCV 2022 ìµœê³  ìŠ¤íƒ€ì˜€ë˜ Jingkang Yang (https://twitter.com/jingkangy)ì˜ [Panoptic Scene Graph Generation](https://arxiv.org/abs/2207.11247). ì € LED ë°±íŒ©ì„ ë³´ë©´ì„œ ë‹¤ìŒì— ë…¼ë¬¸ í™ë³´ë¥¼ í•  ì¼ì´ ìˆë‹¤ë©´ ì €ê±¸ ê¼­ êµ¬í•´ë†“ê² ë…¸ë¼ê³  ë‹¤ì§í–ˆë‹¤. ì—¬í•˜ê°„ ë…¼ë¬¸ ì£¼ì œëŠ” ì¼ë°˜ì ì¸ Scene Graph ê°™ì´ ë°”ìš´ë”© ë°•ìŠ¤ ìƒí™©ì— ëŒ€í•œ ê·¸ë˜í”„ ì¶œë ¥ì´ ì•„ë‹ˆë¼ Panoptic Segmentation ì¶œë ¥ì— ëŒ€í•œ Scene Graph ìƒì„± ë¬¸ì œì˜€ë‹¤. ë‚´ê°€ ì§ˆë¬¸í–ˆë˜ ê²ƒì€ í¬ìŠ¤í„°ì—ë„ ë‚˜ì™€ìˆëŠ” PSGTRê³¼ PSGFormerì˜ ì°¨ì´. PSGTRì€ Scene Graphì˜ Triplet (Subject/Predicate/Object)ë¥¼ ëª¨ë‘ í¬í•¨í•˜ëŠ” ì¿¼ë¦¬ê°€ ì‚¬ìš©ë˜ê³  PSGFormerëŠ” Object ì¿¼ë¦¬ì™€ Relation ì¿¼ë¦¬ë¡œ factorize ë˜ì–´ìˆë‹¤. í•™ìŠµì€ PSGFormerê°€ ë” ë¹ ë¥´ì§€ë§Œ ì„±ëŠ¥ì˜ ë°”ìš´ë“œëŠ” PSGTRì´ ë†’ë‹¤.

![Unsupervised Domain Adaptation for One-stage Object Detector using Offsets to Bounding Box](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_110210.jpg)

[Unsupervised Domain Adaptation for One-stage Object Detector using Offsets to Bounding Box](https://arxiv.org/abs/2207.09656). FCOS ê°™ì€ ë””í…í„°ì—ì„œ ë‚˜ì˜¤ëŠ” ì¶œë ¥ featureë“¤ì€ class ë¿ë§Œ ì•„ë‹ˆë¼ offsetì— ë”°ë¼ì„œë„ ë¶„í™”ë˜ì–´ ìˆëŠ”ë° domain adaptationì—ì„œ ì´ ì˜¤í”„ì…‹ì— ë”°ë¥¸ feature clusteringì„ ê³ ë ¤í•´ ìˆ˜í–‰í•œë‹¤ëŠ” ì•„ì´ë””ì–´ì¸ ë“¯. ê° feature levelë§ˆë‹¤ ë¶€ì—¬ë˜ëŠ” box scaleì´ ë‹¤ë¥¸ë° ê·¸ ë¶€ì—¬ëœ scale ë‚´ì—ì„œ ì´ëŸ¬í•œ offsetë³„ ë¶„í™”ê°€ ê´€ì°°ëœ ê²ƒì¸ê°€ í•˜ëŠ” ì§ˆë¬¸ì„ í–ˆì—ˆëŠ”ë° ìƒí™©ì´ ì–´ìˆ˜ì„ í•´ì„œ ë‹µì€ ì œëŒ€ë¡œ í™•ì¸í•˜ì§€ ëª»í–ˆë‹¤. ê·¸ë ‡ì§€ë§Œ ìƒê°í•´ë³´ë©´ ë‹¹ì—°í•œ ì†Œë¦¬ë¥¼ ì§ˆë¬¸ìœ¼ë¡œ í•œ ë“¯.

![Streamable Neural Fields](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_114537.jpg)

[Streamable Neural Fields](https://arxiv.org/abs/2207.09663). Implicit Representationì€ ë‹¤ë¥¸ í¬ë§·ë“¤, ì˜ˆë¥¼ ë“¤ì–´ ì¼ë°˜ì ì¸ ì˜ìƒì´ë‚˜ ìŒì„± íŒŒì¼ê³¼ëŠ” ë‹¬ë¦¬ íŒŒì¼ì˜ ì¼ë¶€ë§Œìœ¼ë¡œëŠ” reconstructionì´ ë¶ˆê°€ëŠ¥í•˜ê³  ì „ì²´ weightê°€ í•„ìš”í•˜ë‹¤. ê·¸ë ‡ë‹¤ë©´ ì¼ë°˜ì ì¸ ì˜ìƒì´ë‚˜ ìŒì„± íŒŒì¼ì²˜ëŸ¼ ì¼ë¶€ weightë§Œìœ¼ë¡œë„ ì ì§„ì ì¸ reconstructionì„ í•  ìˆ˜ ìˆëŠ” implicit representationì„ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆëŠ”ê°€? í•˜ëŠ” ì£¼ì œ. ì•½ê°„ ìƒìƒë„ í•´ë³´ì§€ ì•Šì•˜ë˜ ì£¼ì œë¼ í¥ë¯¸ë¡œì› ë‹¤.

ì´ì™¸ì— ëˆˆì— ë„ì—ˆë˜ í¬ìŠ¤í„°ë“¤.

![BlobGAN](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_105146.jpg)

![Learning Audio-Video Modalities from Image Captions](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_105852.jpg)

![Visual Prompt Tuning](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_110511.jpg)

![Rethinking Few-Shot Object Detection on a Multi-Domain Benchmark](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_110753.jpg)

![Decoupled Contrastive Learning](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_111118.jpg)

![Text to Image Generation ê°•ì—°](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_112318.jpg)

í•™íšŒì¥ í•œìª½ì—ì„œëŠ” ì´ëŸ° ê°•ì—°ì„ í•˜ê³  ìˆì—ˆë‹¤. ì´ì–´í°ì„ ì“°ë©´ ë“¤ì„ ìˆ˜ ìˆëŠ” ì‹. ì£¼ì œëŠ” ìš”ì¦˜ ê°€ì¥ ëœ¨ê±°ìš´ ë¬¸ì œ Text to Image Generation.

![ìŠ¤í°ì„œ ê°•ì—° ìŠ¤ì¼€ì¤„](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_165614.jpg)

ê°•ì—° ìŠ¤ì¼€ì¤„.

![ì ì‹¬ ìŠˆë‹ˆì²¼](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_121318.jpg)

ì ì‹¬ íƒ€ì„. ìŠˆë‹ˆì²¼ê³¼ ê°€ì§€ì™€ ë¹µ. ìŠˆë‹ˆì²¼ì´ í•™íšŒ ë‹¨ê³¨ ë©”ë‰´ì˜€ë‹¤.

![Adaptive Token Sampling For Efficient Vision Transformers 1](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_135555.jpg)

![Adaptive Token Sampling For Efficient Vision Transformers 2](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_135636.jpg)

![Adaptive Token Sampling For Efficient Vision Transformers 3](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_140139.jpg)

ì˜¤í›„ ë°œí‘œ. [Adaptive Token Sampling For Efficient Vision Transformers](https://arxiv.org/abs/2111.15667). í¬ìŠ¤í„°ì—ì„œëŠ” ì¸ê¸°ê°€ ë„ˆë¬´ ë§ì•„ì„œ ì§ˆë¬¸í•  ì—¬ìœ ê°€ ì—†ì—ˆë‹¤. ViTì—ì„œ í† í°ì´ ì „ë¶€ ë‹¤ í•„ìš”í•´? ë¼ëŠ” ë¬¸ì œ ì˜ì‹ì—ì„œ ë‚˜ì˜¤ê³  ìˆëŠ” ì—°êµ¬ë“¤ ì¤‘ í•˜ë‚˜ë¼ê³  í•  ìˆ˜ ìˆê² ë‹¤. attention weightì™€ embedding normì„ ì‚¬ìš©í•´ ìŠ¤ì½”ì–´ë¥¼ êµ¬í•˜ê³  (normì´ ë‚®ìœ¼ë©´ ê²°ê³¼ì— ì˜í–¥ì´ ì ë‹¤ëŠ” ë¶€ë¶„ì„ ì¶”ê°€ë¡œ ê³ ë ¤í•œ ê²ƒì´ë¼ í•  ìˆ˜ ìˆê² ë‹¤.) top-k ëŒ€ì‹  ìŠ¤ì½”ì–´ë¥¼ ì‚¬ìš©í•´ inverse transform samplingìœ¼ë¡œ í† í°ì„ ë½‘ì•„ë‚¸ë‹¤. ìŠ¤ì½”ì–´ê°€ ë‚®ì€ í† í°ì´ ì„ íƒë˜ëŠ” ê²½ìš°ê°€ ìƒê¸´ë‹¤ëŠ” ì , ê·¸ë¦¬ê³  ê°™ì€ í† í°ì´ ë‘ ë²ˆ ì„ íƒë˜ëŠ” ê²½ìš° ë‘ í† í°ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ê²ƒìœ¼ë¡œ ê²°ê³¼ì ìœ¼ë¡œ ìƒ˜í”Œ ìˆ˜ $k$ë³´ë‹¤ ì‘ì€ ìˆ˜ì˜ í† í°ì„ ì‚¬ìš©í•˜ë„ë¡ í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì´ ì„ íƒì˜ ì´ìœ .

![The Challenges of Continuous Self-Supervised Learning 1](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_141005.jpg)

![The Challenges of Continuous Self-Supervised Learning 2](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_141215.jpg)

[The Challenges of Continuous Self-Supervised Learning](https://arxiv.org/abs/2203.12710). ì§€ê¸ˆê¹Œì§€ self supervised learningì€ ê³ ì •ëœ, íë ˆì´ì…˜ëœ ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œ ì„±ê³µì ì´ì—ˆìŒ. ê·¸ëŸ¬ë‚˜ ë°ì´í„°ê°€ ê³„ì†ì ìœ¼ë¡œ ì¶”ê°€ë˜ê³ , ë°ì´í„° ìƒ˜í”Œë“¤ ì‚¬ì´ì— correlationì´ ìˆìœ¼ë©°, ë°ì´í„° ë¶„í¬ê°€ ê³„ì†ì ìœ¼ë¡œ ë³€í™”í•˜ëŠ” ìƒí™©ì´ë¼ë©´ ì–´ë–¨ê¹Œ? ì´ ê²½ìš° ê°€ì¥ í° ë¬´ê¸°ëŠ” ë¦¬í”Œë ˆì´ ë²„í¼. ë¦¬í”Œë ˆì´ ë²„í¼ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒìœ¼ë¡œ ì´ íŠ¹ì§•ë“¤ì—ì„œ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤ì„ ìƒë‹¹íˆ ê²½ê°í•  ìˆ˜ ìˆë‹¤ëŠ” ì—°êµ¬.

![PACTran: PAC-Bayesian Metrics for Estimating the Transferability of Pretrained Models to Classification Tasks](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_142134.jpg)

[PACTran: PAC-Bayesian Metrics for Estimating the Transferability of Pretrained Models to Classification Tasks](https://arxiv.org/abs/2203.05126). í¬ìŠ¤í„°ì—ì„œ ì €ìì™€ ì ê¹ ì´ì•¼ê¸°í•  ìˆ˜ ìˆì—ˆìœ¼ë‹ˆ ê·¸ìª½ì—ì„œ.

![Towards Sequence-Level Training for Visual Tracking](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_154427.jpg)

[Towards Sequence-Level Training for Visual Tracking](https://arxiv.org/abs/2208.05810) ì´ë²ˆ í•™íšŒì—ì„œ íŠ¸ë˜í‚¹ í•˜ì‹œëŠ” ë¶„ë“¤ì„ ë§Œë‚˜ì„œ ì¡°ê¸ˆì”© ì´ì•¼ê¸°ë¥¼ ë“¤ì–´ë³¼ ìˆ˜ ìˆì—ˆëŠ”ë°, íŠ¸ë˜í‚¹ì—ì„œëŠ” ì•„ì§ sequence levelë¡œ í•™ìŠµí•˜ëŠ” ì‚¬ë¡€ëŠ” ì´ì œ ë§‰ ë‚˜ì˜¤ëŠ” ì‹œì ì¸ ëª¨ì–‘. ì‹œí€€ìŠ¤ ë‹¨ìœ„ê°€ ì•„ë‹ˆë¼ í”„ë ˆì„ ë‹¨ìœ„ë¡œ í•™ìŠµí•˜ëŠ” ê²ƒìœ¼ë¡œ ì¸í•´ occlusion ë“±ì´ ë°œìƒí–ˆì„ ë•Œ ë†“ì¹˜ëŠ” ì‚¬ë¡€ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì‹œí€€ìŠ¤ ë‹¨ìœ„ë¡œ íŠ¸ë˜í‚¹ì„ í•™ìŠµí•œ ì‚¬ë¡€ë¼ê³  í•  ìˆ˜ ìˆê² ë‹¤. ì´ ì‹œí€€ìŠ¤ ë ˆë²¨ í•™ìŠµì„ ìœ„í•œ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ê°€ REINFORCEë¥¼ ì‚¬ìš©í•œ ê°•í™”í•™ìŠµì´ê¸¸ë˜ í•™ìŠµì´ ì˜ ë˜ëƒê³  ë¬¼ì–´ë´¤ëŠ”ë° ì €ìì˜ ì‘ë‹µìœ¼ë¡œëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì˜ ë§ì¶”ë©´ ë˜ê¸´ ëœë‹¤ê³ . ğŸ˜…

![Unleashing Transformers: Parallel Token Prediction with Discrete Absorbing Diffusion for Fast High-Resolution Image Generation from Vector-Quantized Codes](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_154629.jpg)

[Unleashing Transformers: Parallel Token Prediction with Discrete Absorbing Diffusion for Fast High-Resolution Image Generation from Vector-Quantized Codes](https://arxiv.org/abs/2111.12701). ë°”ë¡œ ìƒê°ë‚˜ëŠ” ê²Œ MaskGIT ([https://arxiv.org/abs/2202.04200](https://arxiv.org/abs/2202.04200))ì´ë¼ì„œ ì €ìë“¤ì—ê²Œ MaskGITê³¼ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ ë¬¼ì–´ë³´ë‹ˆ ì‚¬ì‹¤ ë¹„ìŠ·í•œ ì‹œì ì— ë‚˜ì˜¨ ë¹„ìŠ·í•œ ì—°êµ¬ì¸ ê²ƒì€ ë§ë‹¤ëŠ” ì˜ê²¬. (ì‹œì ìœ¼ë¡œëŠ” Unleashing Transformersê°€ ë¨¼ì € ë‚˜ì™”ë‹¤.) ì°¨ì´ë¡œ ì œì‹œí•œ ê²ƒì€ ìƒ˜í”Œë§ ê³¼ì •. MaskGITì€ ìŠ¤ì½”ì–´ ê¸°ë°˜ìœ¼ë¡œ í† í°ì„ ìƒ˜í”Œë§í–ˆëŠ”ë° ì´í›„ ì½”ë“œë¥¼ í™•ì¸í•´ë³´ë‹ˆ Unleashing TransformersëŠ” ëœë¤í•˜ê²Œ ìƒì„±í•  í† í°ì„ ìƒ˜í”Œë§í•œë‹¤.

![PACTran: PAC-Bayesian Metrics for Estimating the Transferability of Pretrained Models to Classification Tasks](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_155912.jpg)

[PACTran: PAC-Bayesian Metrics for Estimating the Transferability of Pretrained Models to Classification Tasks]. íŒŒì¸íŠœë‹ì„ í•´ì„œ ì„±ëŠ¥ì„ ì°ì–´ë³´ê¸° ì „ì— ëª¨ë¸ weightê°€ ê° ê³¼ì œë“¤ì—ê²Œ ì˜ transfer ë  ìˆ˜ ìˆëŠ”ì§€ë¥¼ í‰ê°€í•˜ëŠ” ë©”íŠ¸ë¦­ì„ ë§Œë“¤ ìˆ˜ ìˆì„ ê²ƒì¸ê°€ í•˜ëŠ” ê³¼ì œ. ì§ê´€ì ì¸ ë ˆë²¨ì—ì„œ ë‹¤ë£¨ìë©´ PACTranì€ ìµœì¢… ë ˆì´ì–´ì˜ ì¶œë ¥ì˜ íŒŒì¸íŠœë‹ ë°ì´í„°ì— ëŒ€í•œ í•™ìŠµ lossì™€ flatness/smoothnessì˜ ê²°í•©ìœ¼ë¡œ transferabilityë¥¼ í‰ê°€í•œë‹¤ê³  í•  ìˆ˜ ìˆëŠ” ê²ƒ ê°™ë‹¤. flatnessëŠ” generalizabilityì— ëŒ€í•´ ê³„ì†í•´ì„œ ìœ ìš©í•˜ë‹¤ëŠ” ì‚¬ë¡€ë“¤ì´ ë‚˜ì˜¤ëŠ” ê²ƒ ê°™ë‹¤. í˜¹ì€ ë°˜ëŒ€ë¡œ ìš°ë¦¬ê°€ ê°€ì§€ê³  ìˆëŠ” ì²™ë„ê°€ ê·¸ê²ƒ ì •ë„ ë°–ì— ì—†ë‹¤ëŠ” ì˜ë¯¸ì¼ ìˆ˜ë„ ìˆê² ê³ .

![An Impartial Take to the CNN vs Transformer Robustness Contest](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_161725.jpg)

[An Impartial Take to the CNN vs Transformer Robustness Contest](https://arxiv.org/abs/2207.11347). ì´ì „ ë©”ëª¨ì—ëŠ” ë˜ ì´ë ‡ê²Œ ëŒ€ì¶© ì¨ë†¨ë‹¤.

> cnn (convnext) vs vitì˜ robustness, calibration, ood detection ë“±ì— ëŒ€í•œ ì„±ëŠ¥ ë¶„ì„. cnnì´ ë‚˜ì€ ê²½ìš°ë„ ìˆê³  vitê°€ ë‚˜ì€ ê²½ìš°ë„ ìˆê³  ì „ë°˜ì ìœ¼ë¡œ ì—‡ë¹„ìŠ·í•˜ë‹¤ëŠ” ê²ƒì´ ê²°ë¡ ì´ë„¤ìš”.

ViTê°€ CNNë³´ë‹¤ ë” robustí•˜ë‹¤ëŠ” ì£¼ì¥ì— ëŒ€í•´ ConvNeXt ì´í›„ë¡œ CNNê³¼ ViTê°€ ë¹„ìŠ·í•œ robustnessë¥¼ ë³´ì¼ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë³´ì¸ ì—°êµ¬ë¼ê³  í•  ìˆ˜ ìˆê² ë‹¤. self attention vs conv ë‘˜ ì¤‘ í•˜ë‚˜ê°€ ë” robustí•¨ì„ ê°€ì ¸ì˜¤ëŠ” ê²ƒì€ ì•„ë‹ˆê³ , vitë„ ë˜‘ê°™ì´ simpleí•œ featureì— ëŒ€í•œ ì„ í˜¸ê°€ ìˆë‹¤ëŠ” ê²ƒ ë“±ì„ ë³´ì˜€ë‹¤. ê²°êµ­ self attentionì´ëƒ convëƒê°€ ì•„ë‹ˆë¼ í•™ìŠµ ë°©ì‹ì´ë‚˜ layer norm ë“±ì˜ ì¡´ì¬ê°€ ë” í° ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ì˜ë¯¸ì¸ë°, ë‘ ì•„í‚¤í…ì²˜ì˜ ê°€ì¥ ë‘ë“œëŸ¬ì§€ëŠ” ì°¨ì´ê°€ ì•„ë‹Œ ë¯¸ë¬˜í•´ë³´ì´ëŠ” ì°¨ì´ë“¤ì´ ì´ëŸ° íŠ¹ì„±ì„ ë§Œë“ ë‹¤ëŠ” ê²°ë¡ ì´ë¼ ì‹œì‚¬í•˜ëŠ” ë°”ê°€ ìˆëŠ” ë“¯ ì‹¶ë‹¤. ê³¼ì¥í•´ì„œ ë§í•˜ìë©´ ê²°êµ­ ìš°ë¦¬ëŠ” ì•„ì§ë„ normalizationì˜ íš¨ê³¼ê°€ ë¬´ì—‡ì¸ì§€ ëª¨ë¥¸ë‹¤ê³  í•  ìˆ˜ ìˆê² ë‹¤.

![Frozen CLIP Models are Efficient Video Learners](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_164230.jpg)

[Frozen CLIP Models are Efficient Video Learners](https://arxiv.org/abs/2208.03550). ì–¼ë ¤ë†“ì€ CLIP featureì— ëŒ€í•´ temporal modelingì„ ê²°í•©í•˜ê³  cls tokenì— ëŒ€í•œ attentionìœ¼ë¡œ cls token ì„ë² ë”©ì„ ì—…ë°ì´íŠ¸í•´ë‚˜ê°€ëŠ” ë°©ì‹ìœ¼ë¡œ ë¹„ë””ì˜¤ ë¶„ë¥˜. ì‹¬í”Œ!

![Prediction-Guided Distillation for Dense Object Detection](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_151955.jpg)

[Prediction-Guided Distillation for Dense Object Detection](https://arxiv.org/abs/2203.05469). ê°ì²´ ê²€ì¶œê¸°ì—ì„œ confidenceê°€ ë†’ì€ ì˜ì—­, ì¦‰ ë°•ìŠ¤ ì˜ˆì¸¡ì— ì£¼ë¡œ ê´€ì—¬í•˜ëŠ” ì˜ì—­ì€ í•œì •ë˜ì–´ ìˆëŠ”ë° ì´ ì˜ì—­ ì •ë³´ë¥¼ ì‚¬ìš©í•´ì„œ distillation í•˜ëŠ” ë°©ë²•. ì¢€ ë‹¤ë¥´ê¸´ í•˜ì§€ë§Œ ìµœê·¼ ë³¸ ëª¨ë°”ì¼ ê²€ì¶œê¸°ë“¤ì—ì„œ ëª¨ë¸ ì¶œë ¥ì„ ì‚¬ìš©í•´ loss assignì„ í•˜ëŠ” ë°©ë²•ë“¤ì´ ìƒê°ë‚¬ë‹¤.

![ARF: Artistic Radiance Fields](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_154909.jpg)

[ARF: Artistic Radiance Fields](https://arxiv.org/abs/2206.06360). ì´ ë…¼ë¬¸ë„ ì—¬ê¸° ë‚˜ì™”ë‹¤. [https://www.cs.cornell.edu/projects/arf/](https://www.cs.cornell.edu/projects/arf/)

ê·¸ ì™¸ ë˜ ëˆˆì— ë„ì—ˆë˜ ë…¼ë¬¸ë“¤.

![AdaNeRF: Adaptive Sampling for Real-time Rendering of Neural Radiance Fields](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_154342.jpg)

![Object Detection as Probabilistic Set Prediction](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_163918.jpg)

![í•´í”¼ ì•„ì›Œ](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_181052.jpg)

í˜¸í…”ì—ì„œ 5ì‹œ ë°˜ ~ 7ì‹œ ì •ë„ê¹Œì§€ í•´í”¼ ì•„ì›Œê°€ ìˆì–´ì„œ ì ê¹ ì™€ì¸ì„ í•œ ì”.

![ì½”ì ¤](https://res.cloudinary.com/rosinality/image/upload/c_scale,h_0.5/v1667528721/tel-aviv/20221025_194948.jpg)

ì™œ ìŒì‹ ì‚¬ì§„ì´ ì—†ì§€!?

ì´ ë‚  ì €ë…ì€ Little Pragueì—ì„œ. ë°”ë¡œ ì•ì— ì¤‘ë™ ìŒì‹ì ì´ ìˆì—ˆëŠ”ë° ìœ ëª…í•˜ê¸´ í•œì§€ í•™íšŒ ì°¸ê°€ìë“¤ê¹Œì§€ ë°€ë ¤ì™€ì„œ ì›¨ì´íŒ…ì´ ìˆì–´ í¬ê¸°. (ë‹¤ìŒì—ë„ í•œ ë²ˆ ë” ê°€ë´¤ëŠ”ë° ì—¬ì „í•˜ë”ë¼.) ë‚´ í”½ì€ ê±°ìœ„ ë‹¤ë¦¬ êµ¬ì´. ê·¸ëŸ­ì €ëŸ­ ê´œì°®ì•˜ë‹¤.