+++
autoThumbnailImage = true
categories = ["thoughts"]
coverImage = "http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/optimization-large.jpg"
coverSize = "partial"
date = "2017-04-21T12:24:32+09:00"
hasMath = false
isCJKLanguage = true
keywords = ["agent based modeling", "hyperparameter optimization"]
tags = ["agent based modeling", "hyperparameter optimization"]
thumbnailImagePosition = "left"
title = "행위자 기반 모형과 하이퍼파라미터 최적화"

+++

모형의 파라미터는 모형의 학습 과정에서 결정된다. 그렇다면 파라미터에 영향을 미치는 하이퍼파라미터는? 그건 사람이 결정해야 할 문제다. 이걸 잘 정하는 것, 혹은 튜닝하는 것은 모형의 성능에 크리티컬한 부분이라고 할 수 있다.

하이퍼파라미터를 결정하는 첫째 방법은 역시 사람이 직접 정하는 것이라고 할 수 있다. 하다보면 경험이 생기고 어떤 하이퍼파라미터를 쓰면 망한다는 식으로 직관이 누적되기 때문에 생각보다 효과적인 방법이다.

둘째 방법은 그리드 탐색(Grid Search). 각 하이퍼파라미터에 대한 후보를 정해놓고 그 후보의 모든 가능한 조합에 대해서 모형을 학습시킨 다음 성능을 보는 것. 문제는 하이퍼파라미터의 후보가 증가할수록 탐색 공간은 조합적(Combinatorial)으로 증가하기 때문에 비현실적이라는 것이다.

셋째 방법은 무작위 탐색 혹은 그와 유사한 준-무작위 탐색 방법들. 무작위 탐색은[Random Search for Hyper-Parameter Optimization](http://www.jmlr.org/papers/v13/bergstra12a.html) 하이퍼파라미터의 공간을 그리드 탐색보다 더 효율적으로 탐색한다는 것이 알려져 있다. 소볼 수열(Sobol Sequence) 같은 준-무작위 수열을 통한 학습도 이러한 문제에선 효과적일 수 있다.

넷째 방법은 베이지안 최적화와 같은 모형 기반 방법들. 예를 들어 모형의 성능을 예측하는 모형 B를 만들고 모형 A를 특정 하이퍼파라미터에 학습시킨 다음 그 결과로 모형 B를 업데이트 하고, 그 모형을 통해 적절한 하이퍼파라미터를 선정해 다시 모형 A를 학습하고, 하는 것을 반복하는 방식이다. 직접 써본 적은 없는데 써본 경험을 들어보면 무작위 탐색보다 확실하게 동일 시간에 대해 나은 결과를 보여준다고 한다.

이외에도 강화학습을 사용하는 등 여러 방법이 있지만 위 네 가지가 여전히 가장 대표적인 방법일 듯 하다.

행위자 기반 모형의 문제 중 하나는, 물론 모형을 제대로 그럴 듯 하게 만드는 것도 문제지만, 모형의 기술에 동반되는 수많은 파라미터의 설정이라고 할 수 있다. 사회학이 본래 다 그렇지만 행위자 기반 모형엔 수많은 요인들이 동반되고 그런 요인들 하나하나가 여러 파라미터들을 추가적으로 요구한다. 그러면 그런 파라미터들의 공간을 탐색하는 것이 문제가 된다. 그래서 보통 몇 가지 파라미터는 이론적인 배경을 통해 고정하고 나머지에 대해서는 그리드 탐색을 하는 접근을 많이 사용한다.

그런데 우리가 모형에 대해 기대하는 결과가 있다면? 그 결과를 목표로 모형 기반 최적화 등을 시도해볼 수 있을 것이다. 그러면 상당히 넓은 파라미터 공간에 대해서도 적당한 시간 내에 좋은 후보 파라미터를 찾아내는 접근이 가능할 것이다.

물론 이렇게 해서 찾아낸 파라미터가 정말로 타당한가 하는 것은 다른 문제긴 하다. 또 서로 다른 파라미터가 유사한 결과를 내는 문제도 회피할 수 없고. 그러나 이런 종류의 문제는 시뮬레이션만으로는 사실 회피하기 어려운 문제라고 봐야할 것이다.