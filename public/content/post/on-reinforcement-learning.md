+++
autoThumbnailImage = true
categories = ["thoughts"]
coverImage = "http://res.cloudinary.com/rosinality/image/upload/v1492734059/covers/rat"
coverSize = "partial"
date = "2017-05-21T00:01:52+09:00"
hasMath = false
isCJKLanguage = true
keywords = ["reinforcement learning", "behaviorism", "mental model", "cognitive psychology"]
tags = ["reinforcement learning", "behaviorism", "mental model", "cognitive psychology"]
thumbnailImagePosition = "left"
title = "강화학습에 대해"

+++

지금의 강화학습은 행동주의 심리학의 조작적 조건 형성과 많이 닮아있다. 사실 강화Reinforcement라는 단어를 쓰는 것 자체가 행동주의적 심리학의 언어와 맞닿아 있는 것이라고 볼 수도 있다.

조작적 조건형성이라는 것 자체는 복잡한 개념은 아니고 강화와 처벌로 동물의 행동의 빈도를 높이거나 낮추는 것이다. 그러니까 레버를 누르면 먹이가 나오는 상자에 쥐를 넣어서 레버를 누르는 행동을 하게 한다거나 하는 것이 그 대표적인 사례다. 워낙 강력한 개념이다보니 많은 곳에서 아주 자연스럽게 쓰이고 있는 원리이기도 하다. 하기를 원하는 행동은 보상을 줘서 더 자주 하게 하고, 하기를 원하지 않는 행동은 처벌을 줘서 하지 않게 만든다는 것이니까 말이다.

조작적 조건형성이 얼마나 강력한가 하면. 유명한 사례이긴 하지만 조작적 조건형성의 대부 스키너는 비둘기가 탁구를 칠 수 있도록 학습을 시키기도 했다.

https://www.youtube.com/watch?v=vGazyH6fQQ4

그런데 이런 복잡한 행동을 하게 하는데는 난점이 한 가지 있다. 어떤 행동을 하면 보상을 줘야 하는데 동물이 보통 그런 행동을 할 일이 없다는 것이다. 레버가 뭔지도 모르고 레버를 누르면 무슨 일이 생기는지를 이해할 수도 없는 쥐가 어떻게 레버를 누르게 한다는 말인가? 정말 오랜 시간을 두고 보면 우연히 레버를 누르는 경우가 발생할 수 있다. 보상을 주기 위해서는 하염없이 그걸 기다려야 하는 것이다. 거기다 한 번으로 학습하기는 어려우니 다시 그런 상황이 우연히 발생하기를 기다려야 한다. 이래서는 너무 오래 걸린다.

다르게 말하면, 행위자가 환경의 메커니즘에 대해 전혀 이해하지 못하고 있는 상황에서는 그저 여러 방식으로 탐색해보는 수밖에 없다는 것이다. 그리고 이게 강화학습에서 흔히 하는 일이기도 하다. 여러 행동들을 해보면서 (거의 우연하게) 괜찮은 행동을 할 수 있기를 기대하기.

그래서 조작적 조건형성에서는 행동 조성Shaping이라는 방법을 흔히 쓴다. 쥐가 레버를 누르게 하는 것이 목표라면 그 목표까지 가는 과정을 단계별로 분해해서 단계적으로 강화해나가는 것이다. 우선 쥐가 레버 근처로 가면 보상을 주고, 그 다음에는 쥐가 레버 근처에 머무르면 보상을 주고, 레버를 건드리면 보상을 주고, 마침내 레버를 누르면 보상을 주는 방식으로 목표의 중간 단계 행동의 확률을 높여서 학습에 걸리는 시간을 단축하는 것이다.

그렇지만 이런 단계적 접근이 강화학습의 입장에서 우아한 접근이라고 보기는 힘들 것이다. 무엇보다 고차원적인 행동을 할 수 있는 것이 목표라면(예: 스타2를 플레이하기) 그 목표의 중간 단계들을 적절하게 분해하는 것 자체도 어려운 일이라고 할 수 있다. 내게 주어진 정보를 가지고 상대의 행동을 파악해서 그에 맞게 대응하는 전술을 사용한다라는 추론과 판단, 의사결정이 복합된 목표의 중간 단계를 분석한다고 생각해보자.

그러나 행위자에게 환경에 대한 인지적 이해가 있다면 굳이 단계적으로 행동을 형성해야할 필요는 없다. 환경에 대한 인지적 모형을 가지고 있다면 벽 뒤에 있는 문의 손잡이를 돌려 연다고 하는 식의 과제를 수행한다고 할 때도 한참 탐색할 필요가 없다. 공간적으로 가능한 행위들을 앉은 상태에서도 추론해 계획할 수 있고 기존의 문을 열었던 방식을 전이Transfer시켜 문을 간단히 열 수 있다.

그렇다면 강화학습에 필요한 몇 가지 도구들을 생각해볼 수 있다. Yann LeCun이 강조하는 것과 같은 세상에 대한 멘탈 모델, 그러니까 세계의 다음 상태에 대한 예측을 수행하는 모델(LeCun은 unsupervised model이 이런 역할을 할 수 있다고 보는 것 같다)과 그러한 모델을 새로운 과제에 전이시키는 Transfer learning, 그리고 세상에 대한 모델을 맨땅에서부터 만들 필요가 없도록 단서를 주는 Imitation learning. 신석기시대가 시작된 이후로도 인류가 바퀴를 발명하기까지는 수천 년의 시간이 필요했다. 이러한 도구 없이 알고리즘이 매번 바퀴를 바닥에서부터 재발명해야 한다면 복잡한 문제를 해결하기는 어려울 것이다. 혹은 웬만해선 그 복잡한 문제를 해결할 수 있을 정도로 상태 공간을 탐색하기에는 시간이 부족할 것이다.