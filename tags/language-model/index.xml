<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>language model on Nondifferentiable Log</title><link>http://rosinality.github.io/tags/language-model/</link><description>Recent content in language model on Nondifferentiable Log</description><generator>Hugo -- gohugo.io</generator><language>ko-kr</language><lastBuildDate>Wed, 15 Feb 2023 23:27:49 +0900</lastBuildDate><atom:link href="http://rosinality.github.io/tags/language-model/index.xml" rel="self" type="application/rss+xml"/><item><title>언어의 손실 압축에 대하여</title><link>http://rosinality.github.io/2023/02/%EC%96%B8%EC%96%B4%EC%9D%98-%EC%86%90%EC%8B%A4-%EC%95%95%EC%B6%95%EC%97%90-%EB%8C%80%ED%95%98%EC%97%AC/</link><pubDate>Wed, 15 Feb 2023 23:27:49 +0900</pubDate><guid>http://rosinality.github.io/2023/02/%EC%96%B8%EC%96%B4%EC%9D%98-%EC%86%90%EC%8B%A4-%EC%95%95%EC%B6%95%EC%97%90-%EB%8C%80%ED%95%98%EC%97%AC/</guid><description>https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web LM을 다음 단어를 예측할 뿐이라거나 학습 데이터를 기억할 뿐이라는 식으로 묘사하는 것은 폄하를 위한 언어이지 LM의 실체나 실제 한계에 대해서 논하기에 적절한 방</description></item></channel></rss>